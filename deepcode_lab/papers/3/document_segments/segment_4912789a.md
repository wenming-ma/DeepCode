# conclusion

**Content Type:** conclusion
**Keywords:** development, modular, resolves, versatility, forms, synthesis, potential, visualization, priorities, identifies

conclusions of the paper: on realistic research code reproduction benchmarks, DeepCode not
only achieves significantly higher average performance than existing automated reproduction and
code assistance systems, but also demonstrates robust and consistent advantages in fine-grained,
multi-paper, multi-run analyses.
A.2 Use Cases for DeepCode
This appendix provides a series of visual artifacts generated by DeepCode, offering concrete evidence
of its capabilities across different software development and research domains. These examples
are intended to supplement the main paper by illustrating the practical utility and versatility of our
system.
The initial set of examples, depicted in Figure 7, focuses on DeepCode’s proficiency in generating
sophisticated backend systems. The figures showcase automatically constructed administrative
dashboards, which likely include functionalities for data monitoring, user management, and content
moderation. Such pages are critical for the operational management of modern web applications but
are often tedious and repetitive to build. DeepCode’s ability to scaffold these complex, data-driven
interfaces from high-level specifications demonstrates its potential to significantly reduce boilerplate
engineering and accelerate the deployment of robust server-side infrastructure.
18

## Page 19

Table 2: Average reproduction scores: DeepCode vs. LLMs and human experts
Model Average Replication Scores
GEMINI-2.0-FLASH (BasicAgent)5.0±0.0
4o (BasicAgent)7.7±0.0
o3-mini (BasicAgent)5.1±0.8
o1 (BasicAgent)19.5±1.2
R1 (BasicAgent)9.8±0.0
CLAUDE-3-5-SONNET (BasicAgent)35.4±0.8
o3-mini (IterativeAgent)16.4±1.4
o1 (IterativeAgent)43.3±1.1
CLAUDE-3-5-SONNET (IterativeAgent)27.5±1.6
o1 [36 hours] (IterativeAgent)42.4±1.0
PaperCoder51.1±1.4
DeepCode 73.6±5.3
Human[3 paper subset, Best@3] 72.4
DeepCode[3 paper subset, Average]76.7±3.9
Table 3: DeepCode with Claude 4.5 Sonnet results.
Paper Run 1 Run 2 Run 3 Mean Std. Error Avg. Cost
FRE 0.844 0.823 0.803 0.814 0.020 9.14
RICE 0.738 0.609 0.761 0.702 0.082 8.22
BAM 0.853 0.673 0.719 0.748 0.094 8.45
WILL-MODEL-FORGET 0.776 0.793 0.857 0.808 0.042 9.20
PINN 0.947 0.800 0.983 0.910 0.097 7.84
ALL-IN-ONE 0.769 0.747 0.759 0.759 0.011 9.43
ADAPTIVE-PRUNING 0.547 0.570 0.516 0.544 0.027 9.13
LBCS 0.689 0.732 0.820 0.747 0.066 10.01
MECHANISTIC-UNDERSTANDING 0.889 0.944 0.941 0.925 0.031 10.20
TEST-TIME-MODEL-ADAPTATION 0.717 0.578 0.652 0.649 0.069 7.90
SAMPLE-SPECIFIC-MASKS 0.690 0.740 0.583 0.671 0.080 8.30
BRIDGING-DATA-GAPS 0.552 0.566 0.626 0.581 0.039 7.98
STAY-ON-TOPIC-WITH-CLASSIFIER-FREE-GUIDANCE 0.734 0.800 0.626 0.705 0.088 9.12
STOCHASTIC-INTERPOLANTS 0.851 0.792 0.801 0.815 0.031 8.89
LCA-ON-THE-LINE 0.665 0.844 0.739 0.749 0.090 7.73
SEQUENTIAL-NEURAL-SCORE-ESTIMATION 0.930 0.862 0.817 0.870 0.057 10.01
SAPG 0.702 0.755 0.757 0.738 0.031 9.19
FTRL 0.558 0.606 0.631 0.598 0.037 7.06
ROBUST-CLIP 0.772 0.742 0.685 0.733 0.044 7.83
BBOX 0.620 0.681 0.631 0.644 0.033 11.90
Building upon the backend logic, a system’s utility is often defined by its user-facing presentation.
Figure 8 illustrates DeepCode’s capacity for generating intuitive and functional Web UIs. The
generated interfaces, featuring elements such as data visualization charts and interactive forms,
translate abstract user requirements into tangible, interactive components. This capability not only
complements the backend generation by providing a corresponding frontend, but also empowers
developers and designers to rapidly prototype and iterate on user experiences, thereby shortening the
path from concept to a functional product.
Perhaps DeepCode’s most ambitious application, however, lies in its potential to bridge the chasm
between academic research and practical implementation. The Paper2Code functionality, illustrated
in Figure 9, exemplifies this capability. The figure is twofold: on the left, it presents the high-level
code structure that DeepCode inferred from a research paper, discerning the architectural blueprint
of the proposed algorithm, including its modular components and file organization. On the right, it
provides a concrete code sample, instantiating a specific function or class with precise logic. This
powerful feature moves beyond conventional code generation by interpreting unstructured scientific
19

## Page 20

Figure 7: DeepCode-generated backend system pages.
Figure 8: DeepCode-generated Web UI.
language to produce structured, executable artifacts, thereby holding immense promise for enhancing
research reproducibility and accelerating the adoption of novel scientific discoveries.
A.3 Sub-Agents Details of DeepCode
DeepCode decomposes the software engineering pipeline into a set of specialized agents with narrow,
well-specified responsibilities and standardized communication interfaces, rather than relying on a
single monolithic generative model. The individual agents and their responsibilities are summarized
in Table 4. This modular design allows different stages of the lifecycle—ranging from requirement un-
derstanding to architectural planning and code synthesis—to be implemented as transformations over
shared intermediate representations, while preserving global architectural and semantic consistency.
During the planning stage, DeepCode relies on explicit coordination between conceptual and
algorithmic analysis agents to derive a coherent development blueprint from high-level spec-
ifications.The Central Orchestrating Agent first routes each input through the Document Parsing
and/or Intent Understanding agents to obtain a structured specification, which then serves as the
input to the Code Planning agent. Within this planning module, two internal analysis pipelines
operate in parallel over the same intermediate representation. The conceptual analysis sub-agent is
responsible for system-level decomposition: it identifies major subsystems, their responsibilities,
and inter-module interfaces, and it constructs an architecture-level call topology. The algorithmic
analysis sub-agent is responsible for computational aspects: it abstracts key algorithmic ideas, selects
candidate data structures, reasons about time and space complexity constraints, and enumerates
feasible implementation patterns. The partial plans produced by these two sub-agents are reconciled
by a planning aggregation component (Code Analysis agent), which resolves inconsistencies and
materializes a project-level development roadmap, including module boundaries, interface signatures,
dependency relations, implementation priorities, and testing hooks. This roadmap serves as the design
baseline that constrains all downstream code generation and refinement steps.
20

## Page 21

Figure 9: Paper2Code Samples of DeepCode. Left: Code Structure, Right: Code Sample
During the code synthesis stage, DeepCode couples retrieval-augmented