<!DOCTYPE html>
<html lang="en">
<head>
<meta content="text/html; charset=utf-8" http-equiv="content-type"/>
<title>DeepCode: Open Agentic Coding</title>
<!--Generated on Mon Dec  8 15:29:19 2025 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport"/>
<link href="/static/browse/0.3.4/css/arxiv-html-papers-20250916.css" rel="stylesheet" type="text/css"/>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/html2canvas/1.3.3/html2canvas.min.js"></script>
<script src="/static/browse/0.3.4/js/addons_new.js"></script>
<script src="/static/browse/0.3.4/js/feedbackOverlay.js"></script>
<base href="/html/2512.07921v1/"/></head>
<body>
<nav class="ltx_page_navbar">
<nav class="ltx_TOC">
<ol class="ltx_toclist">
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2512.07921v1#S1" title="In DeepCode: Open Agentic Coding"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1 </span>Introduction</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2512.07921v1#S2" title="In DeepCode: Open Agentic Coding"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2 </span>Preliminary</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2512.07921v1#S2.SS1" title="In 2 Preliminary â€£ DeepCode: Open Agentic Coding"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.1 </span>Task Definition</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2512.07921v1#S2.SS2" title="In 2 Preliminary â€£ DeepCode: Open Agentic Coding"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.2 </span>Objectives</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2512.07921v1#S3" title="In DeepCode: Open Agentic Coding"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3 </span>The DeepCode Framework</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2512.07921v1#S3.SS1" title="In 3 The DeepCode Framework â€£ DeepCode: Open Agentic Coding"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1 </span>Phase 1: Blueprint Generation</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2512.07921v1#S3.SS1.SSS1" title="In 3.1 Phase 1: Blueprint Generation â€£ 3 The DeepCode Framework â€£ DeepCode: Open Agentic Coding"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1.1 </span>Hierarchical Content Segmentation</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2512.07921v1#S3.SS1.SSS2" title="In 3.1 Phase 1: Blueprint Generation â€£ 3 The DeepCode Framework â€£ DeepCode: Open Agentic Coding"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1.2 </span>Multi-Agent Specification Analysis</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2512.07921v1#S3.SS1.SSS3" title="In 3.1 Phase 1: Blueprint Generation â€£ 3 The DeepCode Framework â€£ DeepCode: Open Agentic Coding"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1.3 </span>Synthesizing the Implementation Blueprint</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2512.07921v1#S3.SS2" title="In 3 The DeepCode Framework â€£ DeepCode: Open Agentic Coding"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.2 </span>Phase 2: Code Generation</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2512.07921v1#S3.SS2.SSS1" title="In 3.2 Phase 2: Code Generation â€£ 3 The DeepCode Framework â€£ DeepCode: Open Agentic Coding"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.2.1 </span>Stateful Generation with CodeMem</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2512.07921v1#S3.SS2.SSS2" title="In 3.2 Phase 2: Code Generation â€£ 3 The DeepCode Framework â€£ DeepCode: Open Agentic Coding"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.2.2 </span>Knowledge Grounding with CodeRAG</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2512.07921v1#S3.SS3" title="In 3 The DeepCode Framework â€£ DeepCode: Open Agentic Coding"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.3 </span>Phase 3: Automated Verification and Refinement</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2512.07921v1#S3.SS3.SSS1" title="In 3.3 Phase 3: Automated Verification and Refinement â€£ 3 The DeepCode Framework â€£ DeepCode: Open Agentic Coding"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.3.1 </span>Static Analysis and Code Quality Refinement</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2512.07921v1#S3.SS3.SSS2" title="In 3.3 Phase 3: Automated Verification and Refinement â€£ 3 The DeepCode Framework â€£ DeepCode: Open Agentic Coding"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.3.2 </span>Sandbox Execution and Functional Correction</span></a></li>
</ol>
</li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2512.07921v1#S4" title="In DeepCode: Open Agentic Coding"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4 </span>Experiments</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2512.07921v1#S4.SS1" title="In 4 Experiments â€£ DeepCode: Open Agentic Coding"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.1 </span>Experiments Settings</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2512.07921v1#S4.SS2" title="In 4 Experiments â€£ DeepCode: Open Agentic Coding"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.2 </span>Main Results</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2512.07921v1#S4.SS3" title="In 4 Experiments â€£ DeepCode: Open Agentic Coding"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.3 </span>Analysis on Different LLMs</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2512.07921v1#S4.SS4" title="In 4 Experiments â€£ DeepCode: Open Agentic Coding"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.4 </span>Ablation Studies</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2512.07921v1#S5" title="In DeepCode: Open Agentic Coding"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5 </span>Related Work</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2512.07921v1#S5.SS1" title="In 5 Related Work â€£ DeepCode: Open Agentic Coding"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.1 </span>General Coding Agents</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2512.07921v1#S5.SS2" title="In 5 Related Work â€£ DeepCode: Open Agentic Coding"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.2 </span>Scientific Coding Agents</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2512.07921v1#S6" title="In DeepCode: Open Agentic Coding"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6 </span>Discussion: Challenges and Future Directions</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2512.07921v1#S7" title="In DeepCode: Open Agentic Coding"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">7 </span>Conclusion</span></a></li>
<li class="ltx_tocentry ltx_tocentry_appendix">
<a class="ltx_ref" href="https://arxiv.org/html/2512.07921v1#A1" title="In DeepCode: Open Agentic Coding"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">A </span>Appendix</span></a>
<ol class="ltx_toclist ltx_toclist_appendix">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2512.07921v1#A1.SS1" title="In Appendix A Appendix â€£ DeepCode: Open Agentic Coding"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">A.1 </span>Full Results</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2512.07921v1#A1.SS2" title="In Appendix A Appendix â€£ DeepCode: Open Agentic Coding"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">A.2 </span>Use Cases for DeepCode</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2512.07921v1#A1.SS3" title="In Appendix A Appendix â€£ DeepCode: Open Agentic Coding"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">A.3 </span>Sub-Agents Details of DeepCode</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2512.07921v1#A1.SS4" title="In Appendix A Appendix â€£ DeepCode: Open Agentic Coding"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">A.4 </span>MCP Tool Stack in DeepCode</span></a></li>
</ol>
</li>
</ol></nav>
</nav>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">
<span class="ltx_text" style="position:relative; bottom:-3.4pt;"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_square" height="21" id="g1" src="figs/logo.png" width="25"/></span>Â DeepCode: Open Agentic Coding</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">
Zongwei Li<span class="ltx_note ltx_role_footnotemark" id="footnotex1"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_note_type">footnotemark: </span><span class="ltx_tag ltx_tag_note">1</span></span></span></span> Â Â Â 
Zhonghang Li<span class="ltx_note ltx_role_footnotemark" id="footnotex2"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_note_type">footnotemark: </span><span class="ltx_tag ltx_tag_note">1</span></span></span></span> Â Â Â 
Zirui GuoÂ Â Â 
Xubin RenÂ Â Â 
Chao Huang 
<br class="ltx_break"/>The University of Hong Kong 
<br class="ltx_break"/><span class="ltx_text ltx_font_typewriter">{zongwei9888, bjdwh.zzh, larfii1010, xubinrencs, chaohuang75}@gmail.com
<br class="ltx_break"/></span>Â <span class="ltx_text ltx_font_bold">Source Code:</span> <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/HKUDS/DeepCode" style="--ltx-fg-color:#0000FF;" title="">https://github.com/HKUDS/DeepCode</a>
</span><span class="ltx_author_notes">Equal contribution.Chao Huang is the Corresponding Author.</span></span>
</div>
<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p class="ltx_p">Recent advances in large language models (LLMs) have given rise to powerful coding agents, making it possible for code assistants to evolve into code engineers. However, existing methods still face significant challenges in achieving high-fidelity document-to-codebase synthesisâ€”such as scientific papers to codeâ€”primarily due to a fundamental conflict between information overload and the context bottlenecks of LLMs.
In this work, we introduce DeepCode, a fully autonomous framework that fundamentally addresses this challenge through principled information-flow management. By treating repository synthesis as a channel optimization problem, DeepCode seamlessly orchestrates four information operations to maximize task-relevant signals under finite context budgets: source compression via blueprint distillation, structured indexing using stateful code memory, conditional knowledge injection via retrieval-augmented generation, and closed-loop error correction.
Extensive evaluations on the PaperBench benchmark demonstrate that DeepCode achieves state-of-the-art performance, decisively outperforming leading commercial agents such as Cursor and Claude Code, and crucially, surpassing PhD-level human experts from top institutes on key reproduction metrics.
By systematically transforming paper specifications into production-grade implementations comparable to human expert quality, this work establishes new foundations for autonomous scientific reproduction that can accelerate research evaluation and discovery.</p>
</div>
<figure class="ltx_figure" id="S0.F1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="167" id="S0.F1.g1" src="x1.png" width="548"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" style="font-size:90%;">Figure 1</span>: </span><span class="ltx_text" style="font-size:90%;">DeepCode main results.</span></figcaption>
</figure>
<section class="ltx_section" id="S1">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>
<div class="ltx_para" id="S1.p1">
<p class="ltx_p">The rapid evolution of Large Language Models (LLMs) has initiated a profound shift in how software is specified, implemented, and maintainedÂ <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">jiang2024survey</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">ge2025survey</span>]</cite>. AI-assisted coding tools such as Cursor and Codex have already transformed everyday development practice by automating routine implementation tasks and offering intelligent inline suggestionsÂ <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">peng2023impact</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">dong2025survey</span>]</cite>. Yet these systems remain fundamentally assistive: they operate at the level of code completion, assuming that a human engineer still performs the higher-level tasks of understanding specifications, planning system architecture, and validating behavior. Recent advances in agentic LLM frameworks point toward a more ambitious paradigmâ€”what we term <em class="ltx_emph ltx_font_italic">agentic software engineering</em>â€”in which LLM-based agents are expected to plan, orchestrate, and refine entire software projects from high-level natural language or document-level specificationsÂ <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">wang2025ai</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">tang2025airesearcher</span>]</cite>. In this emerging regime, programming shifts from <em class="ltx_emph ltx_font_italic">writing code</em> to <em class="ltx_emph ltx_font_italic">writing specifications</em>, and the central question becomes: <em class="ltx_emph ltx_font_italic">can an artificial coding agent behave as an autonomous engineer that translates rich, informal specifications into comprehensive, robust systems?</em></p>
</div>
<div class="ltx_para" id="S1.p2">
<p class="ltx_p">A natural and stringent testbed for this paradigm is <em class="ltx_emph ltx_font_italic">high-fidelity, document-grounded program synthesis</em>, where a complex scientific paper serves as the sole specification and the goal is to produce a fully executable implementation that faithfully reflects it. Such papers are detailed multimodal specifications, combining informal exposition with equations, pseudo-code, and scattered hyperparameters. In this work, we tackle the highly challenging task of reproducing machine learning papers as complete code repositories. Recent efforts have explored this via LLM-based agents. PaperBench evaluates frontier models on 20 ICML papers, finding the strongest model (o1) with IterativeAgent achieves only 42.4% replication score, far below 72.4% for human expertsÂ <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">starace2025PaperBench</span>]</cite>. PaperCoder employs a multi-agent pipeline spanning planning, analysis, and generation, reaching 51.14% reproduction rate on PaperBenchÂ <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">seo2025paper2code</span>]</cite>. These modest results reveal that current approaches fall well short of reliable, end-to-end replication. We identify four key challenges that underlie this gap:</p>
</div>
<figure class="ltx_figure" id="S1.F2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="310" id="S1.F2.g1" src="x2.png" width="660"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" style="font-size:90%;">Figure 2</span>: </span><span class="ltx_text" style="font-size:90%;">From Challenge to Solution of DeepCode. Left: Current AI agents achieve only a 42% paper replication score compared to 72% for human experts, highlighting the limitations of existing agents. Middle: The core challenge stems from information overload conflicting with LLM context limits, causing four key failure modes. Right: DeepCode addresses this through four information operations (Blueprint, CodeMem, CodeRAG, Verification), surpassing human expert performance.</span></figcaption>
</figure>
<div class="ltx_para" id="S1.p3">
<p class="ltx_p"><span class="ltx_text ltx_font_bold">(i) Specification Preservation.</span> Papers describe the target system through scattered, multimodal constraints. Preserving a faithful mapping from this fragmented specification to implementation is inherently difficult.
<span class="ltx_text ltx_font_bold">(ii) Global Consistency under Partial Views.</span> Repositories comprise interdependent modules, but generation proceeds file-by-file under limited context. Maintaining consistency across interfaces, types, and invariants under finite context windows easily leads to broken abstractions.
<span class="ltx_text ltx_font_bold">(iii) Completion of Underspecified Designs.</span> Papers specify only algorithmic cores, leaving implementation details and experimental frameworks implicit. Inferring these consequential but underspecified choices is non-trivial.
<span class="ltx_text ltx_font_bold">(iv) Executable Faithfulness.</span> Faithful reproduction requires executable systems, not just plausible code. Long-horizon generation often yields repositories with subtle logic bugs, dependency conflicts, and fragile pipelines that prevent end-to-end execution.</p>
</div>
<div class="ltx_para" id="S1.p4">
<p class="ltx_p">We argue that fundamentally addressing these challenges requires <em class="ltx_emph ltx_font_italic">principled information-flow management</em>. We abstract the synthesis process as the transmission of a high-entropy specificationâ€”the scientific paperâ€”through a sequence of bandwidth-constrained channels, defined by the LLMâ€™s context windows. Naive strategies that simply concatenate raw documents with growing code history induce channel saturation, where redundant tokens mask critical algorithmic constraints, causing the effective Signal-to-Noise Ratio to collapse. Consequently, valid repository generation requires a paradigm shift governed by <em class="ltx_emph ltx_font_italic">contextual information maximization</em>: at each generation step, the system must actively maximize the density of task-relevant signals while suppressing irrelevant noise.</p>
</div>
<div class="ltx_para" id="S1.p5">
<p class="ltx_p">Motivated by this perspective, we introduce <span class="ltx_text ltx_font_bold">DeepCode</span>, an open agentic coding framework that fundamentally reimagines repository-level synthesis as a problem of <em class="ltx_emph ltx_font_italic">hierarchical information-flow management</em>. Rather than treating synthesis as a monolithic process, DeepCode systematically addresses the doc-to-repos challenges by instantiating the proposed paradigm through four orchestrated information operations: (1) <em class="ltx_emph ltx_font_italic">source compression</em>, which distills unstructured multi-modal specifications into a precise structural blueprint to maximize signal density; (2) <em class="ltx_emph ltx_font_italic">structured indexing</em>, which abstracts the evolving repository state into concise memory entries to maintain global consistency without context saturation; (3) <em class="ltx_emph ltx_font_italic">conditional knowledge injection</em>, which leverages retrieval-augmented generation to bridge implicit specification gaps with standard implementation patterns; and (4) <em class="ltx_emph ltx_font_italic">error correction</em>, which utilizes closed-loop verification to transform execution feedback into corrective signals for rectifying transmission errors. Our contributions are threefold:</p>
</div>
<div class="ltx_para" id="S1.p6">
<ul class="ltx_itemize" id="S1.I1">
<li class="ltx_item" id="S1.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span>
<div class="ltx_para" id="S1.I1.i1.p1">
<p class="ltx_p">We characterize the task of high-fidelity document-to-repository synthesis through an information-theoretic lens, identifying the central conflict as an <em class="ltx_emph ltx_font_italic">information-overload vs. context-bottleneck</em> conflict. From this perspective, we propose an information-theoretic design principle: effective agentic coding systems must explicitly structure, route, and compress information to maximize task-relevant signal under finite context budgets.</p>
</div>
</li>
<li class="ltx_item" id="S1.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span>
<div class="ltx_para" id="S1.I1.i2.p1">
<p class="ltx_p">We instantiate this principle in DeepCode, a systematic framework that orchestrates four strategic information operations: blueprint distillation, stateful memory management, conditional knowledge injection, and closed-loop verification. By dynamically optimizing the signal-to-noise ratio within the context window, DeepCode effectively resolves the challenges of long-range specification preservation, cross-file consistency, and implicit knowledge gaps in complex generation tasks.</p>
</div>
</li>
<li class="ltx_item" id="S1.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span>
<div class="ltx_para" id="S1.I1.i3.p1">
<p class="ltx_p">Extensive evaluations on the PaperBench benchmark demonstrate that DeepCode achieves state-of-the-art performance, decisively <span class="ltx_text ltx_font_bold">outperforming leading commercial agents</span> (<span class="ltx_text ltx_font_italic">e</span>.<span class="ltx_text ltx_font_italic">g</span>.Â Cursor, Claude Code, Codex) and, notably, <span class="ltx_text ltx_font_bold">surpassing human expert performance</span> on key reproduction metrics. Furthermore, our analysis reveals that principled information-flow management yields significantly larger performance gains than merely scaling model size or context length, offering a pivotal direction for the future design of autonomous software engineers.</p>
</div>
</li>
</ul>
</div>
</section>
<section class="ltx_section" id="S2">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Preliminary</h2>
<section class="ltx_subsection" id="S2.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.1 </span>Task Definition</h3>
<div class="ltx_para" id="S2.SS1.p1">
<p class="ltx_p">The primary objective of this work is to develop a system for <span class="ltx_text ltx_font_italic">high-fidelity program synthesis</span>. We formalize this as the process of learning a mapping function, <math alttext="\mathcal{F}_{gen}" class="ltx_Math" display="inline" id="S2.SS1.p1.m1" intent=":literal"><semantics><msub><mi class="ltx_font_mathcaligraphic">â„±</mi><mrow><mi>g</mi><mo lspace="0em" rspace="0em">â€‹</mo><mi>e</mi><mo lspace="0em" rspace="0em">â€‹</mo><mi>n</mi></mrow></msub><annotation encoding="application/x-tex">\mathcal{F}_{gen}</annotation></semantics></math>, which transforms a specification document, <math alttext="\mathcal{D}" class="ltx_Math" display="inline" id="S2.SS1.p1.m2" intent=":literal"><semantics><mi class="ltx_font_mathcaligraphic">ğ’Ÿ</mi><annotation encoding="application/x-tex">\mathcal{D}</annotation></semantics></math>, into a complete and executable code repository, <math alttext="\mathcal{P}" class="ltx_Math" display="inline" id="S2.SS1.p1.m3" intent=":literal"><semantics><mi class="ltx_font_mathcaligraphic">ğ’«</mi><annotation encoding="application/x-tex">\mathcal{P}</annotation></semantics></math>. The core function is defined as:</p>
<table class="ltx_equation ltx_eqn_table" id="S2.E1">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\mathcal{F}_{gen}:\mathbb{D}\rightarrow\mathbb{P}" class="ltx_Math" display="block" id="S2.E1.m1" intent=":literal"><semantics><mrow><msub><mi class="ltx_font_mathcaligraphic">â„±</mi><mrow><mi>g</mi><mo lspace="0em" rspace="0em">â€‹</mo><mi>e</mi><mo lspace="0em" rspace="0em">â€‹</mo><mi>n</mi></mrow></msub><mo lspace="0.278em" rspace="0.278em">:</mo><mrow><mi>ğ”»</mi><mo stretchy="false">â†’</mo><mi>â„™</mi></mrow></mrow><annotation encoding="application/x-tex">\mathcal{F}_{gen}:\mathbb{D}\rightarrow\mathbb{P}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1)</span></td>
</tr></tbody>
</table>
<p class="ltx_p">where <math alttext="\mathbb{D}" class="ltx_Math" display="inline" id="S2.SS1.p1.m4" intent=":literal"><semantics><mi>ğ”»</mi><annotation encoding="application/x-tex">\mathbb{D}</annotation></semantics></math> represents the space of specification documents and <math alttext="\mathbb{P}" class="ltx_Math" display="inline" id="S2.SS1.p1.m5" intent=":literal"><semantics><mi>â„™</mi><annotation encoding="application/x-tex">\mathbb{P}</annotation></semantics></math> represents the space of valid code repositories. Such that for a given input document <math alttext="\mathcal{D}\in\mathbb{D}" class="ltx_Math" display="inline" id="S2.SS1.p1.m6" intent=":literal"><semantics><mrow><mi class="ltx_font_mathcaligraphic">ğ’Ÿ</mi><mo>âˆˆ</mo><mi>ğ”»</mi></mrow><annotation encoding="application/x-tex">\mathcal{D}\in\mathbb{D}</annotation></semantics></math>, the output is a program repository <math alttext="\mathcal{P}=\mathcal{F}_{gen}(\mathcal{D})" class="ltx_Math" display="inline" id="S2.SS1.p1.m7" intent=":literal"><semantics><mrow><mi class="ltx_font_mathcaligraphic">ğ’«</mi><mo>=</mo><mrow><msub><mi class="ltx_font_mathcaligraphic">â„±</mi><mrow><mi>g</mi><mo lspace="0em" rspace="0em">â€‹</mo><mi>e</mi><mo lspace="0em" rspace="0em">â€‹</mo><mi>n</mi></mrow></msub><mo lspace="0em" rspace="0em">â€‹</mo><mrow><mo stretchy="false">(</mo><mi class="ltx_font_mathcaligraphic">ğ’Ÿ</mi><mo stretchy="false">)</mo></mrow></mrow></mrow><annotation encoding="application/x-tex">\mathcal{P}=\mathcal{F}_{gen}(\mathcal{D})</annotation></semantics></math>. We address two primary manifestations of this task:</p>
</div>
<div class="ltx_para" id="S2.SS1.p2">
<ul class="ltx_itemize" id="S2.I1">
<li class="ltx_item" id="S2.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span>
<div class="ltx_para" id="S2.I1.i1.p1">
<p class="ltx_p"><span class="ltx_text ltx_font_bold">Scientific Paper Reproduction:</span> Given a scientific paper from domains such as machine learning or computer sciences as the source document <math alttext="\mathcal{D}" class="ltx_Math" display="inline" id="S2.I1.i1.p1.m1" intent=":literal"><semantics><mi class="ltx_font_mathcaligraphic">ğ’Ÿ</mi><annotation encoding="application/x-tex">\mathcal{D}</annotation></semantics></math>, the system should generate the full source code <math alttext="\mathcal{P}" class="ltx_Math" display="inline" id="S2.I1.i1.p1.m2" intent=":literal"><semantics><mi class="ltx_font_mathcaligraphic">ğ’«</mi><annotation encoding="application/x-tex">\mathcal{P}</annotation></semantics></math> required to replicate the paperâ€™s key experiments and results.</p>
</div>
</li>
<li class="ltx_item" id="S2.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span>
<div class="ltx_para" id="S2.I1.i2.p1">
<p class="ltx_p"><span class="ltx_text ltx_font_bold">Software System Generation:</span> Given a comprehensive technical design document or a concise natural language requirement for a software application (e.g., specifying UI, backend APIs, and database schema) as <math alttext="\mathcal{D}" class="ltx_Math" display="inline" id="S2.I1.i2.p1.m1" intent=":literal"><semantics><mi class="ltx_font_mathcaligraphic">ğ’Ÿ</mi><annotation encoding="application/x-tex">\mathcal{D}</annotation></semantics></math>, the system should generate the corresponding multi-component software repository <math alttext="\mathcal{P}" class="ltx_Math" display="inline" id="S2.I1.i2.p1.m2" intent=":literal"><semantics><mi class="ltx_font_mathcaligraphic">ğ’«</mi><annotation encoding="application/x-tex">\mathcal{P}</annotation></semantics></math>, including frontend, backend, and configuration files.</p>
</div>
</li>
</ul>
</div>
<div class="ltx_para" id="S2.SS1.p3">
<p class="ltx_p"><span class="ltx_text ltx_font_bold">Input: Source Document <math alttext="\mathcal{D}" class="ltx_Math" display="inline" id="S2.SS1.p3.m1" intent=":literal"><semantics><mi class="ltx_font_mathcaligraphic">ğ’Ÿ</mi><annotation encoding="application/x-tex">\mathcal{D}</annotation></semantics></math>.</span>
The source document <math alttext="\mathcal{D}" class="ltx_Math" display="inline" id="S2.SS1.p3.m2" intent=":literal"><semantics><mi class="ltx_font_mathcaligraphic">ğ’Ÿ</mi><annotation encoding="application/x-tex">\mathcal{D}</annotation></semantics></math> is represented as a sequence of multi-modal elements, <math alttext="\mathcal{D}=(d_{1},d_{2},\dots,d_{L})" class="ltx_Math" display="inline" id="S2.SS1.p3.m3" intent=":literal"><semantics><mrow><mi class="ltx_font_mathcaligraphic">ğ’Ÿ</mi><mo>=</mo><mrow><mo stretchy="false">(</mo><msub><mi>d</mi><mn>1</mn></msub><mo>,</mo><msub><mi>d</mi><mn>2</mn></msub><mo>,</mo><mi mathvariant="normal">â€¦</mi><mo>,</mo><msub><mi>d</mi><mi>L</mi></msub><mo stretchy="false">)</mo></mrow></mrow><annotation encoding="application/x-tex">\mathcal{D}=(d_{1},d_{2},\dots,d_{L})</annotation></semantics></math>, where each element <math alttext="d_{i}" class="ltx_Math" display="inline" id="S2.SS1.p3.m4" intent=":literal"><semantics><msub><mi>d</mi><mi>i</mi></msub><annotation encoding="application/x-tex">d_{i}</annotation></semantics></math> can be a block of text, a mathematical equation, a table, a figure, or a snippet of pseudocode. The length <math alttext="L" class="ltx_Math" display="inline" id="S2.SS1.p3.m5" intent=":literal"><semantics><mi>L</mi><annotation encoding="application/x-tex">L</annotation></semantics></math> of this sequence is typically large, posing significant challenges for models with finite context windows.</p>
</div>
<div class="ltx_para" id="S2.SS1.p4">
<p class="ltx_p"><span class="ltx_text ltx_font_bold">Output: Code Repository <math alttext="\mathcal{P}" class="ltx_Math" display="inline" id="S2.SS1.p4.m1" intent=":literal"><semantics><mi class="ltx_font_mathcaligraphic">ğ’«</mi><annotation encoding="application/x-tex">\mathcal{P}</annotation></semantics></math>.</span>
The target output <math alttext="\mathcal{P}" class="ltx_Math" display="inline" id="S2.SS1.p4.m2" intent=":literal"><semantics><mi class="ltx_font_mathcaligraphic">ğ’«</mi><annotation encoding="application/x-tex">\mathcal{P}</annotation></semantics></math> is not a single file but a structured repository. We define it as a tuple:</p>
<table class="ltx_equation ltx_eqn_table" id="S2.E2">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\mathcal{P}=(\mathcal{T},\mathcal{C},\mathcal{M})" class="ltx_Math" display="block" id="S2.E2.m1" intent=":literal"><semantics><mrow><mi class="ltx_font_mathcaligraphic">ğ’«</mi><mo>=</mo><mrow><mo stretchy="false">(</mo><mi class="ltx_font_mathcaligraphic">ğ’¯</mi><mo>,</mo><mi class="ltx_font_mathcaligraphic">ğ’</mi><mo>,</mo><mi class="ltx_font_mathcaligraphic">â„³</mi><mo stretchy="false">)</mo></mrow></mrow><annotation encoding="application/x-tex">\mathcal{P}=(\mathcal{T},\mathcal{C},\mathcal{M})</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(2)</span></td>
</tr></tbody>
</table>
</div>
<div class="ltx_para" id="S2.SS1.p5">
<p class="ltx_p">Here, <math alttext="\mathcal{T}" class="ltx_Math" display="inline" id="S2.SS1.p5.m1" intent=":literal"><semantics><mi class="ltx_font_mathcaligraphic">ğ’¯</mi><annotation encoding="application/x-tex">\mathcal{T}</annotation></semantics></math> represents the directory structure that organizes the files in <math alttext="\mathcal{C}" class="ltx_Math" display="inline" id="S2.SS1.p5.m2" intent=":literal"><semantics><mi class="ltx_font_mathcaligraphic">ğ’</mi><annotation encoding="application/x-tex">\mathcal{C}</annotation></semantics></math>. <math alttext="\mathcal{C}=\{c_{1},c_{2},\dots,c_{N}\}" class="ltx_Math" display="inline" id="S2.SS1.p5.m3" intent=":literal"><semantics><mrow><mi class="ltx_font_mathcaligraphic">ğ’</mi><mo>=</mo><mrow><mo stretchy="false">{</mo><msub><mi>c</mi><mn>1</mn></msub><mo>,</mo><msub><mi>c</mi><mn>2</mn></msub><mo>,</mo><mi mathvariant="normal">â€¦</mi><mo>,</mo><msub><mi>c</mi><mi>N</mi></msub><mo stretchy="false">}</mo></mrow></mrow><annotation encoding="application/x-tex">\mathcal{C}=\{c_{1},c_{2},\dots,c_{N}\}</annotation></semantics></math> is a set of <math alttext="N" class="ltx_Math" display="inline" id="S2.SS1.p5.m4" intent=":literal"><semantics><mi>N</mi><annotation encoding="application/x-tex">N</annotation></semantics></math> source code files. The generation of a coherent set <math alttext="\mathcal{C}" class="ltx_Math" display="inline" id="S2.SS1.p5.m5" intent=":literal"><semantics><mi class="ltx_font_mathcaligraphic">ğ’</mi><annotation encoding="application/x-tex">\mathcal{C}</annotation></semantics></math> where files correctly interact (e.g., via imports and function calls) is a non-trivial problem of ensuring cross-file consistency. <math alttext="\mathcal{M}" class="ltx_Math" display="inline" id="S2.SS1.p5.m6" intent=":literal"><semantics><mi class="ltx_font_mathcaligraphic">â„³</mi><annotation encoding="application/x-tex">\mathcal{M}</annotation></semantics></math> is the dependency manifest (<span class="ltx_text ltx_font_italic">e</span>.<span class="ltx_text ltx_font_italic">g</span>.Â <span class="ltx_text ltx_font_typewriter">requirements.txt</span>, <span class="ltx_text ltx_font_typewriter">package.json</span>, <span class="ltx_text ltx_font_typewriter">README.md</span> file) specifying all external libraries required to run the code.</p>
</div>
</section>
<section class="ltx_subsection" id="S2.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.2 </span>Objectives</h3>
<div class="ltx_para" id="S2.SS2.p1">
<p class="ltx_p">An ideal synthesis function <math alttext="\mathcal{F}_{gen}" class="ltx_Math" display="inline" id="S2.SS2.p1.m1" intent=":literal"><semantics><msub><mi class="ltx_font_mathcaligraphic">â„±</mi><mrow><mi>g</mi><mo lspace="0em" rspace="0em">â€‹</mo><mi>e</mi><mo lspace="0em" rspace="0em">â€‹</mo><mi>n</mi></mrow></msub><annotation encoding="application/x-tex">\mathcal{F}_{gen}</annotation></semantics></math> must generate a repository <math alttext="\mathcal{P}^{*}" class="ltx_Math" display="inline" id="S2.SS2.p1.m2" intent=":literal"><semantics><msup><mi class="ltx_font_mathcaligraphic">ğ’«</mi><mo>âˆ—</mo></msup><annotation encoding="application/x-tex">\mathcal{P}^{*}</annotation></semantics></math> that optimizes a composite scoring function. Under our paradigm of <em class="ltx_emph ltx_font_italic">principled information-flow management</em>, this optimization is framed as maximizing the effective signal-to-noise ratio across the synthesis channel. The optimal output is defined as:</p>
<table class="ltx_equation ltx_eqn_table" id="S2.E3">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\mathcal{P}^{*}=\arg\max_{\mathcal{P}\in\mathbb{P}}\text{Score}(\mathcal{P}|\mathcal{D})" class="ltx_Math" display="block" id="S2.E3.m1" intent=":literal"><semantics><mrow><msup><mi class="ltx_font_mathcaligraphic">ğ’«</mi><mo>âˆ—</mo></msup><mo>=</mo><mrow><mrow><mi>arg</mi><mo lspace="0.167em">â¡</mo><mrow><munder><mi>max</mi><mrow><mi class="ltx_font_mathcaligraphic">ğ’«</mi><mo>âˆˆ</mo><mi>â„™</mi></mrow></munder><mo lspace="0.167em">â¡</mo><mtext>Score</mtext></mrow></mrow><mo lspace="0em" rspace="0em">â€‹</mo><mrow><mo stretchy="false">(</mo><mrow><mi class="ltx_font_mathcaligraphic">ğ’«</mi><mo fence="false">|</mo><mi class="ltx_font_mathcaligraphic">ğ’Ÿ</mi></mrow><mo stretchy="false">)</mo></mrow></mrow></mrow><annotation encoding="application/x-tex">\mathcal{P}^{*}=\arg\max_{\mathcal{P}\in\mathbb{P}}\text{Score}(\mathcal{P}|\mathcal{D})</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(3)</span></td>
</tr></tbody>
</table>
</div>
<div class="ltx_para" id="S2.SS2.p2">
<p class="ltx_p">To overcome the conflict between information overload and finite context bandwidth, the scoring function decomposes into four distinct objectives, each corresponding to an information operation:</p>
</div>
<div class="ltx_para" id="S2.SS2.p3">
<ul class="ltx_itemize" id="S2.I2">
<li class="ltx_item" id="S2.I2.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span>
<div class="ltx_para" id="S2.I2.i1.p1">
<p class="ltx_p"><span class="ltx_text ltx_font_bold">Specification Preservation:</span> The repository must faithfully implement the rigid algorithmic constraints hidden within the multimodal source document. The objective is to maximize signal density by extracting precise blueprints from the unstructured input noise.</p>
</div>
</li>
<li class="ltx_item" id="S2.I2.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span>
<div class="ltx_para" id="S2.I2.i2.p1">
<p class="ltx_p"><span class="ltx_text ltx_font_bold">Global Structural Consistency:</span> The generated modules must maintain strict interface compatibility and type coherence. The objective is to maintain state consistency without context saturation, achieved by indexing the evolving codebase into compact, retrievable summaries.</p>
</div>
</li>
<li class="ltx_item" id="S2.I2.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span>
<div class="ltx_para" id="S2.I2.i3.p1">
<p class="ltx_p"><span class="ltx_text ltx_font_bold">Domain Knowledge Grounding:</span> The system must bridge the gap between abstract academic descriptions and concrete engineering implementations. The objective is to resolve underspecified designs by conditionally injecting standard libraries and patterns from external knowledge bases.</p>
</div>
</li>
<li class="ltx_item" id="S2.I2.i4" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span>
<div class="ltx_para" id="S2.I2.i4.p1">
<p class="ltx_p"><span class="ltx_text ltx_font_bold">Functional Executability:</span> The final repository must be robust and runnable. The objective is to minimize transmission errors (bugs) by treating runtime execution feedback as a corrective signal to iteratively refine the generated code.</p>
</div>
</li>
</ul>
</div>
<div class="ltx_para" id="S2.SS2.p4">
<p class="ltx_p">Our framework is designed to satisfy these objectives by explicitly routing and compressing information, enabling high-fidelity repository generation under strict context window constraints.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S3">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>The DeepCode Framework</h2>
<div class="ltx_para" id="S3.p1">
<p class="ltx_p">We introduce DeepCode, a multi-stage framework designed to instantiate the principle of principled information-flow management for repository-level synthesis. To solve the optimization problem, DeepCode decomposes the generation process into three orchestrated phases, each serving a distinct information-processing role to maximize the effective signal-to-noise ratio. The process initiates with <span class="ltx_text ltx_font_bold">(1) Blueprint Generation</span>, where a planning agent acts as a source compression mechanism, distilling the high-entropy source document <math alttext="\mathcal{D}" class="ltx_Math" display="inline" id="S3.p1.m1" intent=":literal"><semantics><mi class="ltx_font_mathcaligraphic">ğ’Ÿ</mi><annotation encoding="application/x-tex">\mathcal{D}</annotation></semantics></math> into a structured, high-signal implementation blueprint to extract critical constraints while filtering narrative noise. Guided by this blueprint, the subsequent <span class="ltx_text ltx_font_bold">(2) Code Generation</span> phase synthesizes source files while preventing channel saturation through two integrated mechanisms: a stateful Code Memory (CodeMem) that performs structured indexing of the evolving codebase to maintain cross-file consistency, and a CodeRAG system that performs conditional knowledge injection to bridge implicit domain gaps with standard implementation patterns. Finally, the framework concludes with <span class="ltx_text ltx_font_bold">(3) Automated Verification</span>, a closed-loop error correction phase where a validation agent treats runtime execution feedback as corrective signals to identify and rectify transmission errors, ensuring the functional correctness of the final output.</p>
</div>
<section class="ltx_subsection" id="S3.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Phase 1: Blueprint Generation</h3>
<div class="ltx_para" id="S3.SS1.p1">
<p class="ltx_p">The primary goal of the first phase is to perform source compression: distilling the unstructured, lengthy content of a source document (<span class="ltx_text ltx_font_italic">e</span>.<span class="ltx_text ltx_font_italic">g</span>.Â a scientific paper) into a structured, machine-readable implementation blueprint. This distillation process directly mitigates the challenges of information overload by transforming the raw input <math alttext="\mathcal{D}" class="ltx_Math" display="inline" id="S3.SS1.p1.m1" intent=":literal"><semantics><mi class="ltx_font_mathcaligraphic">ğ’Ÿ</mi><annotation encoding="application/x-tex">\mathcal{D}</annotation></semantics></math> into a high-density signal format. The process begins with a crucial preprocessing step: hierarchical content segmentation.</p>
</div>
<figure class="ltx_figure" id="S3.F3"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="342" id="S3.F3.g1" src="x3.png" width="660"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" style="font-size:90%;">Figure 3</span>: </span><span class="ltx_text" style="font-size:90%;">The overall framework of DeepCode.</span></figcaption>
</figure>
<section class="ltx_subsubsection" id="S3.SS1.SSS1">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.1.1 </span>Hierarchical Content Segmentation</h4>
<div class="ltx_para" id="S3.SS1.SSS1.p1">
<p class="ltx_p">Instead of feeding the entire document <math alttext="\mathcal{D}" class="ltx_Math" display="inline" id="S3.SS1.SSS1.p1.m1" intent=":literal"><semantics><mi class="ltx_font_mathcaligraphic">ğ’Ÿ</mi><annotation encoding="application/x-tex">\mathcal{D}</annotation></semantics></math> into an LLM, we first parse it into a structured representation that facilitates targeted information access. We introduce a <span class="ltx_text ltx_font_bold">hierarchical content index</span>, which leverages the inherent structure of academic papers and technical documents. The process is:</p>
</div>
<div class="ltx_para" id="S3.SS1.SSS1.p2">
<ol class="ltx_enumerate" id="S3.I1">
<li class="ltx_item" id="S3.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span>
<div class="ltx_para" id="S3.I1.i1.p1">
<p class="ltx_p"><span class="ltx_text ltx_font_bold">Structural Parsing:</span> The source document <math alttext="\mathcal{D}" class="ltx_Math" display="inline" id="S3.I1.i1.p1.m1" intent=":literal"><semantics><mi class="ltx_font_mathcaligraphic">ğ’Ÿ</mi><annotation encoding="application/x-tex">\mathcal{D}</annotation></semantics></math> is parsed to identify its hierarchical structure based on explicit delimiters like section and subsection titles (<span class="ltx_text ltx_font_italic">e</span>.<span class="ltx_text ltx_font_italic">g</span>.Â "3. Methodology", "3.1. Model Architecture"). This divides the document into a set of content chunks <math alttext="S=\{s_{1},s_{2},\dots,s_{K}\}" class="ltx_Math" display="inline" id="S3.I1.i1.p1.m2" intent=":literal"><semantics><mrow><mi>S</mi><mo>=</mo><mrow><mo stretchy="false">{</mo><msub><mi>s</mi><mn>1</mn></msub><mo>,</mo><msub><mi>s</mi><mn>2</mn></msub><mo>,</mo><mi mathvariant="normal">â€¦</mi><mo>,</mo><msub><mi>s</mi><mi>K</mi></msub><mo stretchy="false">}</mo></mrow></mrow><annotation encoding="application/x-tex">S=\{s_{1},s_{2},\dots,s_{K}\}</annotation></semantics></math>.</p>
</div>
</li>
<li class="ltx_item" id="S3.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span>
<div class="ltx_para" id="S3.I1.i2.p1">
<p class="ltx_p"><span class="ltx_text ltx_font_bold">Keyword-Chunk Association:</span> Each chunk <math alttext="s_{k}" class="ltx_Math" display="inline" id="S3.I1.i2.p1.m1" intent=":literal"><semantics><msub><mi>s</mi><mi>k</mi></msub><annotation encoding="application/x-tex">s_{k}</annotation></semantics></math> is stored as a key-value pair <math alttext="(h_{k},c_{k})" class="ltx_Math" display="inline" id="S3.I1.i2.p1.m2" intent=":literal"><semantics><mrow><mo stretchy="false">(</mo><msub><mi>h</mi><mi>k</mi></msub><mo>,</mo><msub><mi>c</mi><mi>k</mi></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(h_{k},c_{k})</annotation></semantics></math>, where the heading <math alttext="h_{k}" class="ltx_Math" display="inline" id="S3.I1.i2.p1.m3" intent=":literal"><semantics><msub><mi>h</mi><mi>k</mi></msub><annotation encoding="application/x-tex">h_{k}</annotation></semantics></math> serves as a natural, high-level semantic keyword, and <math alttext="c_{k}" class="ltx_Math" display="inline" id="S3.I1.i2.p1.m4" intent=":literal"><semantics><msub><mi>c</mi><mi>k</mi></msub><annotation encoding="application/x-tex">c_{k}</annotation></semantics></math> is the corresponding raw text content of that section.</p>
</div>
</li>
</ol>
</div>
<div class="ltx_para" id="S3.SS1.SSS1.p3">
<p class="ltx_p">This indexed structure effectively transforms the problem from one of long-context comprehension to a series of more manageable, on-demand retrievals. An agent no longer needs to process the entire document at once. Instead, it can query the index using semantic keywords (<span class="ltx_text ltx_font_italic">e</span>.<span class="ltx_text ltx_font_italic">g</span>.Â requesting the content associated with "Model Architecture") to fetch only the most relevant context for its current task. This approach drastically reduces the token load for any single operation and allows the model to focus its limited context window on the most pertinent information, thereby solving the problem of context overload and information forgetting. This structured representation serves as the foundational input for the specialized agents that perform the detailed analysis in the subsequent steps.</p>
</div>
</section>
<section class="ltx_subsubsection" id="S3.SS1.SSS2">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.1.2 </span>Multi-Agent Specification Analysis</h4>
<div class="ltx_para" id="S3.SS1.SSS2.p1">
<p class="ltx_p">Following the hierarchical segmentation, we employ a specialized multi-agent system to conduct a deep and structured analysis of the documentâ€™s content. This approach decomposes the complex comprehension task into two parallel tracks, executed by a <span class="ltx_text ltx_font_bold">Concept Agent</span> and an <span class="ltx_text ltx_font_bold">Algorithm Agent</span>. Each agent is equipped with a specific prompt and interacts with the indexed document to extract complementary layers of information, ensuring a comprehensive understanding without processing the entire document simultaneously.</p>
</div>
<div class="ltx_para" id="S3.SS1.SSS2.p2">
<p class="ltx_p"><span class="ltx_text ltx_font_bold">Concept Agent: High-Level Structural and Conceptual Mapping.</span>
The Concept Agent is tasked with building a holistic, high-level understanding of the document. Its primary objective is to map the paperâ€™s entire conceptual structure, identify its core scientific contributions, and outline the necessary components for a successful experimental reproduction. Operating on the indexed document, the agent is instructed to use a segmented reading strategy, querying the index with semantically broad keywords (<span class="ltx_text ltx_font_italic">e</span>.<span class="ltx_text ltx_font_italic">g</span>.Â â€œintroductionâ€, â€œmethodâ€). This allows it to assemble a comprehensive overview by strategically fetching relevant sections. The output of this agent is a structured <span class="ltx_text ltx_font_italic">Conceptual Analysis Schema</span>. This schema comprises a detailed paper structure map, a method decomposition map outlining the systemâ€™s core functional components, an implementation map aligning claims with code requirements, and a reproduction roadmap specifying the criteria for success. Collectively, these elements translate the paperâ€™s narrative into a structured project plan.</p>
</div>
<div class="ltx_para" id="S3.SS1.SSS2.p3">
<p class="ltx_p"><span class="ltx_text ltx_font_bold">Algorithm Agent: Low-Level Technical Detail Extraction.</span>
Complementing the conceptual overview, the Algorithm Agent is responsible for the meticulous extraction of every low-level technical detail required for an exact implementation. Itâ€™s designed to perform an exhaustive search for all algorithms, mathematical formulations, model architectures, training procedures, and hyperparameters. Moreover, it can leverage online search capabilities to retrieve relevant algorithm implementations from the web as references. Like the Concept Agent, it leverages the segmented reading strategy but uses a distinct set of highly specific keywords (<span class="ltx_text ltx_font_italic">e</span>.<span class="ltx_text ltx_font_italic">g</span>.Â â€œalgorithmâ€, â€œhyperparameterâ€) to perform targeted queries on the most technically dense sections of the document. The agentâ€™s output is a granular <span class="ltx_text ltx_font_italic">Algorithmic Implementation Schema</span>. This schema captures verbatim pseudocode from algorithm boxes, exact mathematical equations and their variables, detailed layer-by-layer network architectures, and a comprehensive list of all hyperparameters with references to their locations in the paper. This schema serves as a precise, unambiguous technical specification, designed to leave no detail to interpretation during the code generation phase.</p>
</div>
</section>
<section class="ltx_subsubsection" id="S3.SS1.SSS3">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.1.3 </span>Synthesizing the Implementation Blueprint</h4>
<div class="ltx_para" id="S3.SS1.SSS3.p1">
<p class="ltx_p">The analytical outputs from the Concept and Algorithm agents are then synthesized by the <span class="ltx_text ltx_font_bold">Code Planning Agent</span> into a single, holistic implementation blueprint. This agentâ€™s critical function is to orchestrate the high-level conceptual framework with the low-level technical specifications, performing a final disambiguation and grounding step. It reconciles the architectural overview with the granular implementation details, ensuring that every abstract component is directly linked to a precise technical specification. Should any inconsistencies arise, the agent is authorized to perform targeted queries on the indexed document to resolve them.
The final <span class="ltx_text ltx_font_bold">Implementation Blueprint</span> <math alttext="\mathcal{B}" class="ltx_Math" display="inline" id="S3.SS1.SSS3.p1.m1" intent=":literal"><semantics><mi class="ltx_font_mathcaligraphic">â„¬</mi><annotation encoding="application/x-tex">\mathcal{B}</annotation></semantics></math> is a structured intermediate representation designed to be a self-contained, unambiguous specification for code generation. This blueprint is organized into the following canonical sections:</p>
</div>
<div class="ltx_para" id="S3.SS1.SSS3.p2">
<ul class="ltx_itemize" id="S3.I2">
<li class="ltx_item" id="S3.I2.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span>
<div class="ltx_para" id="S3.I2.i1.p1">
<p class="ltx_p"><span class="ltx_text ltx_font_bold">Project File Hierarchy:</span> A prioritized project file structure that dictates the logical organization of the codebase and the implementation order of its modules.</p>
</div>
</li>
<li class="ltx_item" id="S3.I2.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span>
<div class="ltx_para" id="S3.I2.i2.p1">
<p class="ltx_p"><span class="ltx_text ltx_font_bold">Component Specification:</span> A granular specification for every module, class, and function, explicitly mapping each to its corresponding algorithmic pseudocode and mathematical formulation.</p>
</div>
</li>
<li class="ltx_item" id="S3.I2.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span>
<div class="ltx_para" id="S3.I2.i3.p1">
<p class="ltx_p"><span class="ltx_text ltx_font_bold">Verification Protocol:</span> A formal plan for validating the final implementation. It defines the experimental setup, specifies the target metrics from the source document, and establishes the success criteria for reproduction.</p>
</div>
</li>
<li class="ltx_item" id="S3.I2.i4" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span>
<div class="ltx_para" id="S3.I2.i4.p1">
<p class="ltx_p"><span class="ltx_text ltx_font_bold">Execution Environment:</span> A complete specification of all software dependencies, library versions, and requisite hardware configurations needed to compile and run the code.</p>
</div>
</li>
<li class="ltx_item" id="S3.I2.i5" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span>
<div class="ltx_para" id="S3.I2.i5.p1">
<p class="ltx_p"><span class="ltx_text ltx_font_bold">Staged Development Plan:</span> A phased implementation roadmap that defines the build order of components and integrates staged verification checks to ensure modular correctness.</p>
</div>
</li>
</ul>
</div>
<div class="ltx_para" id="S3.SS1.SSS3.p3">
<p class="ltx_p">By consolidating all distilled information into this canonical blueprint, the Code Planning Agent concludes the specification distillation phase. This artifact serves as the definitive "source of truth" for the subsequent code generation phase, effectively resolving the long-context challenge by providing a dense, structured, and actionable input that obviates any need for the coding agents to interact with the original, lengthy document.</p>
</div>
</section>
</section>
<section class="ltx_subsection" id="S3.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Phase 2: Code Generation</h3>
<div class="ltx_para" id="S3.SS2.p1">
<p class="ltx_p">Upon generating the high-signal blueprint, the second phase synthesizes the code repository. This phase maximizes the density of relevant context while preventing channel saturation caused by the accumulation of raw code history. A naive iterative approach, which appends previously generated code to the prompt, leads to a collapse in the signal-to-noise ratio and induces hallucinations. To overcome this, we propose a dual-mechanism strategy for efficient information routing: (1) a stateful <span class="ltx_text ltx_font_bold">CodeMem</span> that performs structured indexing of the evolving repository to maintain internal structural cohesion without context bloat, and (2) a <span class="ltx_text ltx_font_bold">CodeRAG</span> system that performs conditional knowledge injection, grounding the implementation in external patterns to bridge implicit knowledge gaps.</p>
</div>
<section class="ltx_subsubsection" id="S3.SS2.SSS1">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.2.1 </span>Stateful Generation with CodeMem</h4>
<div class="ltx_para" id="S3.SS2.SSS1.p1">
<p class="ltx_p">The core of our generation process is the Code Memory mechanism, a strategy designed to maintain a compressed, structured representation of the repositoryâ€™s state, thereby ensuring cross-file consistency without suffering from prohibitive context lengths. Instead of passing the full source code of previously implemented files to the generative agent, we iteratively build and query a structured memory bank, <math alttext="\mathcal{M}" class="ltx_Math" display="inline" id="S3.SS2.SSS1.p1.m1" intent=":literal"><semantics><mi class="ltx_font_mathcaligraphic">â„³</mi><annotation encoding="application/x-tex">\mathcal{M}</annotation></semantics></math>.</p>
</div>
<div class="ltx_para" id="S3.SS2.SSS1.p2">
<p class="ltx_p">Let the set of all files to be implemented, as defined by Sec.Â <a class="ltx_ref" href="https://arxiv.org/html/2512.07921v1#S2" title="2 Preliminary â€£ DeepCode: Open Agentic Coding"><span class="ltx_text ltx_ref_tag">2</span></a>, be <math alttext="\mathcal{C}=\{c_{1},c_{2},\dots,c_{N}\}" class="ltx_Math" display="inline" id="S3.SS2.SSS1.p2.m1" intent=":literal"><semantics><mrow><mi class="ltx_font_mathcaligraphic">ğ’</mi><mo>=</mo><mrow><mo stretchy="false">{</mo><msub><mi>c</mi><mn>1</mn></msub><mo>,</mo><msub><mi>c</mi><mn>2</mn></msub><mo>,</mo><mi mathvariant="normal">â€¦</mi><mo>,</mo><msub><mi>c</mi><mi>N</mi></msub><mo stretchy="false">}</mo></mrow></mrow><annotation encoding="application/x-tex">\mathcal{C}=\{c_{1},c_{2},\dots,c_{N}\}</annotation></semantics></math>. The generation process is an iterative loop over <math alttext="t=1,\dots,N" class="ltx_Math" display="inline" id="S3.SS2.SSS1.p2.m2" intent=":literal"><semantics><mrow><mi>t</mi><mo>=</mo><mrow><mn>1</mn><mo>,</mo><mi mathvariant="normal">â€¦</mi><mo>,</mo><mi>N</mi></mrow></mrow><annotation encoding="application/x-tex">t=1,\dots,N</annotation></semantics></math>. At each step <math alttext="t" class="ltx_Math" display="inline" id="S3.SS2.SSS1.p2.m3" intent=":literal"><semantics><mi>t</mi><annotation encoding="application/x-tex">t</annotation></semantics></math>, we maintain the set of implemented files, <math alttext="\mathcal{C}_{t-1}" class="ltx_Math" display="inline" id="S3.SS2.SSS1.p2.m4" intent=":literal"><semantics><msub><mi class="ltx_font_mathcaligraphic">ğ’</mi><mrow><mi>t</mi><mo>âˆ’</mo><mn>1</mn></mrow></msub><annotation encoding="application/x-tex">\mathcal{C}_{t-1}</annotation></semantics></math>, and the set of unimplemented files, <math alttext="\mathcal{U}_{t-1}" class="ltx_Math" display="inline" id="S3.SS2.SSS1.p2.m5" intent=":literal"><semantics><msub><mi class="ltx_font_mathcaligraphic">ğ’°</mi><mrow><mi>t</mi><mo>âˆ’</mo><mn>1</mn></mrow></msub><annotation encoding="application/x-tex">\mathcal{U}_{t-1}</annotation></semantics></math>. The process for generating the target file for the current step, <math alttext="\hat{c}_{t}" class="ltx_Math" display="inline" id="S3.SS2.SSS1.p2.m6" intent=":literal"><semantics><msub><mover accent="true"><mi>c</mi><mo>^</mo></mover><mi>t</mi></msub><annotation encoding="application/x-tex">\hat{c}_{t}</annotation></semantics></math>, is as follows:</p>
</div>
<div class="ltx_para" id="S3.SS2.SSS1.p3">
<ol class="ltx_enumerate" id="S3.I3">
<li class="ltx_item" id="S3.I3.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span>
<div class="ltx_para" id="S3.I3.i1.p1">
<p class="ltx_p"><span class="ltx_text ltx_font_bold">Context Formulation.</span> The generation context for the current step, <math alttext="\mathcal{X}_{t}" class="ltx_Math" display="inline" id="S3.I3.i1.p1.m1" intent=":literal"><semantics><msub><mi class="ltx_font_mathcaligraphic">ğ’³</mi><mi>t</mi></msub><annotation encoding="application/x-tex">\mathcal{X}_{t}</annotation></semantics></math>, is constructed not from raw source code, but from the static implementation blueprint <math alttext="\mathcal{B}" class="ltx_Math" display="inline" id="S3.I3.i1.p1.m2" intent=":literal"><semantics><mi class="ltx_font_mathcaligraphic">â„¬</mi><annotation encoding="application/x-tex">\mathcal{B}</annotation></semantics></math> and a dynamically selected subset of the Code Memory, <math alttext="\mathcal{M}_{t-1}" class="ltx_Math" display="inline" id="S3.I3.i1.p1.m3" intent=":literal"><semantics><msub><mi class="ltx_font_mathcaligraphic">â„³</mi><mrow><mi>t</mi><mo>âˆ’</mo><mn>1</mn></mrow></msub><annotation encoding="application/x-tex">\mathcal{M}_{t-1}</annotation></semantics></math>. The agent first identifies which previously implemented files are relevant to the current target file <math alttext="\hat{c}_{t}" class="ltx_Math" display="inline" id="S3.I3.i1.p1.m4" intent=":literal"><semantics><msub><mover accent="true"><mi>c</mi><mo>^</mo></mover><mi>t</mi></msub><annotation encoding="application/x-tex">\hat{c}_{t}</annotation></semantics></math> (where <math alttext="\hat{c}_{t}" class="ltx_Math" display="inline" id="S3.I3.i1.p1.m5" intent=":literal"><semantics><msub><mover accent="true"><mi>c</mi><mo>^</mo></mover><mi>t</mi></msub><annotation encoding="application/x-tex">\hat{c}_{t}</annotation></semantics></math> denotes the blank code file to be generated, and <math alttext="c_{t}" class="ltx_Math" display="inline" id="S3.I3.i1.p1.m6" intent=":literal"><semantics><msub><mi>c</mi><mi>t</mi></msub><annotation encoding="application/x-tex">c_{t}</annotation></semantics></math> denotes the resulting generated code file). It then retrieves only their corresponding summaries from the memory bank:</p>
<table class="ltx_equation ltx_eqn_table" id="S3.E4">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\mathcal{X}_{t}=\left(\mathcal{B},\text{SelectRelevantMemory}(\mathcal{M}_{t-1},\hat{c}_{t})\right)" class="ltx_Math" display="block" id="S3.E4.m1" intent=":literal"><semantics><mrow><msub><mi class="ltx_font_mathcaligraphic">ğ’³</mi><mi>t</mi></msub><mo>=</mo><mrow><mo>(</mo><mi class="ltx_font_mathcaligraphic">â„¬</mi><mo>,</mo><mrow><mtext>SelectRelevantMemory</mtext><mo lspace="0em" rspace="0em">â€‹</mo><mrow><mo stretchy="false">(</mo><msub><mi class="ltx_font_mathcaligraphic">â„³</mi><mrow><mi>t</mi><mo>âˆ’</mo><mn>1</mn></mrow></msub><mo>,</mo><msub><mover accent="true"><mi>c</mi><mo>^</mo></mover><mi>t</mi></msub><mo stretchy="false">)</mo></mrow></mrow><mo>)</mo></mrow></mrow><annotation encoding="application/x-tex">\mathcal{X}_{t}=\left(\mathcal{B},\text{SelectRelevantMemory}(\mathcal{M}_{t-1},\hat{c}_{t})\right)</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(4)</span></td>
</tr></tbody>
</table>
<p class="ltx_p">where <span class="ltx_text ltx_markedasmath">SelectRelevantMemory</span> is a function that queries <math alttext="\mathcal{M}_{t-1}" class="ltx_Math" display="inline" id="S3.I3.i1.p1.m8" intent=":literal"><semantics><msub><mi class="ltx_font_mathcaligraphic">â„³</mi><mrow><mi>t</mi><mo>âˆ’</mo><mn>1</mn></mrow></msub><annotation encoding="application/x-tex">\mathcal{M}_{t-1}</annotation></semantics></math> to fetch only the essential summaries of dependencies.</p>
</div>
</li>
<li class="ltx_item" id="S3.I3.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span>
<div class="ltx_para" id="S3.I3.i2.p1">
<p class="ltx_p"><span class="ltx_text ltx_font_bold">Code Generation.</span> The coding agent, represented by the LLM function <math alttext="\mathcal{L}" class="ltx_Math" display="inline" id="S3.I3.i2.p1.m1" intent=":literal"><semantics><mi class="ltx_font_mathcaligraphic">â„’</mi><annotation encoding="application/x-tex">\mathcal{L}</annotation></semantics></math>, synthesizes the source code for the target file based on the curated context:</p>
<table class="ltx_equation ltx_eqn_table" id="S3.E5">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="c_{t}=\mathcal{L}(\mathcal{X}_{t})" class="ltx_Math" display="block" id="S3.E5.m1" intent=":literal"><semantics><mrow><msub><mi>c</mi><mi>t</mi></msub><mo>=</mo><mrow><mi class="ltx_font_mathcaligraphic">â„’</mi><mo lspace="0em" rspace="0em">â€‹</mo><mrow><mo stretchy="false">(</mo><msub><mi class="ltx_font_mathcaligraphic">ğ’³</mi><mi>t</mi></msub><mo stretchy="false">)</mo></mrow></mrow></mrow><annotation encoding="application/x-tex">c_{t}=\mathcal{L}(\mathcal{X}_{t})</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(5)</span></td>
</tr></tbody>
</table>
</div>
</li>
<li class="ltx_item" id="S3.I3.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">3.</span>
<div class="ltx_para" id="S3.I3.i3.p1">
<p class="ltx_p"><span class="ltx_text ltx_font_bold">Memory Update.</span> After generating the code <math alttext="c_{t}" class="ltx_Math" display="inline" id="S3.I3.i3.p1.m1" intent=":literal"><semantics><msub><mi>c</mi><mi>t</mi></msub><annotation encoding="application/x-tex">c_{t}</annotation></semantics></math>, the system clears the generation context. A specialized summarization agent, <math alttext="\mathcal{S}" class="ltx_Math" display="inline" id="S3.I3.i3.p1.m2" intent=":literal"><semantics><mi class="ltx_font_mathcaligraphic">ğ’®</mi><annotation encoding="application/x-tex">\mathcal{S}</annotation></semantics></math>, is then invoked. This agent analyzes the newly generated source code <math alttext="c_{t}" class="ltx_Math" display="inline" id="S3.I3.i3.p1.m3" intent=":literal"><semantics><msub><mi>c</mi><mi>t</mi></msub><annotation encoding="application/x-tex">c_{t}</annotation></semantics></math> to extract its structural essence and create a new memory entry, <math alttext="m_{t}" class="ltx_Math" display="inline" id="S3.I3.i3.p1.m4" intent=":literal"><semantics><msub><mi>m</mi><mi>t</mi></msub><annotation encoding="application/x-tex">m_{t}</annotation></semantics></math>. The Code Memory is then updated:</p>
<table class="ltx_equation ltx_eqn_table" id="S3.E6">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\mathcal{M}_{t}=\mathcal{M}_{t-1}\cup\{m_{t}\}" class="ltx_Math" display="block" id="S3.E6.m1" intent=":literal"><semantics><mrow><msub><mi class="ltx_font_mathcaligraphic">â„³</mi><mi>t</mi></msub><mo>=</mo><mrow><msub><mi class="ltx_font_mathcaligraphic">â„³</mi><mrow><mi>t</mi><mo>âˆ’</mo><mn>1</mn></mrow></msub><mo>âˆª</mo><mrow><mo stretchy="false">{</mo><msub><mi>m</mi><mi>t</mi></msub><mo stretchy="false">}</mo></mrow></mrow></mrow><annotation encoding="application/x-tex">\mathcal{M}_{t}=\mathcal{M}_{t-1}\cup\{m_{t}\}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(6)</span></td>
</tr></tbody>
</table>
</div>
</li>
</ol>
</div>
<div class="ltx_para" id="S3.SS2.SSS1.p4">
<p class="ltx_p">The summarization agent <math alttext="\mathcal{S}" class="ltx_Math" display="inline" id="S3.SS2.SSS1.p4.m1" intent=":literal"><semantics><mi class="ltx_font_mathcaligraphic">ğ’®</mi><annotation encoding="application/x-tex">\mathcal{S}</annotation></semantics></math> distills the code into a structured format that captures all information necessary for inter-module communication. Each memory entry <math alttext="m_{t}" class="ltx_Math" display="inline" id="S3.SS2.SSS1.p4.m2" intent=":literal"><semantics><msub><mi>m</mi><mi>t</mi></msub><annotation encoding="application/x-tex">m_{t}</annotation></semantics></math> is a structured object containing:</p>
</div>
<div class="ltx_para" id="S3.SS2.SSS1.p5">
<ul class="ltx_itemize" id="S3.I4">
<li class="ltx_item" id="S3.I4.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span>
<div class="ltx_para" id="S3.I4.i1.p1">
<p class="ltx_p"><span class="ltx_text ltx_font_bold">Core Purpose (<math alttext="\mathcal{P}_{t}" class="ltx_Math" display="inline" id="S3.I4.i1.p1.m1" intent=":literal"><semantics><msub><mi class="ltx_font_mathcaligraphic">ğ’«</mi><mi>t</mi></msub><annotation encoding="application/x-tex">\mathcal{P}_{t}</annotation></semantics></math>):</span> A concise, natural language summary of the fileâ€™s primary responsibility and role within the repository.</p>
</div>
</li>
<li class="ltx_item" id="S3.I4.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span>
<div class="ltx_para" id="S3.I4.i2.p1">
<p class="ltx_p"><span class="ltx_text ltx_font_bold">Public Interface (<math alttext="\mathcal{I}_{t}" class="ltx_Math" display="inline" id="S3.I4.i2.p1.m1" intent=":literal"><semantics><msub><mi class="ltx_font_mathcaligraphic">â„</mi><mi>t</mi></msub><annotation encoding="application/x-tex">\mathcal{I}_{t}</annotation></semantics></math>):</span> A formal description of all externally accessible classes, functions, and constants, including their signatures and purposes (e.g., Class(params): methods).</p>
</div>
</li>
<li class="ltx_item" id="S3.I4.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span>
<div class="ltx_para" id="S3.I4.i3.p1">
<p class="ltx_p"><span class="ltx_text ltx_font_bold">Dependency Edges (<math alttext="\mathcal{E}_{t}" class="ltx_Math" display="inline" id="S3.I4.i3.p1.m1" intent=":literal"><semantics><msub><mi class="ltx_font_mathcaligraphic">â„°</mi><mi>t</mi></msub><annotation encoding="application/x-tex">\mathcal{E}_{t}</annotation></semantics></math>):</span> A comprehensive map of the fileâ€™s position within the projectâ€™s dependency graph. This structured entry specifies both <span class="ltx_text ltx_font_bold">afferent couplings</span> (internal dependencies), detailing the specific imports from other project modules and external packages, and predicted <span class="ltx_text ltx_font_bold">efferent couplings</span> (external dependencies), identifying which unimplemented modules are expected to consume this fileâ€™s public interface.</p>
</div>
</li>
<li class="ltx_item" id="S3.I4.i4" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span>
<div class="ltx_para" id="S3.I4.i4.p1">
<p class="ltx_p"><span class="ltx_text ltx_font_bold">Next Implementation Target (<math alttext="\hat{c}_{t+1}" class="ltx_Math" display="inline" id="S3.I4.i4.p1.m1" intent=":literal"><semantics><msub><mover accent="true"><mi>c</mi><mo>^</mo></mover><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow></msub><annotation encoding="application/x-tex">\hat{c}_{t+1}</annotation></semantics></math>):</span> A decision on the next file to be implemented, based on the blueprint, dependency graph and the current state. Note that, to avoid introducing noise into the memory, this information is separated from <math alttext="m_{t}" class="ltx_Math" display="inline" id="S3.I4.i4.p1.m2" intent=":literal"><semantics><msub><mi>m</mi><mi>t</mi></msub><annotation encoding="application/x-tex">m_{t}</annotation></semantics></math> and provided independently as part of <math alttext="\mathcal{L}" class="ltx_Math" display="inline" id="S3.I4.i4.p1.m3" intent=":literal"><semantics><mi class="ltx_font_mathcaligraphic">â„’</mi><annotation encoding="application/x-tex">\mathcal{L}</annotation></semantics></math> input.</p>
</div>
</li>
</ul>
</div>
<div class="ltx_para" id="S3.SS2.SSS1.p6">
<p class="ltx_p">This mechanism effectively decouples the context size from the repository size. The context provided to the agent at any step <math alttext="t" class="ltx_Math" display="inline" id="S3.SS2.SSS1.p6.m1" intent=":literal"><semantics><mi>t</mi><annotation encoding="application/x-tex">t</annotation></semantics></math> remains compact, containing only the high-level blueprint and the highly compressed summaries of relevant, already-implemented files. This stateful, summary-based approach allows our system to maintain global consistency and logical cohesion across a large number of files, directly solving the long-context and cross-file consistency challenges.</p>
</div>
</section>
<section class="ltx_subsubsection" id="S3.SS2.SSS2">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.2.2 </span>Knowledge Grounding with CodeRAG</h4>
<div class="ltx_para" id="S3.SS2.SSS2.p1">
<p class="ltx_p">While the Code Memory mechanism ensures internal consistency, it does not address the challenges of model hallucination or the omission of implicit domain knowledge. To mitigate these issues, we introduce a retrieval-augmented generation framework, <span class="ltx_text ltx_font_bold">CodeRAG</span>, which grounds the synthesis process in a pre-indexed corpus of relevant, high-quality code repositories. This process is divided into two stages: an indexing phase and an adaptive retrieval phase during code generation.</p>
</div>
<div class="ltx_para" id="S3.SS2.SSS2.p2">
<p class="ltx_p"><span class="ltx_text ltx_font_bold">Repository Indexing.</span>
The goal of this phase is to analyze a set of relevant source code repositories, <math alttext="\mathcal{R}=\{R_{1},R_{2},\dots,R_{K}\}" class="ltx_Math" display="inline" id="S3.SS2.SSS2.p2.m1" intent=":literal"><semantics><mrow><mi class="ltx_font_mathcaligraphic">â„›</mi><mo>=</mo><mrow><mo stretchy="false">{</mo><msub><mi>R</mi><mn>1</mn></msub><mo>,</mo><msub><mi>R</mi><mn>2</mn></msub><mo>,</mo><mi mathvariant="normal">â€¦</mi><mo>,</mo><msub><mi>R</mi><mi>K</mi></msub><mo stretchy="false">}</mo></mrow></mrow><annotation encoding="application/x-tex">\mathcal{R}=\{R_{1},R_{2},\dots,R_{K}\}</annotation></semantics></math>, and build a structured, queryable index, <math alttext="\mathcal{J}" class="ltx_Math" display="inline" id="S3.SS2.SSS2.p2.m2" intent=":literal"><semantics><mi class="ltx_font_mathcaligraphic">ğ’¥</mi><annotation encoding="application/x-tex">\mathcal{J}</annotation></semantics></math>. The process, modeled by <math alttext="\mathcal{I}_{\text{index}}:\mathcal{R}\times\mathcal{B}\rightarrow\mathcal{J}" class="ltx_Math" display="inline" id="S3.SS2.SSS2.p2.m3" intent=":literal"><semantics><mrow><msub><mi class="ltx_font_mathcaligraphic">â„</mi><mtext>index</mtext></msub><mo lspace="0.278em" rspace="0.278em">:</mo><mrow><mrow><mi class="ltx_font_mathcaligraphic">â„›</mi><mo lspace="0.222em" rspace="0.222em">Ã—</mo><mi class="ltx_font_mathcaligraphic">â„¬</mi></mrow><mo stretchy="false">â†’</mo><mi class="ltx_font_mathcaligraphic">ğ’¥</mi></mrow></mrow><annotation encoding="application/x-tex">\mathcal{I}_{\text{index}}:\mathcal{R}\times\mathcal{B}\rightarrow\mathcal{J}</annotation></semantics></math>, consists of the following steps:</p>
</div>
<div class="ltx_para" id="S3.SS2.SSS2.p3">
<ol class="ltx_enumerate" id="S3.I5">
<li class="ltx_item" id="S3.I5.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span>
<div class="ltx_para" id="S3.I5.i1.p1">
<p class="ltx_p"><span class="ltx_text ltx_font_bold">Relevance Filtering:</span> For each repository <math alttext="R_{k}\in\mathcal{R}" class="ltx_Math" display="inline" id="S3.I5.i1.p1.m1" intent=":literal"><semantics><mrow><msub><mi>R</mi><mi>k</mi></msub><mo>âˆˆ</mo><mi class="ltx_font_mathcaligraphic">â„›</mi></mrow><annotation encoding="application/x-tex">R_{k}\in\mathcal{R}</annotation></semantics></math>, we perform an initial LLM-based filtering to identify a subset of source files, <math alttext="\mathcal{C}^{\prime}_{k}\subset R_{k}" class="ltx_Math" display="inline" id="S3.I5.i1.p1.m2" intent=":literal"><semantics><mrow><msubsup><mi class="ltx_font_mathcaligraphic">ğ’</mi><mi>k</mi><mo>â€²</mo></msubsup><mo>âŠ‚</mo><msub><mi>R</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">\mathcal{C}^{\prime}_{k}\subset R_{k}</annotation></semantics></math>, that are most relevant to the target project structure defined in the implementation blueprint <math alttext="\mathcal{B}" class="ltx_Math" display="inline" id="S3.I5.i1.p1.m3" intent=":literal"><semantics><mi class="ltx_font_mathcaligraphic">â„¬</mi><annotation encoding="application/x-tex">\mathcal{B}</annotation></semantics></math>. In this context, <math alttext="\mathcal{R}" class="ltx_Math" display="inline" id="S3.I5.i1.p1.m4" intent=":literal"><semantics><mi class="ltx_font_mathcaligraphic">â„›</mi><annotation encoding="application/x-tex">\mathcal{R}</annotation></semantics></math> can denote either the corresponding repository cited in the references of the target paper or other relevant repositories identified through online search. This focuses computational resources on the most promising assets.</p>
</div>
</li>
<li class="ltx_item" id="S3.I5.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span>
<div class="ltx_para" id="S3.I5.i2.p1">
<p class="ltx_p"><span class="ltx_text ltx_font_bold">Code Understanding:</span> Each relevant source file <math alttext="c_{s}^{\prime}\in\mathcal{C}^{\prime}_{k}" class="ltx_Math" display="inline" id="S3.I5.i2.p1.m1" intent=":literal"><semantics><mrow><msubsup><mi>c</mi><mi>s</mi><mo>â€²</mo></msubsup><mo>âˆˆ</mo><msubsup><mi class="ltx_font_mathcaligraphic">ğ’</mi><mi>k</mi><mo>â€²</mo></msubsup></mrow><annotation encoding="application/x-tex">c_{s}^{\prime}\in\mathcal{C}^{\prime}_{k}</annotation></semantics></math> is independently analyzed to create a structured summary, analogous to the memory entries described previously. This summary captures the fileâ€™s purpose, key concepts, and public interfaces.</p>
</div>
</li>
<li class="ltx_item" id="S3.I5.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">3.</span>
<div class="ltx_para" id="S3.I5.i3.p1">
<p class="ltx_p"><span class="ltx_text ltx_font_bold">Relationship Mapping:</span> The core of the indexing process is to establish explicit links between the analyzed source files and the target files in our blueprint. For each source file summary, an agent maps it to one or more target files in <math alttext="\mathcal{B}" class="ltx_Math" display="inline" id="S3.I5.i3.p1.m1" intent=":literal"><semantics><mi class="ltx_font_mathcaligraphic">â„¬</mi><annotation encoding="application/x-tex">\mathcal{B}</annotation></semantics></math>, generating a set of relationship tuples.</p>
</div>
</li>
</ol>
</div>
<div class="ltx_para" id="S3.SS2.SSS2.p4">
<p class="ltx_p">The final output index <math alttext="\mathcal{J}" class="ltx_Math" display="inline" id="S3.SS2.SSS2.p4.m1" intent=":literal"><semantics><mi class="ltx_font_mathcaligraphic">ğ’¥</mi><annotation encoding="application/x-tex">\mathcal{J}</annotation></semantics></math> is a structured knowledge base containing a collection of relationship tuples. Each tuple is defined as <math alttext="(c_{s}^{\prime},\hat{c_{t}},\tau,\sigma,\gamma)" class="ltx_Math" display="inline" id="S3.SS2.SSS2.p4.m2" intent=":literal"><semantics><mrow><mo stretchy="false">(</mo><msubsup><mi>c</mi><mi>s</mi><mo>â€²</mo></msubsup><mo>,</mo><mover accent="true"><msub><mi>c</mi><mi>t</mi></msub><mo>^</mo></mover><mo>,</mo><mi>Ï„</mi><mo>,</mo><mi>Ïƒ</mi><mo>,</mo><mi>Î³</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(c_{s}^{\prime},\hat{c_{t}},\tau,\sigma,\gamma)</annotation></semantics></math>. Here, <math alttext="c_{s}^{\prime}" class="ltx_Math" display="inline" id="S3.SS2.SSS2.p4.m3" intent=":literal"><semantics><msubsup><mi>c</mi><mi>s</mi><mo>â€²</mo></msubsup><annotation encoding="application/x-tex">c_{s}^{\prime}</annotation></semantics></math> is a file in the source repository and <math alttext="\hat{c_{t}}" class="ltx_Math" display="inline" id="S3.SS2.SSS2.p4.m4" intent=":literal"><semantics><mover accent="true"><msub><mi>c</mi><mi>t</mi></msub><mo>^</mo></mover><annotation encoding="application/x-tex">\hat{c_{t}}</annotation></semantics></math> is the corresponding target file in the blueprintâ€™s structure.
<math alttext="\mathbf{\tau}" class="ltx_Math" display="inline" id="S3.SS2.SSS2.p4.m5" intent=":literal"><semantics><mi>Ï„</mi><annotation encoding="application/x-tex">\mathbf{\tau}</annotation></semantics></math> denotes the relationship type, indicating the nature of the potential contribution, while <math alttext="\mathbf{\sigma}" class="ltx_Math" display="inline" id="S3.SS2.SSS2.p4.m6" intent=":literal"><semantics><mi>Ïƒ</mi><annotation encoding="application/x-tex">\mathbf{\sigma}</annotation></semantics></math> is a confidence score representing the strength of the mapping.
<math alttext="\mathbf{\gamma}" class="ltx_Math" display="inline" id="S3.SS2.SSS2.p4.m7" intent=":literal"><semantics><mi>Î³</mi><annotation encoding="application/x-tex">\mathbf{\gamma}</annotation></semantics></math> is a set of actionable context, such as helpful code snippets, usage suggestions, and implementation patterns.</p>
</div>
<div class="ltx_para" id="S3.SS2.SSS2.p5">
<p class="ltx_p"><span class="ltx_text ltx_font_bold">Adaptive Retrieval.</span>
During the iterative code generation phase, our framework will optionally query the CodeRAG index <math alttext="\mathcal{J}" class="ltx_Math" display="inline" id="S3.SS2.SSS2.p5.m1" intent=":literal"><semantics><mi class="ltx_font_mathcaligraphic">ğ’¥</mi><annotation encoding="application/x-tex">\mathcal{J}</annotation></semantics></math> to augment its context. At each generation step <math alttext="t" class="ltx_Math" display="inline" id="S3.SS2.SSS2.p5.m2" intent=":literal"><semantics><mi>t</mi><annotation encoding="application/x-tex">t</annotation></semantics></math> for a target file <math alttext="\hat{c_{t}}" class="ltx_Math" display="inline" id="S3.SS2.SSS2.p5.m3" intent=":literal"><semantics><mover accent="true"><msub><mi>c</mi><mi>t</mi></msub><mo>^</mo></mover><annotation encoding="application/x-tex">\hat{c_{t}}</annotation></semantics></math>, the agent makes an adaptive decision on whether to retrieve external knowledge. This decision is modeled by a binary function <math alttext="\delta" class="ltx_Math" display="inline" id="S3.SS2.SSS2.p5.m4" intent=":literal"><semantics><mi>Î´</mi><annotation encoding="application/x-tex">\delta</annotation></semantics></math>:</p>
<table class="ltx_equation ltx_eqn_table" id="S3.E7">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="r_{t}=\delta(\mathcal{X}_{t},\hat{c_{t}})" class="ltx_Math" display="block" id="S3.E7.m1" intent=":literal"><semantics><mrow><msub><mi>r</mi><mi>t</mi></msub><mo>=</mo><mrow><mi>Î´</mi><mo lspace="0em" rspace="0em">â€‹</mo><mrow><mo stretchy="false">(</mo><msub><mi class="ltx_font_mathcaligraphic">ğ’³</mi><mi>t</mi></msub><mo>,</mo><mover accent="true"><msub><mi>c</mi><mi>t</mi></msub><mo>^</mo></mover><mo stretchy="false">)</mo></mrow></mrow></mrow><annotation encoding="application/x-tex">r_{t}=\delta(\mathcal{X}_{t},\hat{c_{t}})</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(7)</span></td>
</tr></tbody>
</table>
<p class="ltx_p">where flag <math alttext="r_{t}\in\{0,1\}" class="ltx_Math" display="inline" id="S3.SS2.SSS2.p5.m5" intent=":literal"><semantics><mrow><msub><mi>r</mi><mi>t</mi></msub><mo>âˆˆ</mo><mrow><mo stretchy="false">{</mo><mn>0</mn><mo>,</mo><mn>1</mn><mo stretchy="false">}</mo></mrow></mrow><annotation encoding="application/x-tex">r_{t}\in\{0,1\}</annotation></semantics></math> and <math alttext="\mathcal{X}_{t}" class="ltx_Math" display="inline" id="S3.SS2.SSS2.p5.m6" intent=":literal"><semantics><msub><mi class="ltx_font_mathcaligraphic">ğ’³</mi><mi>t</mi></msub><annotation encoding="application/x-tex">\mathcal{X}_{t}</annotation></semantics></math> is the standard context containing the blueprint and relevant code memory. The decision is based on the complexity of the target file and the level of detail available in the blueprint.
If <math alttext="r_{t}=1" class="ltx_Math" display="inline" id="S3.SS2.SSS2.p5.m7" intent=":literal"><semantics><mrow><msub><mi>r</mi><mi>t</mi></msub><mo>=</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">r_{t}=1</annotation></semantics></math>, the agent queries the index <math alttext="\mathcal{J}" class="ltx_Math" display="inline" id="S3.SS2.SSS2.p5.m8" intent=":literal"><semantics><mi class="ltx_font_mathcaligraphic">ğ’¥</mi><annotation encoding="application/x-tex">\mathcal{J}</annotation></semantics></math> to find the most relevant relationship tuples for <math alttext="\hat{c_{t}}" class="ltx_Math" display="inline" id="S3.SS2.SSS2.p5.m9" intent=":literal"><semantics><mover accent="true"><msub><mi>c</mi><mi>t</mi></msub><mo>^</mo></mover><annotation encoding="application/x-tex">\hat{c_{t}}</annotation></semantics></math>. The retrieved context <math alttext="\gamma" class="ltx_Math" display="inline" id="S3.SS2.SSS2.p5.m10" intent=":literal"><semantics><mi>Î³</mi><annotation encoding="application/x-tex">\gamma</annotation></semantics></math> from the highest-confidence relationship is used to create an augmented context, <math alttext="\mathcal{X}^{\prime}_{t}" class="ltx_Math" display="inline" id="S3.SS2.SSS2.p5.m11" intent=":literal"><semantics><msubsup><mi class="ltx_font_mathcaligraphic">ğ’³</mi><mi>t</mi><mo>â€²</mo></msubsup><annotation encoding="application/x-tex">\mathcal{X}^{\prime}_{t}</annotation></semantics></math>:</p>
<table class="ltx_equation ltx_eqn_table" id="S3.E8">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\mathcal{X}^{\prime}_{t}=\mathcal{X}_{t}\cup\{\text{Retrieve}(\mathcal{J},\hat{c_{t}})\}" class="ltx_Math" display="block" id="S3.E8.m1" intent=":literal"><semantics><mrow><msubsup><mi class="ltx_font_mathcaligraphic">ğ’³</mi><mi>t</mi><mo>â€²</mo></msubsup><mo>=</mo><mrow><msub><mi class="ltx_font_mathcaligraphic">ğ’³</mi><mi>t</mi></msub><mo>âˆª</mo><mrow><mo stretchy="false">{</mo><mrow><mtext>Retrieve</mtext><mo lspace="0em" rspace="0em">â€‹</mo><mrow><mo stretchy="false">(</mo><mi class="ltx_font_mathcaligraphic">ğ’¥</mi><mo>,</mo><mover accent="true"><msub><mi>c</mi><mi>t</mi></msub><mo>^</mo></mover><mo stretchy="false">)</mo></mrow></mrow><mo stretchy="false">}</mo></mrow></mrow></mrow><annotation encoding="application/x-tex">\mathcal{X}^{\prime}_{t}=\mathcal{X}_{t}\cup\{\text{Retrieve}(\mathcal{J},\hat{c_{t}})\}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(8)</span></td>
</tr></tbody>
</table>
<p class="ltx_p">The final code is then generated using this enriched context: <math alttext="c_{t}=\mathcal{L}(\mathcal{X}^{\prime}_{t})" class="ltx_Math" display="inline" id="S3.SS2.SSS2.p5.m12" intent=":literal"><semantics><mrow><msub><mi>c</mi><mi>t</mi></msub><mo>=</mo><mrow><mi class="ltx_font_mathcaligraphic">â„’</mi><mo lspace="0em" rspace="0em">â€‹</mo><mrow><mo stretchy="false">(</mo><msubsup><mi class="ltx_font_mathcaligraphic">ğ’³</mi><mi>t</mi><mo>â€²</mo></msubsup><mo stretchy="false">)</mo></mrow></mrow></mrow><annotation encoding="application/x-tex">c_{t}=\mathcal{L}(\mathcal{X}^{\prime}_{t})</annotation></semantics></math>. By dynamically incorporating proven implementation patterns from existing repositories, CodeRAG significantly reduces the likelihood of generating erroneous or suboptimal code, thus bridging the knowledge gap for the generative agent.</p>
</div>
</section>
</section>
<section class="ltx_subsection" id="S3.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.3 </span>Phase 3: Automated Verification and Refinement</h3>
<div class="ltx_para" id="S3.SS3.p1">
<p class="ltx_p">The final phase serves as an error correction mechanism to ensure the functional faithfulness of the synthesized repository <math alttext="\mathcal{P}" class="ltx_Math" display="inline" id="S3.SS3.p1.m1" intent=":literal"><semantics><mi class="ltx_font_mathcaligraphic">ğ’«</mi><annotation encoding="application/x-tex">\mathcal{P}</annotation></semantics></math>. Recognizing that purely generative processes are prone to transmission errorsâ€”manifesting as logic bugs, invalid dependencies, or dead codeâ€”this phase establishes a crucial closed-loop feedback system absent in standard models. By treating execution outcomes as corrective signals, the framework systematically identifies and rectifies defects through two sequential stages: (1) a static analysis pass to ensure structural integrity and code quality, and (2) a dynamic execution pass within a sandboxed environment to enforce functional correctness.</p>
</div>
<section class="ltx_subsubsection" id="S3.SS3.SSS1">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.3.1 </span>Static Analysis and Code Quality Refinement</h4>
<div class="ltx_para" id="S3.SS3.SSS1.p1">
<p class="ltx_p">The first stage addresses issues that can be detected without executing the code. This process is orchestrated by a dedicated Analysis Agent and a Modification Agent.</p>
</div>
<div class="ltx_para" id="S3.SS3.SSS1.p2">
<p class="ltx_p"><span class="ltx_text ltx_font_bold">Static Analysis.</span>
An Analysis Agent, denoted by the function <math alttext="\mathcal{A}_{\text{static}}" class="ltx_Math" display="inline" id="S3.SS3.SSS1.p2.m1" intent=":literal"><semantics><msub><mi class="ltx_font_mathcaligraphic">ğ’œ</mi><mtext>static</mtext></msub><annotation encoding="application/x-tex">\mathcal{A}_{\text{static}}</annotation></semantics></math>, inspects the generated repository <math alttext="\mathcal{P}" class="ltx_Math" display="inline" id="S3.SS3.SSS1.p2.m2" intent=":literal"><semantics><mi class="ltx_font_mathcaligraphic">ğ’«</mi><annotation encoding="application/x-tex">\mathcal{P}</annotation></semantics></math> against the implementation blueprint <math alttext="\mathcal{B}" class="ltx_Math" display="inline" id="S3.SS3.SSS1.p2.m3" intent=":literal"><semantics><mi class="ltx_font_mathcaligraphic">â„¬</mi><annotation encoding="application/x-tex">\mathcal{B}</annotation></semantics></math>. It produces a structured static analysis report, <math alttext="\mathcal{R}_{\text{static}}" class="ltx_Math" display="inline" id="S3.SS3.SSS1.p2.m4" intent=":literal"><semantics><msub><mi class="ltx_font_mathcaligraphic">â„›</mi><mtext>static</mtext></msub><annotation encoding="application/x-tex">\mathcal{R}_{\text{static}}</annotation></semantics></math>, which identifies a set of issues. This process can be formalized as: <math alttext="\mathcal{R}_{\text{static}}=\mathcal{A}_{\text{static}}(\mathcal{P},\mathcal{B})" class="ltx_Math" display="inline" id="S3.SS3.SSS1.p2.m5" intent=":literal"><semantics><mrow><msub><mi class="ltx_font_mathcaligraphic">â„›</mi><mtext>static</mtext></msub><mo>=</mo><mrow><msub><mi class="ltx_font_mathcaligraphic">ğ’œ</mi><mtext>static</mtext></msub><mo lspace="0em" rspace="0em">â€‹</mo><mrow><mo stretchy="false">(</mo><mi class="ltx_font_mathcaligraphic">ğ’«</mi><mo>,</mo><mi class="ltx_font_mathcaligraphic">â„¬</mi><mo stretchy="false">)</mo></mrow></mrow></mrow><annotation encoding="application/x-tex">\mathcal{R}_{\text{static}}=\mathcal{A}_{\text{static}}(\mathcal{P},\mathcal{B})</annotation></semantics></math>.</p>
</div>
<div class="ltx_para" id="S3.SS3.SSS1.p3">
<p class="ltx_p">The identified issues <math alttext="I=\{i_{1},i_{2},\dots,i_{K}\}" class="ltx_Math" display="inline" id="S3.SS3.SSS1.p3.m1" intent=":literal"><semantics><mrow><mi>I</mi><mo>=</mo><mrow><mo stretchy="false">{</mo><msub><mi>i</mi><mn>1</mn></msub><mo>,</mo><msub><mi>i</mi><mn>2</mn></msub><mo>,</mo><mi mathvariant="normal">â€¦</mi><mo>,</mo><msub><mi>i</mi><mi>K</mi></msub><mo stretchy="false">}</mo></mrow></mrow><annotation encoding="application/x-tex">I=\{i_{1},i_{2},\dots,i_{K}\}</annotation></semantics></math> fall into two categories:
i) <em class="ltx_emph ltx_font_italic">Structural Discrepancies:</em> This includes integrity violations such as missing files specified in the blueprint or empty (zero-byte) source files that were not correctly generated.
ii) <em class="ltx_emph ltx_font_italic">Code Quality Deficiencies:</em> The agent leverages an LLM to perform a quality assessment of each source file, assigning a quality score, <math alttext="q(c_{i})" class="ltx_Math" display="inline" id="S3.SS3.SSS1.p3.m2" intent=":literal"><semantics><mrow><mi>q</mi><mo lspace="0em" rspace="0em">â€‹</mo><mrow><mo stretchy="false">(</mo><msub><mi>c</mi><mi>i</mi></msub><mo stretchy="false">)</mo></mrow></mrow><annotation encoding="application/x-tex">q(c_{i})</annotation></semantics></math>, and flagging sections with poor style, complexity, or maintainability.</p>
</div>
<div class="ltx_para" id="S3.SS3.SSS1.p4">
<p class="ltx_p"><span class="ltx_text ltx_font_bold">Code Refinement.</span>
The report <math alttext="\mathcal{R}_{\text{static}}" class="ltx_Math" display="inline" id="S3.SS3.SSS1.p4.m1" intent=":literal"><semantics><msub><mi class="ltx_font_mathcaligraphic">â„›</mi><mtext>static</mtext></msub><annotation encoding="application/x-tex">\mathcal{R}_{\text{static}}</annotation></semantics></math> is then passed to a Modification Agent, <math alttext="\mathcal{A}_{\text{modify}}" class="ltx_Math" display="inline" id="S3.SS3.SSS1.p4.m2" intent=":literal"><semantics><msub><mi class="ltx_font_mathcaligraphic">ğ’œ</mi><mtext>modify</mtext></msub><annotation encoding="application/x-tex">\mathcal{A}_{\text{modify}}</annotation></semantics></math>. This agent iterates through each issue <math alttext="i_{k}\in I" class="ltx_Math" display="inline" id="S3.SS3.SSS1.p4.m3" intent=":literal"><semantics><mrow><msub><mi>i</mi><mi>k</mi></msub><mo>âˆˆ</mo><mi>I</mi></mrow><annotation encoding="application/x-tex">i_{k}\in I</annotation></semantics></math> and applies a targeted fix. To perform precise, line-level modifications without rewriting entire files, the agent utilizes a programmatic interface inspired by the Language Server Protocol (LSP). We model this refinement operation as a function <math alttext="\Phi_{\text{LSP}}" class="ltx_Math" display="inline" id="S3.SS3.SSS1.p4.m4" intent=":literal"><semantics><msub><mi mathvariant="normal">Î¦</mi><mtext>LSP</mtext></msub><annotation encoding="application/x-tex">\Phi_{\text{LSP}}</annotation></semantics></math> that takes a file <math alttext="c_{i}" class="ltx_Math" display="inline" id="S3.SS3.SSS1.p4.m5" intent=":literal"><semantics><msub><mi>c</mi><mi>i</mi></msub><annotation encoding="application/x-tex">c_{i}</annotation></semantics></math> and a modification instruction from the report, producing a corrected file <math alttext="c^{\prime}_{i}" class="ltx_Math" display="inline" id="S3.SS3.SSS1.p4.m6" intent=":literal"><semantics><msubsup><mi>c</mi><mi>i</mi><mo>â€²</mo></msubsup><annotation encoding="application/x-tex">c^{\prime}_{i}</annotation></semantics></math>. The overall process yields a statically refined repository <math alttext="\mathcal{P}^{\prime}" class="ltx_Math" display="inline" id="S3.SS3.SSS1.p4.m7" intent=":literal"><semantics><msup><mi class="ltx_font_mathcaligraphic">ğ’«</mi><mo>â€²</mo></msup><annotation encoding="application/x-tex">\mathcal{P}^{\prime}</annotation></semantics></math> as: <math alttext="\mathcal{P}^{\prime}=\mathcal{A}_{\text{modify}}(\mathcal{P},\mathcal{R}_{\text{static}})" class="ltx_Math" display="inline" id="S3.SS3.SSS1.p4.m8" intent=":literal"><semantics><mrow><msup><mi class="ltx_font_mathcaligraphic">ğ’«</mi><mo>â€²</mo></msup><mo>=</mo><mrow><msub><mi class="ltx_font_mathcaligraphic">ğ’œ</mi><mtext>modify</mtext></msub><mo lspace="0em" rspace="0em">â€‹</mo><mrow><mo stretchy="false">(</mo><mi class="ltx_font_mathcaligraphic">ğ’«</mi><mo>,</mo><msub><mi class="ltx_font_mathcaligraphic">â„›</mi><mtext>static</mtext></msub><mo stretchy="false">)</mo></mrow></mrow></mrow><annotation encoding="application/x-tex">\mathcal{P}^{\prime}=\mathcal{A}_{\text{modify}}(\mathcal{P},\mathcal{R}_{\text{static}})</annotation></semantics></math>.</p>
</div>
</section>
<section class="ltx_subsubsection" id="S3.SS3.SSS2">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.3.2 </span>Sandbox Execution and Functional Correction</h4>
<div class="ltx_para" id="S3.SS3.SSS2.p1">
<p class="ltx_p">After static refinement, the repository <math alttext="\mathcal{P}^{\prime}" class="ltx_Math" display="inline" id="S3.SS3.SSS2.p1.m1" intent=":literal"><semantics><msup><mi class="ltx_font_mathcaligraphic">ğ’«</mi><mo>â€²</mo></msup><annotation encoding="application/x-tex">\mathcal{P}^{\prime}</annotation></semantics></math> undergoes dynamic testing in a secure, isolated sandbox environment to ensure it runs as intended.</p>
</div>
<div class="ltx_para" id="S3.SS3.SSS2.p2">
<p class="ltx_p"><span class="ltx_text ltx_font_bold">Environment Verification and Setup.</span>
A Sandbox Agent, <math alttext="\mathcal{A}_{\text{sandbox}}" class="ltx_Math" display="inline" id="S3.SS3.SSS2.p2.m1" intent=":literal"><semantics><msub><mi class="ltx_font_mathcaligraphic">ğ’œ</mi><mtext>sandbox</mtext></msub><annotation encoding="application/x-tex">\mathcal{A}_{\text{sandbox}}</annotation></semantics></math>, first validates the environment setup instructions (e.g., in <span class="ltx_text ltx_font_typewriter">README.md</span>) against the dependencies specified in the blueprint <math alttext="\mathcal{B}" class="ltx_Math" display="inline" id="S3.SS3.SSS2.p2.m2" intent=":literal"><semantics><mi class="ltx_font_mathcaligraphic">â„¬</mi><annotation encoding="application/x-tex">\mathcal{B}</annotation></semantics></math>. Any discrepancies are corrected. The agent then automatically provisions the specified environment and installs all dependencies.</p>
</div>
<div class="ltx_para" id="S3.SS3.SSS2.p3">
<p class="ltx_p"><span class="ltx_text ltx_font_bold">Iterative Execution and Correction.</span>
The agent then attempts to execute the main entry points of the repository, using automatically generated test data and test files designed to exercise the core algorithms and functions. The execution process, <math alttext="\mathcal{E}_{\text{sandbox}}" class="ltx_Math" display="inline" id="S3.SS3.SSS2.p3.m1" intent=":literal"><semantics><msub><mi class="ltx_font_mathcaligraphic">â„°</mi><mtext>sandbox</mtext></msub><annotation encoding="application/x-tex">\mathcal{E}_{\text{sandbox}}</annotation></semantics></math>, takes the repository <math alttext="\mathcal{P}^{\prime}_{j}" class="ltx_Math" display="inline" id="S3.SS3.SSS2.p3.m2" intent=":literal"><semantics><msubsup><mi class="ltx_font_mathcaligraphic">ğ’«</mi><mi>j</mi><mo>â€²</mo></msubsup><annotation encoding="application/x-tex">\mathcal{P}^{\prime}_{j}</annotation></semantics></math> at iteration <math alttext="j" class="ltx_Math" display="inline" id="S3.SS3.SSS2.p3.m3" intent=":literal"><semantics><mi>j</mi><annotation encoding="application/x-tex">j</annotation></semantics></math> (initially <math alttext="\mathcal{P}^{\prime}_{0}=\mathcal{P}^{\prime}" class="ltx_Math" display="inline" id="S3.SS3.SSS2.p3.m4" intent=":literal"><semantics><mrow><msubsup><mi class="ltx_font_mathcaligraphic">ğ’«</mi><mn>0</mn><mo>â€²</mo></msubsup><mo>=</mo><msup><mi class="ltx_font_mathcaligraphic">ğ’«</mi><mo>â€²</mo></msup></mrow><annotation encoding="application/x-tex">\mathcal{P}^{\prime}_{0}=\mathcal{P}^{\prime}</annotation></semantics></math>) and produces an execution trace, <math alttext="\mathcal{T}_{j}" class="ltx_Math" display="inline" id="S3.SS3.SSS2.p3.m5" intent=":literal"><semantics><msub><mi class="ltx_font_mathcaligraphic">ğ’¯</mi><mi>j</mi></msub><annotation encoding="application/x-tex">\mathcal{T}_{j}</annotation></semantics></math>, containing all outputs and error messages.</p>
<table class="ltx_equation ltx_eqn_table" id="S3.E9">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\mathcal{T}_{j}=\mathcal{E}_{\text{sandbox}}(\mathcal{P}^{\prime}_{j})" class="ltx_Math" display="block" id="S3.E9.m1" intent=":literal"><semantics><mrow><msub><mi class="ltx_font_mathcaligraphic">ğ’¯</mi><mi>j</mi></msub><mo>=</mo><mrow><msub><mi class="ltx_font_mathcaligraphic">â„°</mi><mtext>sandbox</mtext></msub><mo lspace="0em" rspace="0em">â€‹</mo><mrow><mo stretchy="false">(</mo><msubsup><mi class="ltx_font_mathcaligraphic">ğ’«</mi><mi>j</mi><mo>â€²</mo></msubsup><mo stretchy="false">)</mo></mrow></mrow></mrow><annotation encoding="application/x-tex">\mathcal{T}_{j}=\mathcal{E}_{\text{sandbox}}(\mathcal{P}^{\prime}_{j})</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(9)</span></td>
</tr></tbody>
</table>
<p class="ltx_p">This initiates an iterative refinement loop. If the trace <math alttext="\mathcal{T}_{j}" class="ltx_Math" display="inline" id="S3.SS3.SSS2.p3.m6" intent=":literal"><semantics><msub><mi class="ltx_font_mathcaligraphic">ğ’¯</mi><mi>j</mi></msub><annotation encoding="application/x-tex">\mathcal{T}_{j}</annotation></semantics></math> contains errors (<math alttext="\mathcal{T}_{j}^{\text{error}}\neq\emptyset" class="ltx_Math" display="inline" id="S3.SS3.SSS2.p3.m7" intent=":literal"><semantics><mrow><msubsup><mi class="ltx_font_mathcaligraphic">ğ’¯</mi><mi>j</mi><mtext>error</mtext></msubsup><mo>â‰ </mo><mi mathvariant="normal">âˆ…</mi></mrow><annotation encoding="application/x-tex">\mathcal{T}_{j}^{\text{error}}\neq\emptyset</annotation></semantics></math>), the Sandbox Agent analyzes the error messages to identify the likely faulty files and the nature of the bug. It then generates a modification instruction and invokes the LSP-based refinement function <math alttext="\Phi_{\text{LSP}}" class="ltx_Math" display="inline" id="S3.SS3.SSS2.p3.m8" intent=":literal"><semantics><msub><mi mathvariant="normal">Î¦</mi><mtext>LSP</mtext></msub><annotation encoding="application/x-tex">\Phi_{\text{LSP}}</annotation></semantics></math> to patch the code, producing the repository for the next iteration, <math alttext="\mathcal{P}^{\prime}_{j+1}" class="ltx_Math" display="inline" id="S3.SS3.SSS2.p3.m9" intent=":literal"><semantics><msubsup><mi class="ltx_font_mathcaligraphic">ğ’«</mi><mrow><mi>j</mi><mo>+</mo><mn>1</mn></mrow><mo>â€²</mo></msubsup><annotation encoding="application/x-tex">\mathcal{P}^{\prime}_{j+1}</annotation></semantics></math>. This loop continues until the execution is successful or a maximum number of iterations is reached.</p>
<table class="ltx_equation ltx_eqn_table" id="S3.E10">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\mathcal{P}^{\prime}_{j+1}=\Phi_{\text{LSP}}(\mathcal{P}^{\prime}_{j},\mathcal{T}_{j}^{\text{error}})" class="ltx_Math" display="block" id="S3.E10.m1" intent=":literal"><semantics><mrow><msubsup><mi class="ltx_font_mathcaligraphic">ğ’«</mi><mrow><mi>j</mi><mo>+</mo><mn>1</mn></mrow><mo>â€²</mo></msubsup><mo>=</mo><mrow><msub><mi mathvariant="normal">Î¦</mi><mtext>LSP</mtext></msub><mo lspace="0em" rspace="0em">â€‹</mo><mrow><mo stretchy="false">(</mo><msubsup><mi class="ltx_font_mathcaligraphic">ğ’«</mi><mi>j</mi><mo>â€²</mo></msubsup><mo>,</mo><msubsup><mi class="ltx_font_mathcaligraphic">ğ’¯</mi><mi>j</mi><mtext>error</mtext></msubsup><mo stretchy="false">)</mo></mrow></mrow></mrow><annotation encoding="application/x-tex">\mathcal{P}^{\prime}_{j+1}=\Phi_{\text{LSP}}(\mathcal{P}^{\prime}_{j},\mathcal{T}_{j}^{\text{error}})</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(10)</span></td>
</tr></tbody>
</table>
<p class="ltx_p">The final verified output of our entire framework is the repository <math alttext="\mathcal{P}^{*}=\mathcal{P}^{\prime}_{J}" class="ltx_Math" display="inline" id="S3.SS3.SSS2.p3.m10" intent=":literal"><semantics><mrow><msup><mi class="ltx_font_mathcaligraphic">ğ’«</mi><mo>âˆ—</mo></msup><mo>=</mo><msubsup><mi class="ltx_font_mathcaligraphic">ğ’«</mi><mi>J</mi><mo>â€²</mo></msubsup></mrow><annotation encoding="application/x-tex">\mathcal{P}^{*}=\mathcal{P}^{\prime}_{J}</annotation></semantics></math>, where <math alttext="J" class="ltx_Math" display="inline" id="S3.SS3.SSS2.p3.m11" intent=":literal"><semantics><mi>J</mi><annotation encoding="application/x-tex">J</annotation></semantics></math> is the terminal iteration of the refinement loop. This multi-stage verification and correction process ensures that the synthesized code is not only structurally sound but also functionally correct and conformant to the original specification.</p>
</div>
</section>
</section>
</section>
<section class="ltx_section" id="S4">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Experiments</h2>
<div class="ltx_para" id="S4.p1">
<p class="ltx_p">In this section, we evaluate the effectiveness of the proposed DeepCode framework by addressing the following 3 research questions:
<span class="ltx_text ltx_font_bold">RQ1:</span> How does DeepCode perform compared to existing agent frameworks?
<span class="ltx_text ltx_font_bold">RQ2:</span> How does the choice of different LLMs affect the performance of DeepCode?
<span class="ltx_text ltx_font_bold">RQ3:</span> What is the contribution of each module within the DeepCode architecture?</p>
</div>
<section class="ltx_subsection" id="S4.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Experiments Settings</h3>
<div class="ltx_para" id="S4.SS1.p1">
<p class="ltx_p"><span class="ltx_text ltx_font_bold">Datasets.</span>
To evaluate DeepCodeâ€™s capabilities in code comprehension and generation, particularly for automated vulnerability detection, we employ <span class="ltx_text ltx_font_bold">PaperBench Code-Dev</span>, an innovative benchmark created by OpenAI <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">starace2025PaperBench</span>]</cite>. PaperBench Code-Dev assesses AI modelsâ€™ ability to independently reproduce leading ML research from major conferences like ICML 2024, focusing on 20 significant papers. Models are required to generate all necessary code from scratch, using only the research papers as references, without accessing existing codebases from the original authors. These tasks are performed in a virtual machine environment, with the goal of building a functional codebase, replicating experiments, and creating a <span class="ltx_text ltx_font_typewriter">reproduce.sh</span> script for execution. Each paper is accompanied by a detailed evaluation rubric approved by the authors, which breaks down the reproduction task into 8,316 specific, gradable components, meticulously assessed using a hierarchical weighting scheme and SimpleJudge, a sophisticated automated judge powered by OpenAIâ€™s o3-mini model. This benchmark is rigorously crafted to challenge AI with tasks requiring advanced natural language understanding, algorithmic reasoning, and the ability to generate reliable code from abstract descriptions, all of which are crucial skills for automating vulnerability detection effectively.</p>
</div>
<div class="ltx_para" id="S4.SS1.p2">
<p class="ltx_p"><span class="ltx_text ltx_font_bold">Baselines.</span>
In order to evaluate the effectiveness of the proposed framework, we include a range of baseline methods for comparison. These baselines fall into four distinct categories:</p>
</div>
<div class="ltx_para" id="S4.SS1.p3">
<p class="ltx_p"><span class="ltx_text ltx_font_bold">(1) LLM Agents.</span> We compare against results reported inÂ <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">starace2025PaperBench</span>]</cite> for several state-of-the-art language models using two agent scaffolding approaches: (1) <span class="ltx_text ltx_font_italic">BasicAgent</span>, a simple tool-use loop based on Inspect AIâ€™s basic agent that allows models to terminate early, and (2) <span class="ltx_text ltx_font_italic">IterativeAgent</span>, which forces models to use their full allocated time and employs prompts designed to encourage incremental, piecemeal progress. All agents run in Ubuntu 24.04 Docker containers with access to a single A10 GPU, the internet, and standard development tools including bash, Python, web browsing, and file reading capabilitiesÂ <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">starace2025PaperBench</span>]</cite>. The baseline models include GPT-4o, o1, o3-mini, DeepSeek-R1, Claude 3.5 Sonnet, and Gemini 2.0 Flash, with most experiments using a 12-hour time limit (extended to 36 hours for select o1 runs).</p>
</div>
<div class="ltx_para" id="S4.SS1.p4">
<p class="ltx_p"><span class="ltx_text ltx_font_bold">(2) Scientific Code Agents.</span> <span class="ltx_text ltx_font_italic">PaperCoder</span>Â <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">seo2025paper2code</span>]</cite>. PaperCoder (also referred to as Paper2Code) is a multi-agent LLM framework that transforms machine learning papers into executable code repositories via a three-stage pipeline: planning, which constructs implementation roadmaps, system architecture diagrams, and file dependencies; analysis, which extracts file-level implementation details; and generation, which produces modular code in dependency order.</p>
</div>
<div class="ltx_para" id="S4.SS1.p5">
<p class="ltx_p"><span class="ltx_text ltx_font_bold">(3) Commercial Code Agents.</span> We compare against three state-of-the-art commercial code agents that provide AI-powered development assistance through different interfaces and capabilities:</p>
</div>
<div class="ltx_para" id="S4.SS1.p6">
<ul class="ltx_itemize" id="S4.I1">
<li class="ltx_item" id="S4.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span>
<div class="ltx_para" id="S4.I1.i1.p1">
<p class="ltx_p"><span class="ltx_text ltx_font_italic">Cursor</span> (Version 1.7.52) is an AI-assisted integrated development environment built as a fork of Visual Studio Code with additional AI features. Cursor allows developers to choose between cutting-edge LLMs and provides codebase embedding models that give agents deep understanding and recallÂ <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">cursor2025</span>]</cite>. In our experiments, Cursor uses Claude Sonnet 4.5-thinking as the underlying model.</p>
</div>
</li>
<li class="ltx_item" id="S4.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span>
<div class="ltx_para" id="S4.I1.i2.p1">
<p class="ltx_p"><span class="ltx_text ltx_font_italic">Claude Code</span> (Version 2.0.22) is Anthropicâ€™s agentic coding tool that lives in the terminal and helps developers turn ideas into code. Claude Code maintains awareness of the entire project structure, can find up-to-date information from the web, and with MCP can pull from external data sources like Google Drive, Figma, and Slack. It can directly edit files, run commands, create commits, and use MCP to read design docs or update ticketsÂ <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">claudecode2025</span>]</cite>. Our evaluation uses Claude Sonnet 4.5-thinking.</p>
</div>
</li>
<li class="ltx_item" id="S4.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span>
<div class="ltx_para" id="S4.I1.i3.p1">
<p class="ltx_p"><span class="ltx_text ltx_font_italic">Codex</span> (Version codex-cli 0.47.0) is OpenAIâ€™s coding agent that runs locally from the terminal and can read, modify, and run code on the userâ€™s machine. Codex is optimized for use with GPT-5-Codex for agentic coding, with configurable reasoning levels from medium to high for complex tasks. In auto approval mode, Codex can read files, make edits, and run commands in the working directory automaticallyÂ <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">codex2025</span>]</cite>. We configure Codex with GPT-5 Codex-high.</p>
</div>
</li>
</ul>
</div>
<div class="ltx_para" id="S4.SS1.p7">
<p class="ltx_p"><span class="ltx_text ltx_font_bold">(4) Human Experts.</span> The human baselineÂ <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">starace2025PaperBench</span>]</cite> consists of 8 ML PhD students and graduates from top institutions (<span class="ltx_text ltx_font_italic">e</span>.<span class="ltx_text ltx_font_italic">g</span>.Â Berkeley, Cambridge, Carnegie Mellon) who worked part-time over a four-week window on a 3-paper subset (all-in-one, fre, stay-on-topic). Participants had similar computational resources (A10 GPU) and could use AI coding assistants like ChatGPT and GitHub Copilot. The best-of-3 human attempts (Best@3) represent expert-level performance on this subset.</p>
</div>
<div class="ltx_para" id="S4.SS1.p8">
<p class="ltx_p"><span class="ltx_text ltx_font_bold">Experimental Setup.</span> To evaluate DeepCodeâ€™s efficacy in high-fidelity repository synthesis, we adopt a rigorous framework under realistic constraints. The setup combines a secure execution environment and the PaperBench protocol for fair, reproducible, detailed comparisons across baselines.</p>
</div>
<div class="ltx_para" id="S4.SS1.p9">
<p class="ltx_p"><span class="ltx_text ltx_font_bold">(1) Implementation Environment.</span> All experiments are conducted within an Ubuntu 22.04 LTS-based sandboxed environment. This infrastructure is provisioned with a standard Python development stack and essential dependencies. DeepCode is configured to operate within this isolated space, retaining privileges for file system manipulation, shell command execution, and internet access, thereby simulating a standard software research and development workflow.</p>
</div>
<div class="ltx_para" id="S4.SS1.p10">
<p class="ltx_p"><span class="ltx_text ltx_font_bold">(2) Task Execution.</span> DeepCode accepts the target paper in both PDF and Markdown formats, along with any supplementary addenda, as primary inputs. To ensure that generated solutions stem from algorithmic reasoning rather than retrieval, a source code blacklist is enforced during execution. This protocol precludes access to the authorsâ€™ original repositories and known third-party implementations during web browsing. With input parameters defined and the search space constrained, DeepCode initiates its autonomous workflow for code generation and debugging.</p>
</div>
<div class="ltx_para" id="S4.SS1.p11">
<p class="ltx_p"><span class="ltx_text ltx_font_bold">(3) Grading Methodology.</span>
Assessment of the generated code follows the PaperBench Code-Dev protocol, which focuses on structural and functional correctness and does not include post-submission reproduction. Grading is carried out by SimpleJudge, an automated system based on OpenAIâ€™s o3-mini, which performs static analysis of the submitted repository against a set of fine-grained, hierarchical criteria co-developed with the authors of the source paper. The judging logic is restricted to the â€œCode Developmentâ€ leaf nodes of this rubric and examines core aspects of software quality, including static correctness (syntax validity and compliance with language standards), dependency validity (completeness and correctness of dependency specifications such as <span class="ltx_text ltx_font_typewriter">requirements.txt</span>), project structure (coherent and consistent organization of files and directories), and algorithmic fidelity (faithful implementation of the algorithms and interfaces described in the original paper). This procedure is designed to align the evaluation with the central technical contributions of the work.</p>
</div>
<div class="ltx_para" id="S4.SS1.p12">
<p class="ltx_p"><span class="ltx_text ltx_font_bold">(4) Evaluation Metrics and Protocol.</span> Our primary evaluation metric is the Replication Score, which quantifies the proficiency of DeepCode in translating theoretical concepts into a functional codebase. The score for a single replication trial is derived from the hierarchical rubric through a bottom-up aggregation process. <span class="ltx_text ltx_font_bold">(i) Leaf node scoring:</span> SimpleJudge first evaluates each leaf node criterion on a binary basis, assigning a score of 1 for â€œpassâ€ (compliance) and 0 for â€œfailâ€ (non-compliance). <span class="ltx_text ltx_font_bold">(ii) Score aggregation:</span> The score for any parent node is then computed as the weighted average of the scores of its immediate children. The weights, predetermined during the rubric design, reflect the relative importance of each sub-task. <span class="ltx_text ltx_font_bold">(iii) Final score derivation:</span> This recursive aggregation continues up the hierarchy until a single score is obtained for the root node, which serves as the Replication Score for that trial.</p>
</div>
<div class="ltx_para" id="S4.SS1.p13">
<p class="ltx_p">To account for the stochasticity inherent in code generation, we adopt a strict evaluation protocol. For each target paper, three independent replication trials are performed, and each resulting repository is scored separately by SimpleJudge using the procedure described above. The final Replication Score is the average of the three scores, mitigating outliers and providing a more stable and reliable measure of the modelâ€™s typical performance.</p>
</div>
<figure class="ltx_figure" id="S4.F4"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="161" id="S4.F4.g1" src="x4.png" width="660"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" style="font-size:90%;">Figure 4</span>: </span><span class="ltx_text" style="font-size:90%;">Comparison of DeepCode with four baseline categories: (1) human experts, (2) state-of-the-art commercial code agents, (3) scientific code agents, and (4) LLM-based agents</span></figcaption>
</figure>
</section>
<section class="ltx_subsection" id="S4.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>Main Results</h3>
<div class="ltx_para" id="S4.SS2.p1">
<p class="ltx_p">The primary results of our experiments are detailed in FigureÂ <a class="ltx_ref" href="https://arxiv.org/html/2512.07921v1#S4.F4" title="Figure 4 â€£ 4.1 Experiments Settings â€£ 4 Experiments â€£ DeepCode: Open Agentic Coding"><span class="ltx_text ltx_ref_tag">4</span></a>. We analyze the performance of DeepCode against the four established categories of baselines: general-purpose LLM agents, specialized scientific code agents, commercial code agents, and human experts.</p>
</div>
<div class="ltx_para" id="S4.SS2.p2">
<ul class="ltx_itemize" id="S4.I2">
<li class="ltx_item" id="S4.I2.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span>
<div class="ltx_para" id="S4.I2.i1.p1">
<p class="ltx_p"><span class="ltx_text ltx_font_bold">Comparison against LLM Agents.</span> FigureÂ <a class="ltx_ref" href="https://arxiv.org/html/2512.07921v1#S4.F4" title="Figure 4 â€£ 4.1 Experiments Settings â€£ 4 Experiments â€£ DeepCode: Open Agentic Coding"><span class="ltx_text ltx_ref_tag">4</span></a> presents average replication scores across all benchmark papers. Among general-purpose LLM agents, performance varies significantly by model and scaffolding. With BasicAgent, Claude-3.5-Sonnet achieves the highest score (35.4<math alttext="\bf{\pm}" class="ltx_Math" display="inline" id="S4.I2.i1.p1.m1" intent=":literal"><semantics><mo>Â±</mo><annotation encoding="application/x-tex">\bf{\pm}</annotation></semantics></math>0.8), while other frontier models range from 5.0 to 19.5. IterativeAgent scaffolding improves some models, with o1 reaching the best LLM agent performance of 43.3<math alttext="\bf{\pm}" class="ltx_Math" display="inline" id="S4.I2.i1.p1.m2" intent=":literal"><semantics><mo>Â±</mo><annotation encoding="application/x-tex">\bf{\pm}</annotation></semantics></math>1.1. DeepCode achieves 73.5<math alttext="\bf{\pm}" class="ltx_Math" display="inline" id="S4.I2.i1.p1.m3" intent=":literal"><semantics><mo>Â±</mo><annotation encoding="application/x-tex">\bf{\pm}</annotation></semantics></math>2.8, representing a 70% relative improvement over the best LLM agent baseline. This substantial gap demonstrates that our frameworkâ€™s specialized design, which incorporates systematic planning, structured code generation and automated verification, provides significant advantages over general-purpose agent scaffolding.</p>
</div>
</li>
<li class="ltx_item" id="S4.I2.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span>
<div class="ltx_para" id="S4.I2.i2.p1">
<p class="ltx_p"><span class="ltx_text ltx_font_bold">Comparison against Scientific Code Agents.</span> PaperCoder, a specialized multi-agent framework designed for transforming machine learning papers into executable code, achieves a score of 51.1<math alttext="\bf{\pm}" class="ltx_Math" display="inline" id="S4.I2.i2.p1.m1" intent=":literal"><semantics><mo>Â±</mo><annotation encoding="application/x-tex">\bf{\pm}</annotation></semantics></math>1.4, outperforming all LLM agents baselines. However, DeepCode achieves a significantly higher score of 73.5<math alttext="\bf{\pm}" class="ltx_Math" display="inline" id="S4.I2.i2.p1.m2" intent=":literal"><semantics><mo>Â±</mo><annotation encoding="application/x-tex">\bf{\pm}</annotation></semantics></math>2.8â€”an improvement of over 22 points. This substantial gain suggests that our approach to task decomposition, code generation, and repository-level integration is markedly more effective than existing specialized methods.</p>
</div>
</li>
<li class="ltx_item" id="S4.I2.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span>
<div class="ltx_para" id="S4.I2.i3.p1">
<p class="ltx_p"><span class="ltx_text ltx_font_bold">Comparison against Commercial Code Agents.</span> TableÂ <a class="ltx_ref" href="https://arxiv.org/html/2512.07921v1#S4.T1" title="Table 1 â€£ 4.2 Main Results â€£ 4 Experiments â€£ DeepCode: Open Agentic Coding"><span class="ltx_text ltx_ref_tag">1</span></a> details a direct comparison with leading commercial agents on a 5-paper subset. DeepCode achieves an average score of 0.8482, decisively outperforming Codex (0.3997), Cursor (0.5841), and Claude Code (0.5871).
This result is particularly noteworthy: DeepCode uses the same base model as both Cursor and Claude Code. The dramatic performance difference provides strong evidence that our frameworkâ€™s performance gains are not merely a product of a powerful base model. Rather, the advantage is directly attributable to the superior agentic architecture, planning, and execution strategies of DeepCode.</p>
</div>
</li>
<li class="ltx_item" id="S4.I2.i4" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span>
<div class="ltx_para" id="S4.I2.i4.p1">
<p class="ltx_p"><span class="ltx_text ltx_font_bold">Comparison against Human Experts.</span> The most compelling finding is the comparison to human expert performance. As shown in the final rows of FigureÂ <a class="ltx_ref" href="https://arxiv.org/html/2512.07921v1#S4.F4" title="Figure 4 â€£ 4.1 Experiments Settings â€£ 4 Experiments â€£ DeepCode: Open Agentic Coding"><span class="ltx_text ltx_ref_tag">4</span></a>, we benchmarked performance on the 3-paper subset. The human baseline, which represents the best-of-3 attempts from ML PhD students, achieved a score of 72.4. Our DeepCodeâ€™s average performance on this same subset was 75.9 <math alttext="\bf{\pm}" class="ltx_Math" display="inline" id="S4.I2.i4.p1.m1" intent=":literal"><semantics><mo>Â±</mo><annotation encoding="application/x-tex">\bf{\pm}</annotation></semantics></math> 4.5, meaning it not only competes with but exceeds the score of the best attempt from a human expert. This result strongly validates our approach, demonstrating its capability to automate and even surpass expert-level performance on this highly challenging task.</p>
</div>
</li>
</ul>
</div>
<figure class="ltx_table" id="S4.T1">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span class="ltx_text" style="font-size:90%;">Table 1</span>: </span><span class="ltx_text" style="font-size:90%;">Reproduction scores of DeepCode and commercial code agents on 5-paper subset</span></figcaption>
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:442.1pt;height:59.2pt;vertical-align:-27.2pt;"><span class="ltx_transformed_inner" style="transform:translate(-9.2pt,1.2pt) scale(0.96,0.96) ;">
<table class="ltx_tabular ltx_align_middle">
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_t" style="padding-top:1.5pt;padding-bottom:1.5pt;"><span class="ltx_text ltx_font_bold">Model</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" style="padding-top:1.5pt;padding-bottom:1.5pt;"><span class="ltx_text ltx_font_bold">fre</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" style="padding-top:1.5pt;padding-bottom:1.5pt;"><span class="ltx_text ltx_font_bold">rice</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" style="padding-top:1.5pt;padding-bottom:1.5pt;"><span class="ltx_text ltx_font_bold">bam</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" style="padding-top:1.5pt;padding-bottom:1.5pt;"><span class="ltx_text ltx_font_bold">pinn</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" style="padding-top:1.5pt;padding-bottom:1.5pt;"><span class="ltx_text ltx_font_bold">mech-u</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" style="padding-top:1.5pt;padding-bottom:1.5pt;"><span class="ltx_text ltx_font_bold">Avg.</span></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_t" style="padding-top:1.5pt;padding-bottom:1.5pt;">Codex (GPT 5 Codex-high)</td>
<td class="ltx_td ltx_align_center ltx_border_t" style="padding-top:1.5pt;padding-bottom:1.5pt;">0.4095</td>
<td class="ltx_td ltx_align_center ltx_border_t" style="padding-top:1.5pt;padding-bottom:1.5pt;">0.3645</td>
<td class="ltx_td ltx_align_center ltx_border_t" style="padding-top:1.5pt;padding-bottom:1.5pt;">0.1937</td>
<td class="ltx_td ltx_align_center ltx_border_t" style="padding-top:1.5pt;padding-bottom:1.5pt;">0.5382</td>
<td class="ltx_td ltx_align_center ltx_border_t" style="padding-top:1.5pt;padding-bottom:1.5pt;">0.4926</td>
<td class="ltx_td ltx_align_center ltx_border_t" style="padding-top:1.5pt;padding-bottom:1.5pt;">0.3997</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left" style="padding-top:1.5pt;padding-bottom:1.5pt;">Claude Code (Claude Sonnet 4.5-think)</td>
<td class="ltx_td ltx_align_center" style="padding-top:1.5pt;padding-bottom:1.5pt;">0.6286</td>
<td class="ltx_td ltx_align_center" style="padding-top:1.5pt;padding-bottom:1.5pt;">0.3787</td>
<td class="ltx_td ltx_align_center" style="padding-top:1.5pt;padding-bottom:1.5pt;">0.3829</td>
<td class="ltx_td ltx_align_center" style="padding-top:1.5pt;padding-bottom:1.5pt;">0.7233</td>
<td class="ltx_td ltx_align_center" style="padding-top:1.5pt;padding-bottom:1.5pt;">0.8222</td>
<td class="ltx_td ltx_align_center" style="padding-top:1.5pt;padding-bottom:1.5pt;">0.5871</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left" style="padding-top:1.5pt;padding-bottom:1.5pt;">Cursor (Claude Sonnet 4.5-think)</td>
<td class="ltx_td ltx_align_center" style="padding-top:1.5pt;padding-bottom:1.5pt;">0.6344</td>
<td class="ltx_td ltx_align_center" style="padding-top:1.5pt;padding-bottom:1.5pt;">0.4186</td>
<td class="ltx_td ltx_align_center" style="padding-top:1.5pt;padding-bottom:1.5pt;">0.3779</td>
<td class="ltx_td ltx_align_center" style="padding-top:1.5pt;padding-bottom:1.5pt;">0.7748</td>
<td class="ltx_td ltx_align_center" style="padding-top:1.5pt;padding-bottom:1.5pt;">0.7148</td>
<td class="ltx_td ltx_align_center" style="padding-top:1.5pt;padding-bottom:1.5pt;">0.5841</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_b ltx_border_t" style="padding-top:1.5pt;padding-bottom:1.5pt;">
<span class="ltx_text ltx_font_bold">DeepCode</span> (Claude Sonnet 4.5-think)</td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_t" style="padding-top:1.5pt;padding-bottom:1.5pt;"><span class="ltx_text ltx_font_bold">0.8435</span></td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_t" style="padding-top:1.5pt;padding-bottom:1.5pt;"><span class="ltx_text ltx_font_bold">0.7380</span></td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_t" style="padding-top:1.5pt;padding-bottom:1.5pt;"><span class="ltx_text ltx_font_bold">0.8530</span></td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_t" style="padding-top:1.5pt;padding-bottom:1.5pt;"><span class="ltx_text ltx_font_bold">0.9474</span></td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_t" style="padding-top:1.5pt;padding-bottom:1.5pt;"><span class="ltx_text ltx_font_bold">0.8888</span></td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_t" style="padding-top:1.5pt;padding-bottom:1.5pt;"><span class="ltx_text ltx_font_bold">0.8541</span></td>
</tr>
</table>
</span></div>
</figure>
</section>
<section class="ltx_subsection" id="S4.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.3 </span>Analysis on Different LLMs</h3>
<div class="ltx_para" id="S4.SS3.p1">
<p class="ltx_p">We evaluate DeepCode with five LLM backbones (Claude-4.5-Sonnet, GPT-5, Claude-3.5-Sonnet, Gemini-2.5-Pro, DeepSeek-R1) on three PaperBench tasks (fre, all-in-one, stay-on-topic). The tasks vary in specification complexity: fre and all-in-one contain long, interdependent setups with overlapping constraints, while stay-on-topic provides more structured descriptions. Agent architecture and tooling remain constant to isolate model capability effects.</p>
</div>
<div class="ltx_para" id="S4.SS3.p2">
<p class="ltx_p">As shown in FigureÂ <a class="ltx_ref" href="https://arxiv.org/html/2512.07921v1#S4.F5" title="Figure 5 â€£ 4.3 Analysis on Different LLMs â€£ 4 Experiments â€£ DeepCode: Open Agentic Coding"><span class="ltx_text ltx_ref_tag">5</span></a>, reproduction scores exhibit consistent stratification across all three tasks. Claude-4.5-Sonnet achieves the best or near-best performance (0.72-0.82), demonstrating particular strength on fre and all-in-one where it more reliably reconstructs implementation details and multi-stage pipelines implied by complex, underspecified descriptions. GPT-5 tracks Claude-4.5-Sonnet closely on most metrics (0.69-0.81) and shows marginal advantages on stay-on-topic (0.81 vs. 0.72), suggesting additional robustness in maintaining alignment with fixed experimental framings, though this does not overturn Claude-4.5-Sonnetâ€™s overall dominance. Mid-tier models occupy an intermediate performance range: Claude-3.5-Sonnet (0.48-0.57) and Gemini-2.5-Pro (0.44-0.73) successfully recover main experimental skeletons but leave notable gaps in finer-grained procedural steps. DeepSeek-R1 consistently underperforms (<math alttext="\approx" class="ltx_Math" display="inline" id="S4.SS3.p2.m1" intent=":literal"><semantics><mo>â‰ˆ</mo><annotation encoding="application/x-tex">\approx</annotation></semantics></math>0.29), reproducing only fragments of target workflows across all tasks. This stable ranking pattern across heterogeneous specifications indicates that under fixed agent architecture, the underlying language model becomes the primary factor determining the ceiling and reliability of automatic paper-level reproduction.</p>
</div>
<figure class="ltx_figure" id="S4.F5"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="189" id="S4.F5.g1" src="x5.png" width="594"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" style="font-size:90%;">Figure 5</span>: </span><span class="ltx_text" style="font-size:90%;">DeepCode reproduction results on the 3-paper subset across LLM backbones</span></figcaption>
</figure>
</section>
<section class="ltx_subsection" id="S4.SS4">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.4 </span>Ablation Studies</h3>
<div class="ltx_para" id="S4.SS4.p1">
<p class="ltx_p">In this section, we conduct ablation studies on three core components of DeepCode: CodeRAG, CodeMem, and Automated Verification. Specifically, we evaluate CodeRAG and Automated Verification on a 3-paper subset (all-in-one, fre, stay-on-topic), while CodeMem is assessed on 5 randomly selected tasks (test-time-model-adaptation, rice, mechanistic-understanding, fre, all-in-one). Our key findings are summarized as follows.</p>
</div>
<div class="ltx_para" id="S4.SS4.p2">
<p class="ltx_p"><span class="ltx_text ltx_font_bold">(1) Impact of CodeRAG.</span> To decouple the impact of CodeRAG, we conducted an ablation study using Gemini-2.5-Flash. As visualized in Figure <a class="ltx_ref" href="https://arxiv.org/html/2512.07921v1#S4.F6.sf1" title="In Figure 6 â€£ 4.4 Ablation Studies â€£ 4 Experiments â€£ DeepCode: Open Agentic Coding"><span class="ltx_text ltx_ref_tag">6(a)</span></a>, the integration of CodeRAG delivers a substantial performance leap (up to 70% relative gain), effectively breaking the base modelâ€™s performance ceiling (0.35â€“0.38). Notably, we observed negligible gains when applying CodeRAG to frontier models like Claude 4.5 Sonnet. This contrast yields a critical insight: while reasoning giants likely encode sufficient implementation patterns within their parameters, cost-efficient models like Flash suffer from inherent <em class="ltx_emph ltx_font_italic">knowledge gaps</em>. Consequently, CodeRAG proves indispensable for these architectures, acting as a vital bridge to fill implicit domain voids with standard practicesâ€”confirming that external knowledge injection is essential for democratizing high-fidelity replication on lightweight models.</p>
</div>
<div class="ltx_para" id="S4.SS4.p3">
<p class="ltx_p"><span class="ltx_text ltx_font_bold">(2) Impact of CodeMem.</span>
We ablate CodeMemâ€™s contribution on five PaperBench tasks using Claude-4.5-Sonnet, comparing DeepCodeâ€™s structured memory against a "Simple" baseline that naively evicts historical messages via sliding windows when approaching context limits.</p>
</div>
<div class="ltx_para" id="S4.SS4.p4">
<p class="ltx_p">Results demonstrate that unstructured eviction causes context saturation with signal loss: the Simple protocol achieves only 0.33-0.43 in rice, fre, and mechanistic-understanding tasks due to dependency truncation, where foundational class definitions are discarded before dependent code generation. CodeMemâ€™s structured indexing maintains task-relevant signal density, restoring scores to 0.70-0.92 by preserving critical dependencies without exhausting context budgets.
Even in scenarios with strong baseline performance (test-time-model-adaptation: 0.62 â†’ 0.72; all-in-one: 0.66 â†’ 0.76), Structured memory delivers consistent gains, confirming our core thesis: effective agentic coding requires explicit information flow management to maximize signal-to-noise ratio under context constraints.</p>
</div>
<figure class="ltx_figure" id="S4.F6">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S4.F6.sf1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="359" id="S4.F6.sf1.g1" src="x6.png" width="726"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" style="font-size:90%;">(a)</span> </span><span class="ltx_text" style="font-size:90%;">Ablation of CodeRAG and Verification</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S4.F6.sf2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_square" height="443" id="S4.F6.sf2.g1" src="x7.png" width="528"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" style="font-size:90%;">(b)</span> </span><span class="ltx_text" style="font-size:90%;">Ablation of CodeMem</span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" style="font-size:90%;">Figure 6</span>: </span><span class="ltx_text" style="font-size:90%;">Ablation studies of key components in DeepCode on PaperBench</span></figcaption>
</figure>
<div class="ltx_para" id="S4.SS4.p5">
<p class="ltx_p"><span class="ltx_text ltx_font_bold">(3) Impact of Automated Verification.</span>
Across 3 test papers, Automated Verification yields consistent gains of 3.7â€“6.5%, elevating scores from 0.69â€“0.81 to 0.73â€“0.84. The layer primarily corrects three types of residual errors: typos in variable names, missing dependencies, and wrong command-line arguments. These errors prevent otherwise sound implementations from executing reliably. The modest improvement reflects an important fact: the earlier phases have already achieved technical correctness. Verification is a final pass to ensure reliable execution. It eliminates small but consequential deviations that cause borderline implementations to fail, transforming them into faithful replications.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S5">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Related Work</h2>
<section class="ltx_subsection" id="S5.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.1 </span>General Coding Agents</h3>
<div class="ltx_para" id="S5.SS1.p1">
<p class="ltx_p">The field of software engineering is being rapidly transformed by agentic systems that have evolved from passive code assistants into autonomous entities capable of planning, executing multi-step tasks, and self-correctionÂ <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">dong2025survey</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">ge2025survey</span>]</cite>. Research has explored several key architectures for these agents. One prominent trend involves multi-agent frameworks that emulate human development teams. This includes systems like ChatDevÂ <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">qian2024chatdev</span>]</cite>, MetaGPTÂ <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">hong2024MetaGPT</span>]</cite>, and CodePoRiÂ <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">rasheed2024codepori</span>]</cite>, which simulate entire software company organizational structures to manage development tasks from scratch.
For repo-level code generation, CodeSÂ <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">zan2024codes</span>]</cite> proposed to decompose repository generation into specialized agents for structure planning and content filling. AgentCoderÂ <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">huang2024agentcoder</span>]</cite> employs atest-driven refinement loop involving programmer, test designer, and test executor agents, while MapCoderÂ <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">islam2024mapcoder</span>]</cite> mirrors human program synthesis with four agents handling example retrieval, planning, generation, and debugging.
A second major trend focuses on enhancing agents with specialized tools and interfaces. For instance, CodeAgentÂ <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">zhang2024codeagent</span>]</cite> integrates five domain-specific tools to support repository-level analysis, while SWE-agentÂ <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">yang2025sweagent</span>]</cite> introduces a high-level Agent-Computer Interface (ACI) to enable robust agent interaction with file systems and development environments. In addition, ToolGenÂ <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">wang2025toolgen</span>]</cite> proposes representing each tool as a unique token and directly integrating tool-specific knowledge into the parameters of the LLM, thereby enabling a paradigm shift toward seamless unification of tool invocation and natural language generation.</p>
</div>
<div class="ltx_para" id="S5.SS1.p2">
<p class="ltx_p">Recent advancements in academic research are increasingly being translated into practical, productized tools. Commercial code agents emerging from this trend can be broadly categorized into two distinct paradigms: (1) AI-native integrated development environments (IDEs) such as CursorÂ <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">cursor2025</span>]</cite> and TraeÂ <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">trae2025</span>]</cite> that embed AI capabilities directly into the editor interface, and (2) terminal-based or extension-based agents including Claude CodeÂ <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">claudecode2025</span>]</cite>, Gemini CLIÂ <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">geminicli2025</span>]</cite>, Github CopilotÂ <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">copilot2025</span>]</cite>, and ClineÂ <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">cline2024</span>]</cite> that operate through command-line interfaces or editor extensions.
These coding agents leverage a holistic understanding of the codebase to perform complex tasks such as multi-file refactoring and autonomous edits. They support flexible, composable workflows and integrate seamlessly into diverse development pipelines. Commercial deployments indicate significant improvements in both function implementation and overall programming productivity.
Despite their effectiveness, these agents suffer from context window limitations that impair their ability to process lengthy technical documents such as academic papers, and struggle to maintain coherence and correctness when synthesizing repository-level codebases.</p>
</div>
</section>
<section class="ltx_subsection" id="S5.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.2 </span>Scientific Coding Agents</h3>
<div class="ltx_para" id="S5.SS2.p1">
<p class="ltx_p">In contrast to general-purpose coding agents, this class of agents targets more complex code generation scenarios, including the implementation and reproduction of entire codebases from high-level ideas and academic papers.
For example, Paper2CodeÂ <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">seo2025paper2code</span>]</cite> addresses the research reproducibility crisis by transforming machine learning papers into executable repositories. Its code generation framework follows a structured three-stage process that includes system architecture design, implementation detail extraction, and modular code generation. CodeScientistÂ <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">jansen2025codescientist</span>]</cite> generates experimental code from literature, employing an iterative generate-execute-reflect cycle to write, run, and debug Python experiments. In addition, AlphaEvolveÂ <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">novikov2025alphaevolve</span>]</cite> utilize code generation for algorithmic discovery, using an LLM as an evolutionary mutator to propose variations to entire codebases, which are then rigorously evaluated.
Besides, the automation code in AI ScientistÂ <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">lu2024aiscientist</span>]</cite> and AI-ResearcherÂ <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">tang2025airesearcher</span>]</cite> enables agents to iteratively plan and execute experiments, handle errors, and refine future runs based on results. AI Scientist focuses on experimental automation, maintaining execution history and generating plots and notes to support scientific write-ups. AI-Researcher extends this with a multi-stage refinement framework, where a code agent implements modular solutions and an advisor agent provides structured feedback for iterative validation, revision, and scaling.
These agents have advanced the pace of scientific research, yet achieving higher generation efficiency without compromising code quality remains an open challenge.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S6">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>Discussion: Challenges and Future Directions</h2>
<div class="ltx_para" id="S6.p1">
<p class="ltx_p">While DeepCode demonstrates the efficacy of principled information-flow management in high-fidelity repository synthesis, the transition from episodic coding tasks to autonomous, cost-effective, and self-evolving engineering remains fraught with challenges. We identify three critical frontiers that define the future trajectory of agentic software engineering.</p>
</div>
<div class="ltx_para" id="S6.p2">
<p class="ltx_p"><span class="ltx_text ltx_font_bold">(1) Agentic Capability and Computational Efficiency. </span>
SOTA performance in agentic coding currently relies on massive, proprietary LLMs (<span class="ltx_text ltx_font_italic">e</span>.<span class="ltx_text ltx_font_italic">g</span>.Â GPT-5, Claude 4.5), which incur prohibitive deployment costs and high latency. Conversely, smaller, open-weight models offer efficiency but lack the complex reasoning capabilities required for autonomous decision-making in open-ended engineering tasks.
Bridging this gap presents a dichotomy of challenges. <em class="ltx_emph ltx_font_italic">(i) Fine-tuning limits:</em> Enhancing small models via supervised fine-tuning (SFT) is constrained by a data bottleneckâ€”while raw code is abundant, high-quality agentic trajectories are scarce and expensive to curate. <em class="ltx_emph ltx_font_italic">(ii) Knowledge injection limits:</em> Merely augmenting small models with external knowledge is often insufficient; retrieved contexts may lack direct relevance to the specific coding task, and small models struggle to integrate complex inputs without suffering from attention dilution.</p>
</div>
<div class="ltx_para" id="S6.p3">
<p class="ltx_p">We envision a shift toward hybrid agentic architectures that synergize models of varying scales, employing large models for high-level reasoning and efficient small models for routine implementation. Besides, distilling knowledge from large models helps reduce the data bottleneck.</p>
</div>
<div class="ltx_para" id="S6.p4">
<p class="ltx_p"><span class="ltx_text ltx_font_bold">(2) From Episodic to Evolving Agents.</span>
Current coding agents typically operate in an episodic manner: they reset after each project, failing to carry over experience or tacit knowledge to subsequent tasks. Enabling agents to self-evolve and accumulate expertise mirrors human professional growth but faces significant hurdles.
<em class="ltx_emph ltx_font_italic">(i) Reinforcement Learning constraints:</em> While RL-based optimization theoretically allows agents to learn from feedback, it requires well-defined reward functions, which are difficult to formulate for complex, multi-objective software engineering tasks. Moreover, this approach is inapplicable to closed-source LLMs where parameter updates are impossible. <em class="ltx_emph ltx_font_italic">(ii) Memory scalability issues:</em> The alternative approachâ€”stacking historical experiences into a long-term memoryâ€”introduces severe noise. Simply accumulating raw interaction logs leads to context bloat, where retrieving relevant past experiences becomes a â€œneedle in a haystackâ€ problem.</p>
</div>
<div class="ltx_para" id="S6.p5">
<p class="ltx_p">Beyond relying on extensive manual annotation and training, a scalable solution involves automating the abstraction of past experiences. Future agents can implement post-task reflection to condense execution traces into reusable skills or heuristics. Storing these refined insights allows agents to retrieve corresponding high-level guidance, enabling self-evolution while avoiding context explosion.</p>
</div>
<div class="ltx_para" id="S6.p6">
<p class="ltx_p"><span class="ltx_text ltx_font_bold">(3) Dynamic Planning and Adaptability.</span>
Most existing frameworks utilize a linear Plan-then-Code workflow, assuming that all constraints are knowable a priori. In real-world engineering, specifications often evolve, and critical implementation constraints are frequently discovered only during the coding process.
Separation between planning and execution leads to fragility: if the initial blueprint is flawed, the coding agent is often constrained by a stale plan, leading to suboptimal workarounds or failure.</p>
</div>
<div class="ltx_para" id="S6.p7">
<p class="ltx_p">Future researches advance toward dynamic, bidirectional planning frameworks. Agents are able to adapt their initial blueprints when encountering unforeseen constraints during implementation. Establishing a feedback mechanism where execution insights directly inform and update the high-level plan is crucial for handling the complex realities of large-scale software development.</p>
</div>
</section>
<section class="ltx_section" id="S7">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">7 </span>Conclusion</h2>
<div class="ltx_para" id="S7.p1">
<p class="ltx_p">In this work, we presented DeepCode, an autonomous framework that advances the frontier of agentic code engineering by reimagining document-to-repository synthesis as a challenge of <em class="ltx_emph ltx_font_italic">information-flow management</em>.
Addressing the fundamental conflict between information overload and finite context bottlenecks, we demonstrated that treating synthesis as a channel optimization problemâ€”solved through the orchestration of blueprint distillation, stateful memory, conditional knowledge injection, and closed-loop verificationâ€”effectively maximizes the signal-to-noise ratio for long-horizon tasks.
Empirical evaluations on PaperBench confirm that DeepCode establishes a new SOTA, decisively outperforming leading commercial agents and surpassing PhD-level human experts in reproduction accuracy.
These findings validate that hierarchical information orchestration, rather than indiscriminate context scaling, provides the decisive path toward robust autonomous systems, laying a critical foundation for the future of automated scientific discovery and rigorous research reproduction.</p>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
<section class="ltx_appendix" id="A1">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix A </span>Appendix</h2>
<div class="ltx_para" id="A1.p1">
<p class="ltx_p">This appendix supplements the main text by providing four categories of supplementary materials.
First, the <em class="ltx_emph ltx_font_italic">Complete Results</em> subsection reports an extensive quantitative evaluation of DeepCode,
including comparative analysis against multiple benchmark models and reproducibility analysis across different papers and operational scenarios.
Second, the <em class="ltx_emph ltx_font_italic">DeepCode Application Cases</em> subsection showcases representative visualizations demonstrating DeepCodeâ€™s end-to-end capabilities, covering backend systems, web user interfaces, and the Paper2Code research reproduction workflow.
Third, the <em class="ltx_emph ltx_font_italic">DeepCode Sub-Agent Details</em> subsection elucidates the internal multi-agent architecture, clarifying the roles, responsibilities, and coordination patterns for implementing specific specialized sub-agents.
Finally, the <em class="ltx_emph ltx_font_italic">MCP Toolkit in DeepCode</em> subsection documents the Model Context Protocol (MCP) tools integrated into the system, defining the external interfaces through which DeepCode interacts with code repositories, documentation, and execution environments.</p>
</div>
<section class="ltx_subsection" id="A1.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A.1 </span>Full Results</h3>
<div class="ltx_para" id="A1.SS1.p1">
<p class="ltx_p">This appendix reports quantitative results that complement the main text and provide a more systematic evaluation of DeepCodeâ€™s overall capability and stability on research code reproduction tasks. TableÂ <a class="ltx_ref" href="https://arxiv.org/html/2512.07921v1#A1.T2" title="Table 2 â€£ A.1 Full Results â€£ Appendix A Appendix â€£ DeepCode: Open Agentic Coding"><span class="ltx_text ltx_ref_tag">2</span></a> first compares, under a unified evaluation protocol, a range of general-purpose code execution agents (including both BasicAgent and IterativeAgent configurations), existing specialized reproduction systems such as PaperCoder, and human experts on the same benchmark. DeepCode achieves an average reproduction score of <math alttext="73.5\pm 2.8" class="ltx_Math" display="inline" id="A1.SS1.p1.m1" intent=":literal"><semantics><mrow><mn>73.5</mn><mo>Â±</mo><mn>2.8</mn></mrow><annotation encoding="application/x-tex">73.5\pm 2.8</annotation></semantics></math> on the full benchmark, substantially outperforming PaperCoder (<math alttext="51.1\pm 1.4" class="ltx_Math" display="inline" id="A1.SS1.p1.m2" intent=":literal"><semantics><mrow><mn>51.1</mn><mo>Â±</mo><mn>1.4</mn></mrow><annotation encoding="application/x-tex">51.1\pm 1.4</annotation></semantics></math>) as well as all configurations derived from commercial models. On the 3-paper subset, DeepCode attains an average score of <math alttext="75.9\pm 4.5" class="ltx_Math" display="inline" id="A1.SS1.p1.m3" intent=":literal"><semantics><mrow><mn>75.9</mn><mo>Â±</mo><mn>4.5</mn></mrow><annotation encoding="application/x-tex">75.9\pm 4.5</annotation></semantics></math>, exceeding the human â€œBest@3â€ score of 72.4, indicating that, on representative deep learning papers, the system delivers reproduction quality comparable to or better than that of strong human practitioners.</p>
</div>
<div class="ltx_para" id="A1.SS1.p2">
<p class="ltx_p">TableÂ <a class="ltx_ref" href="https://arxiv.org/html/2512.07921v1#S4.T1" title="Table 1 â€£ 4.2 Main Results â€£ 4 Experiments â€£ DeepCode: Open Agentic Coding"><span class="ltx_text ltx_ref_tag">1</span></a> further selects a 5-paper subset (fre, rice, bam, pinn, mech-u) for a head-to-head comparison against several widely used commercial code assistants (Codex, Claude Code, Cursor, etc.). Across all papers, DeepCode achieves the highest reproduction score, with an average of 0.8482, corresponding to an absolute improvement of more than 0.26 over the strongest competing system. The advantage is consistent across all individual papers, suggesting that the gains arise from architectural and procedural design choices rather than from favorable alignment with a narrow subset of tasks.</p>
</div>
<div class="ltx_para" id="A1.SS1.p3">
<p class="ltx_p">Finally, TableÂ <a class="ltx_ref" href="https://arxiv.org/html/2512.07921v1#A1.T3" title="Table 3 â€£ A.1 Full Results â€£ Appendix A Appendix â€£ DeepCode: Open Agentic Coding"><span class="ltx_text ltx_ref_tag">3</span></a> provides per-paper details for the Claude 4.5 Sonnetâ€“based configuration, including three independent runs, their mean and standard error, as well as the associated average cost. Across a diverse set of targetsâ€”such as FRE, PINN, MECHANISTIC-UNDERSTANDING, and SEQUENTIAL-NEURAL-SCORE-ESTIMATIONâ€”DeepCodeâ€™s reproduction scores typically lie in the 0.7â€“0.9 range with relatively small standard errors, while the distribution of average cost across papers remains tight. This indicates strong cross-task generalization, stable behavior across repeated runs, and reasonable resource usage. Taken together, these appendix results reinforce the main conclusions of the paper: on realistic research code reproduction benchmarks, DeepCode not only achieves significantly higher average performance than existing automated reproduction and code assistance systems, but also demonstrates robust and consistent advantages in fine-grained, multi-paper, multi-run analyses.</p>
</div>
<figure class="ltx_table" id="A1.T2">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span class="ltx_text" style="font-size:90%;">Table 2</span>: </span><span class="ltx_text" style="font-size:90%;">Average reproduction scores: DeepCode vs. LLMs and human experts</span></figcaption>
<table class="ltx_tabular ltx_centering ltx_align_middle">
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;"><span class="ltx_text ltx_font_bold">Model</span></td>
<td class="ltx_td ltx_align_right ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;"><span class="ltx_text ltx_font_bold">Average Replication Scores</span></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;">GEMINI-2.0-FLASH (BasicAgent)</td>
<td class="ltx_td ltx_align_right ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;"><math alttext="5.0\pm 0.0" class="ltx_Math" display="inline" id="A1.T2.m1" intent=":literal"><semantics><mrow><mn>5.0</mn><mo>Â±</mo><mn>0.0</mn></mrow><annotation encoding="application/x-tex">5.0\pm 0.0</annotation></semantics></math></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left" style="padding-top:1pt;padding-bottom:1pt;">4o (BasicAgent)</td>
<td class="ltx_td ltx_align_right" style="padding-top:1pt;padding-bottom:1pt;"><math alttext="7.7\pm 0.0" class="ltx_Math" display="inline" id="A1.T2.m2" intent=":literal"><semantics><mrow><mn>7.7</mn><mo>Â±</mo><mn>0.0</mn></mrow><annotation encoding="application/x-tex">7.7\pm 0.0</annotation></semantics></math></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left" style="padding-top:1pt;padding-bottom:1pt;">o3-mini (BasicAgent)</td>
<td class="ltx_td ltx_align_right" style="padding-top:1pt;padding-bottom:1pt;"><math alttext="5.1\pm 0.8" class="ltx_Math" display="inline" id="A1.T2.m3" intent=":literal"><semantics><mrow><mn>5.1</mn><mo>Â±</mo><mn>0.8</mn></mrow><annotation encoding="application/x-tex">5.1\pm 0.8</annotation></semantics></math></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left" style="padding-top:1pt;padding-bottom:1pt;">o1 (BasicAgent)</td>
<td class="ltx_td ltx_align_right" style="padding-top:1pt;padding-bottom:1pt;"><math alttext="19.5\pm 1.2" class="ltx_Math" display="inline" id="A1.T2.m4" intent=":literal"><semantics><mrow><mn>19.5</mn><mo>Â±</mo><mn>1.2</mn></mrow><annotation encoding="application/x-tex">19.5\pm 1.2</annotation></semantics></math></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left" style="padding-top:1pt;padding-bottom:1pt;">R1 (BasicAgent)</td>
<td class="ltx_td ltx_align_right" style="padding-top:1pt;padding-bottom:1pt;"><math alttext="9.8\pm 0.0" class="ltx_Math" display="inline" id="A1.T2.m5" intent=":literal"><semantics><mrow><mn>9.8</mn><mo>Â±</mo><mn>0.0</mn></mrow><annotation encoding="application/x-tex">9.8\pm 0.0</annotation></semantics></math></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left" style="padding-top:1pt;padding-bottom:1pt;">CLAUDE-3-5-SONNET (BasicAgent)</td>
<td class="ltx_td ltx_align_right" style="padding-top:1pt;padding-bottom:1pt;"><math alttext="35.4\pm 0.8" class="ltx_Math" display="inline" id="A1.T2.m6" intent=":literal"><semantics><mrow><mn>35.4</mn><mo>Â±</mo><mn>0.8</mn></mrow><annotation encoding="application/x-tex">35.4\pm 0.8</annotation></semantics></math></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left" style="padding-top:1pt;padding-bottom:1pt;">o3-mini (IterativeAgent)</td>
<td class="ltx_td ltx_align_right" style="padding-top:1pt;padding-bottom:1pt;"><math alttext="16.4\pm 1.4" class="ltx_Math" display="inline" id="A1.T2.m7" intent=":literal"><semantics><mrow><mn>16.4</mn><mo>Â±</mo><mn>1.4</mn></mrow><annotation encoding="application/x-tex">16.4\pm 1.4</annotation></semantics></math></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left" style="padding-top:1pt;padding-bottom:1pt;">o1 (IterativeAgent)</td>
<td class="ltx_td ltx_align_right" style="padding-top:1pt;padding-bottom:1pt;"><math alttext="43.3\pm 1.1" class="ltx_Math" display="inline" id="A1.T2.m8" intent=":literal"><semantics><mrow><mn>43.3</mn><mo>Â±</mo><mn>1.1</mn></mrow><annotation encoding="application/x-tex">43.3\pm 1.1</annotation></semantics></math></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left" style="padding-top:1pt;padding-bottom:1pt;">CLAUDE-3-5-SONNET (IterativeAgent)</td>
<td class="ltx_td ltx_align_right" style="padding-top:1pt;padding-bottom:1pt;"><math alttext="27.5\pm 1.6" class="ltx_Math" display="inline" id="A1.T2.m9" intent=":literal"><semantics><mrow><mn>27.5</mn><mo>Â±</mo><mn>1.6</mn></mrow><annotation encoding="application/x-tex">27.5\pm 1.6</annotation></semantics></math></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left" style="padding-top:1pt;padding-bottom:1pt;">o1 [36 hours] (IterativeAgent)</td>
<td class="ltx_td ltx_align_right" style="padding-top:1pt;padding-bottom:1pt;"><math alttext="42.4\pm 1.0" class="ltx_Math" display="inline" id="A1.T2.m10" intent=":literal"><semantics><mrow><mn>42.4</mn><mo>Â±</mo><mn>1.0</mn></mrow><annotation encoding="application/x-tex">42.4\pm 1.0</annotation></semantics></math></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;">PaperCoder</td>
<td class="ltx_td ltx_align_right ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;"><math alttext="51.1\pm 1.4" class="ltx_Math" display="inline" id="A1.T2.m11" intent=":literal"><semantics><mrow><mn>51.1</mn><mo>Â±</mo><mn>1.4</mn></mrow><annotation encoding="application/x-tex">51.1\pm 1.4</annotation></semantics></math></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left" style="padding-top:1pt;padding-bottom:1pt;"><span class="ltx_text ltx_font_bold">DeepCode</span></td>
<td class="ltx_td ltx_align_right" style="padding-top:1pt;padding-bottom:1pt;">
<span class="ltx_text ltx_font_bold">73.6</span> <math alttext="\bf{\pm}" class="ltx_Math" display="inline" id="A1.T2.m12" intent=":literal"><semantics><mo>Â±</mo><annotation encoding="application/x-tex">\bf{\pm}</annotation></semantics></math> <span class="ltx_text ltx_font_bold">5.3</span>
</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_tt" style="padding-top:1pt;padding-bottom:1pt;">
<span class="ltx_text ltx_font_bold">Human</span> [3 paper subset, Best@3]</td>
<td class="ltx_td ltx_align_right ltx_border_tt" style="padding-top:1pt;padding-bottom:1pt;">72.4</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_bb" style="padding-top:1pt;padding-bottom:1pt;">
<span class="ltx_text ltx_font_bold">DeepCode</span> [3 paper subset, Average]</td>
<td class="ltx_td ltx_align_right ltx_border_bb" style="padding-top:1pt;padding-bottom:1pt;">
<span class="ltx_text ltx_font_bold">76.7</span> <math alttext="\bf{\pm}" class="ltx_Math" display="inline" id="A1.T2.m13" intent=":literal"><semantics><mo>Â±</mo><annotation encoding="application/x-tex">\bf{\pm}</annotation></semantics></math> <span class="ltx_text ltx_font_bold">3.9</span>
</td>
</tr>
</table>
</figure>
<figure class="ltx_table" id="A1.T3">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span class="ltx_text" style="font-size:90%;">Table 3</span>: </span><span class="ltx_text" style="font-size:90%;">DeepCode with Claude 4.5 Sonnet results.</span></figcaption>
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:345.0pt;height:159.5pt;vertical-align:-78.2pt;"><span class="ltx_transformed_inner" style="transform:translate(-101.3pt,46.9pt) scale(0.629936511034836,0.629936511034836) ;">
<table class="ltx_tabular ltx_align_middle">
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_tt" style="padding:0.5pt 4.0pt;"><span class="ltx_text ltx_font_bold">Paper</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" style="padding:0.5pt 4.0pt;"><span class="ltx_text ltx_font_bold">Run 1</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" style="padding:0.5pt 4.0pt;"><span class="ltx_text ltx_font_bold">Run 2</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" style="padding:0.5pt 4.0pt;"><span class="ltx_text ltx_font_bold">Run 3</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" style="padding:0.5pt 4.0pt;"><span class="ltx_text ltx_font_bold">Mean</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" style="padding:0.5pt 4.0pt;"><span class="ltx_text ltx_font_bold">Std. Error</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_center ltx_border_tt" style="padding:0.5pt 4.0pt;"><span class="ltx_text ltx_font_bold">Avg. Cost</span></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_t" style="padding:0.5pt 4.0pt;">FRE</td>
<td class="ltx_td ltx_align_center ltx_border_t" style="padding:0.5pt 4.0pt;">0.844</td>
<td class="ltx_td ltx_align_center ltx_border_t" style="padding:0.5pt 4.0pt;">0.823</td>
<td class="ltx_td ltx_align_center ltx_border_t" style="padding:0.5pt 4.0pt;">0.803</td>
<td class="ltx_td ltx_align_center ltx_border_t" style="padding:0.5pt 4.0pt;">0.814</td>
<td class="ltx_td ltx_align_center ltx_border_t" style="padding:0.5pt 4.0pt;">0.020</td>
<td class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t" style="padding:0.5pt 4.0pt;">9.14</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left" style="padding:0.5pt 4.0pt;">RICE</td>
<td class="ltx_td ltx_align_center" style="padding:0.5pt 4.0pt;">0.738</td>
<td class="ltx_td ltx_align_center" style="padding:0.5pt 4.0pt;">0.609</td>
<td class="ltx_td ltx_align_center" style="padding:0.5pt 4.0pt;">0.761</td>
<td class="ltx_td ltx_align_center" style="padding:0.5pt 4.0pt;">0.702</td>
<td class="ltx_td ltx_align_center" style="padding:0.5pt 4.0pt;">0.082</td>
<td class="ltx_td ltx_nopad_r ltx_align_center" style="padding:0.5pt 4.0pt;">8.22</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left" style="padding:0.5pt 4.0pt;">BAM</td>
<td class="ltx_td ltx_align_center" style="padding:0.5pt 4.0pt;">0.853</td>
<td class="ltx_td ltx_align_center" style="padding:0.5pt 4.0pt;">0.673</td>
<td class="ltx_td ltx_align_center" style="padding:0.5pt 4.0pt;">0.719</td>
<td class="ltx_td ltx_align_center" style="padding:0.5pt 4.0pt;">0.748</td>
<td class="ltx_td ltx_align_center" style="padding:0.5pt 4.0pt;">0.094</td>
<td class="ltx_td ltx_nopad_r ltx_align_center" style="padding:0.5pt 4.0pt;">8.45</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left" style="padding:0.5pt 4.0pt;">WILL-MODEL-FORGET</td>
<td class="ltx_td ltx_align_center" style="padding:0.5pt 4.0pt;">0.776</td>
<td class="ltx_td ltx_align_center" style="padding:0.5pt 4.0pt;">0.793</td>
<td class="ltx_td ltx_align_center" style="padding:0.5pt 4.0pt;">0.857</td>
<td class="ltx_td ltx_align_center" style="padding:0.5pt 4.0pt;">0.808</td>
<td class="ltx_td ltx_align_center" style="padding:0.5pt 4.0pt;">0.042</td>
<td class="ltx_td ltx_nopad_r ltx_align_center" style="padding:0.5pt 4.0pt;">9.20</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left" style="padding:0.5pt 4.0pt;">PINN</td>
<td class="ltx_td ltx_align_center" style="padding:0.5pt 4.0pt;">0.947</td>
<td class="ltx_td ltx_align_center" style="padding:0.5pt 4.0pt;">0.800</td>
<td class="ltx_td ltx_align_center" style="padding:0.5pt 4.0pt;">0.983</td>
<td class="ltx_td ltx_align_center" style="padding:0.5pt 4.0pt;">0.910</td>
<td class="ltx_td ltx_align_center" style="padding:0.5pt 4.0pt;">0.097</td>
<td class="ltx_td ltx_nopad_r ltx_align_center" style="padding:0.5pt 4.0pt;">7.84</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left" style="padding:0.5pt 4.0pt;">ALL-IN-ONE</td>
<td class="ltx_td ltx_align_center" style="padding:0.5pt 4.0pt;">0.769</td>
<td class="ltx_td ltx_align_center" style="padding:0.5pt 4.0pt;">0.747</td>
<td class="ltx_td ltx_align_center" style="padding:0.5pt 4.0pt;">0.759</td>
<td class="ltx_td ltx_align_center" style="padding:0.5pt 4.0pt;">0.759</td>
<td class="ltx_td ltx_align_center" style="padding:0.5pt 4.0pt;">0.011</td>
<td class="ltx_td ltx_nopad_r ltx_align_center" style="padding:0.5pt 4.0pt;">9.43</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left" style="padding:0.5pt 4.0pt;">ADAPTIVE-PRUNING</td>
<td class="ltx_td ltx_align_center" style="padding:0.5pt 4.0pt;">0.547</td>
<td class="ltx_td ltx_align_center" style="padding:0.5pt 4.0pt;">0.570</td>
<td class="ltx_td ltx_align_center" style="padding:0.5pt 4.0pt;">0.516</td>
<td class="ltx_td ltx_align_center" style="padding:0.5pt 4.0pt;">0.544</td>
<td class="ltx_td ltx_align_center" style="padding:0.5pt 4.0pt;">0.027</td>
<td class="ltx_td ltx_nopad_r ltx_align_center" style="padding:0.5pt 4.0pt;">9.13</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left" style="padding:0.5pt 4.0pt;">LBCS</td>
<td class="ltx_td ltx_align_center" style="padding:0.5pt 4.0pt;">0.689</td>
<td class="ltx_td ltx_align_center" style="padding:0.5pt 4.0pt;">0.732</td>
<td class="ltx_td ltx_align_center" style="padding:0.5pt 4.0pt;">0.820</td>
<td class="ltx_td ltx_align_center" style="padding:0.5pt 4.0pt;">0.747</td>
<td class="ltx_td ltx_align_center" style="padding:0.5pt 4.0pt;">0.066</td>
<td class="ltx_td ltx_nopad_r ltx_align_center" style="padding:0.5pt 4.0pt;">10.01</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left" style="padding:0.5pt 4.0pt;">MECHANISTIC-UNDERSTANDING</td>
<td class="ltx_td ltx_align_center" style="padding:0.5pt 4.0pt;">0.889</td>
<td class="ltx_td ltx_align_center" style="padding:0.5pt 4.0pt;">0.944</td>
<td class="ltx_td ltx_align_center" style="padding:0.5pt 4.0pt;">0.941</td>
<td class="ltx_td ltx_align_center" style="padding:0.5pt 4.0pt;">0.925</td>
<td class="ltx_td ltx_align_center" style="padding:0.5pt 4.0pt;">0.031</td>
<td class="ltx_td ltx_nopad_r ltx_align_center" style="padding:0.5pt 4.0pt;">10.20</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left" style="padding:0.5pt 4.0pt;">TEST-TIME-MODEL-ADAPTATION</td>
<td class="ltx_td ltx_align_center" style="padding:0.5pt 4.0pt;">0.717</td>
<td class="ltx_td ltx_align_center" style="padding:0.5pt 4.0pt;">0.578</td>
<td class="ltx_td ltx_align_center" style="padding:0.5pt 4.0pt;">0.652</td>
<td class="ltx_td ltx_align_center" style="padding:0.5pt 4.0pt;">0.649</td>
<td class="ltx_td ltx_align_center" style="padding:0.5pt 4.0pt;">0.069</td>
<td class="ltx_td ltx_nopad_r ltx_align_center" style="padding:0.5pt 4.0pt;">7.90</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left" style="padding:0.5pt 4.0pt;">SAMPLE-SPECIFIC-MASKS</td>
<td class="ltx_td ltx_align_center" style="padding:0.5pt 4.0pt;">0.690</td>
<td class="ltx_td ltx_align_center" style="padding:0.5pt 4.0pt;">0.740</td>
<td class="ltx_td ltx_align_center" style="padding:0.5pt 4.0pt;">0.583</td>
<td class="ltx_td ltx_align_center" style="padding:0.5pt 4.0pt;">0.671</td>
<td class="ltx_td ltx_align_center" style="padding:0.5pt 4.0pt;">0.080</td>
<td class="ltx_td ltx_nopad_r ltx_align_center" style="padding:0.5pt 4.0pt;">8.30</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left" style="padding:0.5pt 4.0pt;">BRIDGING-DATA-GAPS</td>
<td class="ltx_td ltx_align_center" style="padding:0.5pt 4.0pt;">0.552</td>
<td class="ltx_td ltx_align_center" style="padding:0.5pt 4.0pt;">0.566</td>
<td class="ltx_td ltx_align_center" style="padding:0.5pt 4.0pt;">0.626</td>
<td class="ltx_td ltx_align_center" style="padding:0.5pt 4.0pt;">0.581</td>
<td class="ltx_td ltx_align_center" style="padding:0.5pt 4.0pt;">0.039</td>
<td class="ltx_td ltx_nopad_r ltx_align_center" style="padding:0.5pt 4.0pt;">7.98</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left" style="padding:0.5pt 4.0pt;">STAY-ON-TOPIC-WITH-CLASSIFIER-FREE-GUIDANCE</td>
<td class="ltx_td ltx_align_center" style="padding:0.5pt 4.0pt;">0.734</td>
<td class="ltx_td ltx_align_center" style="padding:0.5pt 4.0pt;">0.800</td>
<td class="ltx_td ltx_align_center" style="padding:0.5pt 4.0pt;">0.626</td>
<td class="ltx_td ltx_align_center" style="padding:0.5pt 4.0pt;">0.705</td>
<td class="ltx_td ltx_align_center" style="padding:0.5pt 4.0pt;">0.088</td>
<td class="ltx_td ltx_nopad_r ltx_align_center" style="padding:0.5pt 4.0pt;">9.12</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left" style="padding:0.5pt 4.0pt;">STOCHASTIC-INTERPOLANTS</td>
<td class="ltx_td ltx_align_center" style="padding:0.5pt 4.0pt;">0.851</td>
<td class="ltx_td ltx_align_center" style="padding:0.5pt 4.0pt;">0.792</td>
<td class="ltx_td ltx_align_center" style="padding:0.5pt 4.0pt;">0.801</td>
<td class="ltx_td ltx_align_center" style="padding:0.5pt 4.0pt;">0.815</td>
<td class="ltx_td ltx_align_center" style="padding:0.5pt 4.0pt;">0.031</td>
<td class="ltx_td ltx_nopad_r ltx_align_center" style="padding:0.5pt 4.0pt;">8.89</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left" style="padding:0.5pt 4.0pt;">LCA-ON-THE-LINE</td>
<td class="ltx_td ltx_align_center" style="padding:0.5pt 4.0pt;">0.665</td>
<td class="ltx_td ltx_align_center" style="padding:0.5pt 4.0pt;">0.844</td>
<td class="ltx_td ltx_align_center" style="padding:0.5pt 4.0pt;">0.739</td>
<td class="ltx_td ltx_align_center" style="padding:0.5pt 4.0pt;">0.749</td>
<td class="ltx_td ltx_align_center" style="padding:0.5pt 4.0pt;">0.090</td>
<td class="ltx_td ltx_nopad_r ltx_align_center" style="padding:0.5pt 4.0pt;">7.73</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left" style="padding:0.5pt 4.0pt;">SEQUENTIAL-NEURAL-SCORE-ESTIMATION</td>
<td class="ltx_td ltx_align_center" style="padding:0.5pt 4.0pt;">0.930</td>
<td class="ltx_td ltx_align_center" style="padding:0.5pt 4.0pt;">0.862</td>
<td class="ltx_td ltx_align_center" style="padding:0.5pt 4.0pt;">0.817</td>
<td class="ltx_td ltx_align_center" style="padding:0.5pt 4.0pt;">0.870</td>
<td class="ltx_td ltx_align_center" style="padding:0.5pt 4.0pt;">0.057</td>
<td class="ltx_td ltx_nopad_r ltx_align_center" style="padding:0.5pt 4.0pt;">10.01</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left" style="padding:0.5pt 4.0pt;">SAPG</td>
<td class="ltx_td ltx_align_center" style="padding:0.5pt 4.0pt;">0.702</td>
<td class="ltx_td ltx_align_center" style="padding:0.5pt 4.0pt;">0.755</td>
<td class="ltx_td ltx_align_center" style="padding:0.5pt 4.0pt;">0.757</td>
<td class="ltx_td ltx_align_center" style="padding:0.5pt 4.0pt;">0.738</td>
<td class="ltx_td ltx_align_center" style="padding:0.5pt 4.0pt;">0.031</td>
<td class="ltx_td ltx_nopad_r ltx_align_center" style="padding:0.5pt 4.0pt;">9.19</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left" style="padding:0.5pt 4.0pt;">FTRL</td>
<td class="ltx_td ltx_align_center" style="padding:0.5pt 4.0pt;">0.558</td>
<td class="ltx_td ltx_align_center" style="padding:0.5pt 4.0pt;">0.606</td>
<td class="ltx_td ltx_align_center" style="padding:0.5pt 4.0pt;">0.631</td>
<td class="ltx_td ltx_align_center" style="padding:0.5pt 4.0pt;">0.598</td>
<td class="ltx_td ltx_align_center" style="padding:0.5pt 4.0pt;">0.037</td>
<td class="ltx_td ltx_nopad_r ltx_align_center" style="padding:0.5pt 4.0pt;">7.06</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left" style="padding:0.5pt 4.0pt;">ROBUST-CLIP</td>
<td class="ltx_td ltx_align_center" style="padding:0.5pt 4.0pt;">0.772</td>
<td class="ltx_td ltx_align_center" style="padding:0.5pt 4.0pt;">0.742</td>
<td class="ltx_td ltx_align_center" style="padding:0.5pt 4.0pt;">0.685</td>
<td class="ltx_td ltx_align_center" style="padding:0.5pt 4.0pt;">0.733</td>
<td class="ltx_td ltx_align_center" style="padding:0.5pt 4.0pt;">0.044</td>
<td class="ltx_td ltx_nopad_r ltx_align_center" style="padding:0.5pt 4.0pt;">7.83</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_bb" style="padding:0.5pt 4.0pt;">BBOX</td>
<td class="ltx_td ltx_align_center ltx_border_bb" style="padding:0.5pt 4.0pt;">0.620</td>
<td class="ltx_td ltx_align_center ltx_border_bb" style="padding:0.5pt 4.0pt;">0.681</td>
<td class="ltx_td ltx_align_center ltx_border_bb" style="padding:0.5pt 4.0pt;">0.631</td>
<td class="ltx_td ltx_align_center ltx_border_bb" style="padding:0.5pt 4.0pt;">0.644</td>
<td class="ltx_td ltx_align_center ltx_border_bb" style="padding:0.5pt 4.0pt;">0.033</td>
<td class="ltx_td ltx_nopad_r ltx_align_center ltx_border_bb" style="padding:0.5pt 4.0pt;">11.90</td>
</tr>
</table>
</span></div>
</figure>
</section>
<section class="ltx_subsection" id="A1.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A.2 </span>Use Cases for DeepCode</h3>
<div class="ltx_para" id="A1.SS2.p1">
<p class="ltx_p">This appendix provides a series of visual artifacts generated by DeepCode, offering concrete evidence of its capabilities across different software development and research domains. These examples are intended to supplement the main paper by illustrating the practical utility and versatility of our system.</p>
</div>
<div class="ltx_para" id="A1.SS2.p2">
<p class="ltx_p">The initial set of examples, depicted in Figure <a class="ltx_ref" href="https://arxiv.org/html/2512.07921v1#A1.F7" title="Figure 7 â€£ A.2 Use Cases for DeepCode â€£ Appendix A Appendix â€£ DeepCode: Open Agentic Coding"><span class="ltx_text ltx_ref_tag">7</span></a>, focuses on DeepCodeâ€™s proficiency in generating sophisticated backend systems. The figures showcase automatically constructed administrative dashboards, which likely include functionalities for data monitoring, user management, and content moderation. Such pages are critical for the operational management of modern web applications but are often tedious and repetitive to build. DeepCodeâ€™s ability to scaffold these complex, data-driven interfaces from high-level specifications demonstrates its potential to significantly reduce boilerplate engineering and accelerate the deployment of robust server-side infrastructure.</p>
</div>
<div class="ltx_para" id="A1.SS2.p3">
<p class="ltx_p">Building upon the backend logic, a systemâ€™s utility is often defined by its user-facing presentation. Figure <a class="ltx_ref" href="https://arxiv.org/html/2512.07921v1#A1.F8" title="Figure 8 â€£ A.2 Use Cases for DeepCode â€£ Appendix A Appendix â€£ DeepCode: Open Agentic Coding"><span class="ltx_text ltx_ref_tag">8</span></a> illustrates DeepCodeâ€™s capacity for generating intuitive and functional Web UIs. The generated interfaces, featuring elements such as data visualization charts and interactive forms, translate abstract user requirements into tangible, interactive components. This capability not only complements the backend generation by providing a corresponding frontend, but also empowers developers and designers to rapidly prototype and iterate on user experiences, thereby shortening the path from concept to a functional product.</p>
</div>
<div class="ltx_para" id="A1.SS2.p4">
<p class="ltx_p">Perhaps DeepCodeâ€™s most ambitious application, however, lies in its potential to bridge the chasm between academic research and practical implementation. The Paper2Code functionality, illustrated in Figure <a class="ltx_ref" href="https://arxiv.org/html/2512.07921v1#A1.F9" title="Figure 9 â€£ A.2 Use Cases for DeepCode â€£ Appendix A Appendix â€£ DeepCode: Open Agentic Coding"><span class="ltx_text ltx_ref_tag">9</span></a>, exemplifies this capability. The figure is twofold: on the left, it presents the high-level code structure that DeepCode inferred from a research paper, discerning the architectural blueprint of the proposed algorithm, including its modular components and file organization. On the right, it provides a concrete code sample, instantiating a specific function or class with precise logic. This powerful feature moves beyond conventional code generation by interpreting unstructured scientific language to produce structured, executable artifacts, thereby holding immense promise for enhancing research reproducibility and accelerating the adoption of novel scientific discoveries.</p>
</div>
<figure class="ltx_figure" id="A1.F7">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_landscape" height="224" id="A1.F7.g1" src="x8.png" width="317"/></div>
<div class="ltx_flex_cell ltx_flex_size_2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_landscape" height="224" id="A1.F7.g2" src="x9.png" width="317"/></div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" style="font-size:90%;">Figure 7</span>: </span><span class="ltx_text" style="font-size:90%;">DeepCode-generated backend system pages.</span></figcaption>
</figure>
<figure class="ltx_figure" id="A1.F8">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_landscape" height="224" id="A1.F8.g1" src="x10.png" width="317"/></div>
<div class="ltx_flex_cell ltx_flex_size_2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_landscape" height="224" id="A1.F8.g2" src="x11.png" width="317"/></div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" style="font-size:90%;">Figure 8</span>: </span><span class="ltx_text" style="font-size:90%;">DeepCode-generated Web UI.</span></figcaption>
</figure>
<figure class="ltx_figure" id="A1.F9">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_portrait" height="213" id="A1.F9.g1" src="figs/appendix/paper1.png" width="91"/></div>
<div class="ltx_flex_cell ltx_flex_size_2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_landscape" height="214" id="A1.F9.g2" src="figs/appendix/paper2.png" width="333"/></div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" style="font-size:90%;">Figure 9</span>: </span><span class="ltx_text" style="font-size:90%;">Paper2Code Samples of DeepCode. Left: Code Structure, Right: Code Sample</span></figcaption>
</figure>
</section>
<section class="ltx_subsection" id="A1.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A.3 </span>Sub-Agents Details of DeepCode</h3>
<div class="ltx_para" id="A1.SS3.p1">
<p class="ltx_p">DeepCode decomposes the software engineering pipeline into a set of specialized
agents with narrow, well-specified responsibilities and standardized
communication interfaces, rather than relying on a single monolithic generative
model. The individual agents and their responsibilities are summarized in
TableÂ <a class="ltx_ref" href="https://arxiv.org/html/2512.07921v1#A1.T4" title="Table 4 â€£ A.3 Sub-Agents Details of DeepCode â€£ Appendix A Appendix â€£ DeepCode: Open Agentic Coding"><span class="ltx_text ltx_ref_tag">4</span></a>. This modular design allows different stages of
the lifecycleâ€”ranging from requirement understanding to architectural planning
and code synthesisâ€”to be implemented as transformations over shared
intermediate representations, while preserving global architectural and
semantic consistency.</p>
</div>
<div class="ltx_para" id="A1.SS3.p2">
<p class="ltx_p"><span class="ltx_text ltx_font_bold">During the planning stage, DeepCode relies on explicit coordination
between conceptual and algorithmic analysis agents to derive a coherent
development blueprint from high-level specifications.</span>
The Central Orchestrating Agent first routes each input through the Document
Parsing and/or Intent Understanding agents to obtain a structured
specification, which then serves as the input to the Code Planning agent.
Within this planning module, two internal analysis pipelines operate in
parallel over the same intermediate representation. The conceptual analysis
sub-agent is responsible for system-level decomposition: it identifies major
subsystems, their responsibilities, and inter-module interfaces, and it
constructs an architecture-level call topology. The algorithmic analysis
sub-agent is responsible for computational aspects: it abstracts key
algorithmic ideas, selects candidate data structures, reasons about time and
space complexity constraints, and enumerates feasible implementation patterns.
The partial plans produced by these two sub-agents are reconciled by a
planning aggregation component (Code Analysis agent), which resolves
inconsistencies and materializes a project-level development roadmap, including
module boundaries, interface signatures, dependency relations, implementation
priorities, and testing hooks. This roadmap serves as the design baseline that
constrains all downstream code generation and refinement steps.</p>
</div>
<div class="ltx_para" id="A1.SS3.p3">
<p class="ltx_p"><span class="ltx_text ltx_font_bold">During the code synthesis stage, DeepCode couples retrieval-augmented
reference mining with a global code memory, forming a closed-loop process that
enforces repository-level consistency during incremental generation.</span>
On the retrieval side, the Code Reference Mining and Code Indexing agents
implement a Retrieval-Augmented Generation (RAG) layer: they maintain
multi-granularity indices over a corpus of prior implementations and expose to
the Code Generation agent semantically relevant and structurally compatible
code patterns, ranging from individual functions to reusable design idioms. In
parallel, the Code Memory agent maintains a structured representation of the
current repository state, including cross-file symbol tables, dependency
graphs, and project-wide conventions such as naming schemes, error-handling
strategies, and configuration mechanisms. Before emitting new code, the Code
Generation agent issues queries to the Code Memory agent to obtain the
up-to-date repository context and applicable constraints; after generation, it
writes back the newly introduced symbols and dependencies, triggering an update
of the global repository model. This queryâ€“constraintâ€“update loop allows
DeepCode to align local synthesis decisions with global architectural intent,
reducing interface mismatches, naming drift, and latent coupling across the
codebase.</p>
</div>
<figure class="ltx_table" id="A1.T4">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span class="ltx_text" style="font-size:90%;">Table 4</span>: </span><span class="ltx_text" style="font-size:90%;">Functional Specifications of Specialized Sub-Agents in the DeepCode Framework</span></figcaption>
<table class="ltx_tabular ltx_centering ltx_align_middle">
<tr class="ltx_tr">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt" style="padding-top:2pt;padding-bottom:2pt;">
<span class="ltx_inline-block ltx_align_top">
<span class="ltx_p" style="width:121.4pt;"><span class="ltx_text ltx_font_bold">Agent Role</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt" style="padding-top:2pt;padding-bottom:2pt;">
<span class="ltx_inline-block ltx_align_top">
<span class="ltx_p" style="width:290.5pt;"><span class="ltx_text ltx_font_bold">Functional Description</span></span>
</span>
</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:2pt;padding-bottom:2pt;">
<span class="ltx_inline-block ltx_align_top">
<span class="ltx_p" style="width:121.4pt;"><span class="ltx_text ltx_font_bold">Central Orchestrating Agent</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:2pt;padding-bottom:2pt;">
<span class="ltx_inline-block ltx_align_top">
<span class="ltx_p" style="width:290.5pt;">Functions as the central control unit, responsible for task decomposition, resource allocation, and the strategic coordination of sub-agents based on the complexity of the input requirements.</span>
</span>
</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:2pt;padding-bottom:2pt;">
<span class="ltx_inline-block ltx_align_top">
<span class="ltx_p" style="width:121.4pt;"><span class="ltx_text ltx_font_bold">Intent Understanding Agent</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:2pt;padding-bottom:2pt;">
<span class="ltx_inline-block ltx_align_top">
<span class="ltx_p" style="width:290.5pt;">Conducts semantic parsing of natural language inputs to extract functional requirements, converting ambiguous user descriptions into formal technical specifications.</span>
</span>
</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:2pt;padding-bottom:2pt;">
<span class="ltx_inline-block ltx_align_top">
<span class="ltx_p" style="width:121.4pt;"><span class="ltx_text ltx_font_bold">Document Parsing Agent</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:2pt;padding-bottom:2pt;">
<span class="ltx_inline-block ltx_align_top">
<span class="ltx_p" style="width:290.5pt;">Processes unstructured technical documents (e.g., research papers). It extracts multimodal information, including text, mathematical formulas, and diagrams, to establish a ground truth for implementation.</span>
</span>
</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:2pt;padding-bottom:2pt;">
<span class="ltx_inline-block ltx_align_top">
<span class="ltx_p" style="width:121.4pt;"><span class="ltx_text ltx_font_bold">Concept Analysis Agent</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:2pt;padding-bottom:2pt;">
<span class="ltx_inline-block ltx_align_top">
<span class="ltx_p" style="width:290.5pt;">Abstracts core theoretical concepts and logical flows from the parsed specifications, ensuring the computational model aligns with the theoretical underpinnings of the source material.</span>
</span>
</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:2pt;padding-bottom:2pt;">
<span class="ltx_inline-block ltx_align_top">
<span class="ltx_p" style="width:121.4pt;"><span class="ltx_text ltx_font_bold">Algorithm Analysis Agent</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:2pt;padding-bottom:2pt;">
<span class="ltx_inline-block ltx_align_top">
<span class="ltx_p" style="width:290.5pt;">Evaluates and selects appropriate algorithmic strategies and data structures. It focuses on optimizing computational complexity and feasibility before code synthesis begins.</span>
</span>
</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:2pt;padding-bottom:2pt;">
<span class="ltx_inline-block ltx_align_top">
<span class="ltx_p" style="width:121.4pt;"><span class="ltx_text ltx_font_bold">Code Planning Agent</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:2pt;padding-bottom:2pt;">
<span class="ltx_inline-block ltx_align_top">
<span class="ltx_p" style="width:290.5pt;">Formulates the software architecture and development roadmap. This agent determines the technology stack, designs modular file structures, and enforces design patterns to ensure scalability.</span>
</span>
</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:2pt;padding-bottom:2pt;">
<span class="ltx_inline-block ltx_align_top">
<span class="ltx_p" style="width:121.4pt;"><span class="ltx_text ltx_font_bold">Code Reference Mining Agent</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:2pt;padding-bottom:2pt;">
<span class="ltx_inline-block ltx_align_top">
<span class="ltx_p" style="width:290.5pt;">Retrieves external knowledge by identifying relevant open-source repositories. It analyzes dependency graphs to recommend integration patterns and library usages.</span>
</span>
</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:2pt;padding-bottom:2pt;">
<span class="ltx_inline-block ltx_align_top">
<span class="ltx_p" style="width:121.4pt;"><span class="ltx_text ltx_font_bold">Code Memory Agent</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:2pt;padding-bottom:2pt;">
<span class="ltx_inline-block ltx_align_top">
<span class="ltx_p" style="width:290.5pt;">Manages the state and context throughout the generation lifecycle. It utilizes hierarchical data structures to retain historical decisions and maintain semantic consistency across long-context interactions.</span>
</span>
</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:2pt;padding-bottom:2pt;">
<span class="ltx_inline-block ltx_align_top">
<span class="ltx_p" style="width:121.4pt;"><span class="ltx_text ltx_font_bold">Code Generation Agent</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:2pt;padding-bottom:2pt;">
<span class="ltx_inline-block ltx_align_top">
<span class="ltx_p" style="width:290.5pt;">Synthesizes executable source code based on the architectural plan and retrieved references. It implements functional interfaces and integrates distinct modules into a cohesive codebase.</span>
</span>
</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb" style="padding-top:2pt;padding-bottom:2pt;">
<span class="ltx_inline-block ltx_align_top">
<span class="ltx_p" style="width:121.4pt;"><span class="ltx_text ltx_font_bold">Automated Validation Agent</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb" style="padding-top:2pt;padding-bottom:2pt;">
<span class="ltx_inline-block ltx_align_top">
<span class="ltx_p" style="width:290.5pt;">Executes a rigorous quality assurance loop. It performs static analysis, generates unit tests, and iteratively debugs the codebase to verify functional correctness and adherence to specifications.</span>
</span>
</td>
</tr>
</table>
</figure>
</section>
<section class="ltx_subsection" id="A1.SS4">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A.4 </span>MCP Tool Stack in DeepCode</h3>
<div class="ltx_para" id="A1.SS4.p1">
<p class="ltx_p">TableÂ <a class="ltx_ref" href="https://arxiv.org/html/2512.07921v1#A1.T5" title="Table 5 â€£ A.4 MCP Tool Stack in DeepCode â€£ Appendix A Appendix â€£ DeepCode: Open Agentic Coding"><span class="ltx_text ltx_ref_tag">5</span></a> summarizes the Model Context Protocol (MCP) tools integrated into DeepCode. The tools are grouped into three functional categories: <em class="ltx_emph ltx_font_italic">Perception &amp; Retrieval</em>, <em class="ltx_emph ltx_font_italic">Cognitive Processing</em>, and <em class="ltx_emph ltx_font_italic">Action &amp; Execution</em>. This organization makes the main stages of the system explicit. Perception &amp; Retrieval tools give the model access to up-to-date web search results, web pages, and binary documents such as research papers and technical manuals, which helps mitigate the effects of the modelâ€™s knowledge cut-off. Cognitive Processing tools then convert large codebases and long documents into semantic indexes and context-window-compatible segments, so that the model can issue natural language queries over existing artifacts and work with long technical materials. Action &amp; Execution tools finally operate on the local development environment by reading and writing project files, executing shell commands, and interacting with the version control system.</p>
</div>
<div class="ltx_para" id="A1.SS4.p2">
<p class="ltx_p">Taken together, the tools in TableÂ <a class="ltx_ref" href="https://arxiv.org/html/2512.07921v1#A1.T5" title="Table 5 â€£ A.4 MCP Tool Stack in DeepCode â€£ Appendix A Appendix â€£ DeepCode: Open Agentic Coding"><span class="ltx_text ltx_ref_tag">5</span></a> form an end-to-end loop for assisted software development. The system can retrieve external and local information, reorganize it into internal structures that fit within the modelâ€™s context window, and then apply code changes while observing their effects through commands such as tests or package installations. The table also shows that operations with side effects on the environment (file I/O, command execution, and Git operations) are confined to the <em class="ltx_emph ltx_font_italic">Action &amp; Execution</em> layer and are described as sandboxed and path-validated. This separation between information access, semantic processing, and environment manipulation makes the extension of the base language model through MCP tools transparent and easier to reason about.</p>
</div>
<figure class="ltx_table" id="A1.T5">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span class="ltx_text" style="font-size:90%;">Table 5</span>: </span><span class="ltx_text" style="font-size:90%;">Specification of Model Context Protocol (MCP) Tools Integrated into DeepCode. These tools extend the Large Language Modelâ€™s capabilities across perception, cognitive processing, and environment manipulation domains</span></figcaption>
<table class="ltx_tabular ltx_centering ltx_align_middle">
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t" style="padding-top:2.3pt;padding-bottom:2.3pt;"><span class="ltx_text ltx_font_bold" style="font-size:90%;">Category</span></td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" style="padding-top:2.3pt;padding-bottom:2.3pt;"><span class="ltx_text ltx_font_bold" style="font-size:90%;">MCP Server Name</span></td>
<td class="ltx_td ltx_align_justify ltx_border_r ltx_border_t" style="padding-top:2.3pt;padding-bottom:2.3pt;">
<span class="ltx_inline-block ltx_align_top">
<span class="ltx_p"><span class="ltx_text ltx_font_bold" style="font-size:90%;">Functional Description &amp; Academic Specification</span></span>
</span>
</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t" rowspan="4" style="padding-top:2.3pt;padding-bottom:2.3pt;"><span class="ltx_text ltx_font_bold" style="font-size:90%;">Perception &amp; Retrieval</span></td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" style="padding-top:2.3pt;padding-bottom:2.3pt;"><span class="ltx_text ltx_font_typewriter" style="font-size:90%;">brave_search</span></td>
<td class="ltx_td ltx_align_justify ltx_border_r ltx_border_t" style="padding-top:2.3pt;padding-bottom:2.3pt;">
<span class="ltx_inline-block ltx_align_top">
<span class="ltx_p"><span class="ltx_text" style="font-size:90%;">A real-time information retrieval interface leveraging the Brave Search API. It provides the agent with temporal-aware access to web indices, enabling the retrieval of up-to-date documentation and resolving knowledge cut-off limitations.</span></span>
</span>
</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" style="padding-top:2.3pt;padding-bottom:2.3pt;"><span class="ltx_text ltx_font_typewriter" style="font-size:90%;">bocha_mcp</span></td>
<td class="ltx_td ltx_align_justify ltx_border_r ltx_border_t" style="padding-top:2.3pt;padding-bottom:2.3pt;">
<span class="ltx_inline-block ltx_align_top">
<span class="ltx_p"><span class="ltx_text" style="font-size:90%;">A specialized search module delivering structured "modal cards" and semantic summaries. It serves as a secondary knowledge source, optimizing token efficiency by returning structured entities rather than raw HTML.</span></span>
</span>
</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" style="padding-top:2.3pt;padding-bottom:2.3pt;"><span class="ltx_text ltx_font_typewriter" style="font-size:90%;">fetch</span></td>
<td class="ltx_td ltx_align_justify ltx_border_r ltx_border_t" style="padding-top:2.3pt;padding-bottom:2.3pt;">
<span class="ltx_inline-block ltx_align_top">
<span class="ltx_p"><span class="ltx_text" style="font-size:90%;">A web content ingestion engine that retrieves URL endpoints and normalizes heterogeneous HTML structures into clean Markdown. It acts as the agentâ€™s primary reading interface for external documentation.</span></span>
</span>
</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" style="padding-top:2.3pt;padding-bottom:2.3pt;"><span class="ltx_text ltx_font_typewriter" style="font-size:90%;">pdf_downloader</span></td>
<td class="ltx_td ltx_align_justify ltx_border_r ltx_border_t" style="padding-top:2.3pt;padding-bottom:2.3pt;">
<span class="ltx_inline-block ltx_align_top">
<span class="ltx_p"><span class="ltx_text" style="font-size:90%;">Binary resource acquisition tool designed for academic papers and technical manuals. It handles HTTP streams to ingest non-textual document formats (PDF/DOCX) for downstream processing.</span></span>
</span>
</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t" rowspan="2" style="padding-top:2.3pt;padding-bottom:2.3pt;"><span class="ltx_text ltx_font_bold" style="font-size:90%;">Cognitive Processing</span></td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" style="padding-top:2.3pt;padding-bottom:2.3pt;"><span class="ltx_text ltx_font_typewriter" style="font-size:90%;">code_reference_indexer</span></td>
<td class="ltx_td ltx_align_justify ltx_border_r ltx_border_t" style="padding-top:2.3pt;padding-bottom:2.3pt;">
<span class="ltx_inline-block ltx_align_top">
<span class="ltx_p"><span class="ltx_text" style="font-size:90%;">A Retrieval-Augmented Generation (RAG) module for local codebases. It constructs a vector or semantic index of the project files, allowing the agent to perform natural language queries over the existing code structure.</span></span>
</span>
</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" style="padding-top:2.3pt;padding-bottom:2.3pt;"><span class="ltx_text ltx_font_typewriter" style="font-size:90%;">document_segmentation</span></td>
<td class="ltx_td ltx_align_justify ltx_border_r ltx_border_t" style="padding-top:2.3pt;padding-bottom:2.3pt;">
<span class="ltx_inline-block ltx_align_top">
<span class="ltx_p"><span class="ltx_text" style="font-size:90%;">A pre-processing utility implementing semantic chunking algorithms. It partitions large technical documents into context-window-compliant segments, facilitating the "Paper2Code" workflow for complex algorithm implementation.</span></span>
</span>
</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_b ltx_border_l ltx_border_r ltx_border_t" rowspan="10" style="padding-top:2.3pt;padding-bottom:2.3pt;"><span class="ltx_text ltx_font_bold" style="font-size:90%;">Action &amp; Execution</span></td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" style="padding-top:2.3pt;padding-bottom:2.3pt;"><span class="ltx_text ltx_font_typewriter" style="font-size:90%;">filesystem</span></td>
<td class="ltx_td ltx_align_justify ltx_border_r ltx_border_t" style="padding-top:2.3pt;padding-bottom:2.3pt;">
<span class="ltx_inline-block ltx_align_top">
<span class="ltx_p"><span class="ltx_text" style="font-size:90%;">A sandboxed file I/O interface allowing controlled read/write operations within the project directory. It enforces path validation security policies to prevent unauthorized system access during code generation.</span></span>
</span>
</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" style="padding-top:2.3pt;padding-bottom:2.3pt;"><span class="ltx_text ltx_font_typewriter" style="font-size:90%;">code_implementation</span></td>
<td class="ltx_td ltx_align_justify ltx_border_r ltx_border_t" style="padding-top:2.3pt;padding-bottom:2.3pt;">
<span class="ltx_inline-block ltx_align_top">
<span class="ltx_p"><span class="ltx_text" style="font-size:90%;">The core generative engine encapsulated as an MCP tool. It orchestrates the synthesis of functional code blocks, integrating logic planning with atomic file writing operations to ensure code coherence.</span></span>
</span>
</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" style="padding-top:2.3pt;padding-bottom:2.3pt;"><span class="ltx_text ltx_font_typewriter" style="font-size:90%;">command_executor</span></td>
<td class="ltx_td ltx_align_justify ltx_border_r ltx_border_t" style="padding-top:2.3pt;padding-bottom:2.3pt;">
<span class="ltx_inline-block ltx_align_top">
<span class="ltx_p"><span class="ltx_text" style="font-size:90%;">A runtime environment interface permitting the execution of shell commands (e.g., </span><span class="ltx_text ltx_font_typewriter" style="font-size:90%;">pytest</span><span class="ltx_text" style="font-size:90%;">, </span><span class="ltx_text ltx_font_typewriter" style="font-size:90%;">pip install</span><span class="ltx_text" style="font-size:90%;">). It establishes a feedback loop by capturing </span><span class="ltx_text ltx_font_typewriter" style="font-size:90%;">stdout</span><span class="ltx_text" style="font-size:90%;">/</span><span class="ltx_text ltx_font_typewriter" style="font-size:90%;">stderr</span><span class="ltx_text" style="font-size:90%;"> for iterative debugging and self-correction.</span></span>
</span>
</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t" style="padding-top:2.3pt;padding-bottom:2.3pt;"><span class="ltx_text ltx_font_typewriter" style="font-size:90%;">git_command</span></td>
<td class="ltx_td ltx_align_justify ltx_border_b ltx_border_r ltx_border_t" style="padding-top:2.3pt;padding-bottom:2.3pt;">
<span class="ltx_inline-block ltx_align_top">
<span class="ltx_p"><span class="ltx_text" style="font-size:90%;">Version control management interface. It abstracts Git plumbing commands, enabling the agent to manage repository state, branch for experimental features, and maintain a clean commit history.</span></span>
</span>
</td>
</tr>
</table>
</figure>
</section>
</section>
</article>
</div>
<footer class="ltx_page_footer">
<div class="ltx_page_logo">Generated  on Mon Dec  8 15:29:19 2025 by <a class="ltx_LaTeXML_logo" href="http://dlmf.nist.gov/LaTeXML/"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img alt="Mascot Sammy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg=="/></a>
</div></footer>
</div>
</body>
</html>
